<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
    
    <entry>
      <title><![CDATA[Storm应用实例--集成HBase]]></title>
      <url>http://www.aloo.me/2016/08/14/%E5%9C%A8Storm%E4%B8%AD%E6%93%8D%E4%BD%9CHBase/</url>
      <content type="html"><![CDATA[<p><div align="center"><img src="http://ww1.sinaimg.cn/bmiddle/9bd9d3e2gw1f6tdpgrrp3j20fp08eq3s.jpg" alt=""></div></p>
<blockquote>
<p>本文展示一个Storm的topology，该topology对给定的词源进行词频统计，然后存入HBase，该实例不借助storm-hbase包，而是直接使用hbase client来完成对HBase的操作。</p>
</blockquote>
<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>由Twitter开源的、分布式实时计算系统<a href="http://storm.apache.org/" target="_blank" rel="external">Apache Storm</a>，如今已被多家知名企业应用于实时分析、流式计算、在线机器学习、分布式RPC调用、ETL等领域，甚至有看到“Storm之于实时计算，就像Hadoop之于数据批处理”这样的评价，是否言过其实，这里暂且不论，但至少已经看到业界对Storm在实时计算领域的肯定，加之其开源特性，必然会得到更广泛的应用。<br>在Storm的实际应用中，在topology中将经过处理的数据通过<a href="http://hbase.apache.org/" target="_blank" rel="external">HBase</a>进行持久化，是一个常见的需求。Storm官方提供了storm-hbase，包含一些比较通用的API及其简单实现，可以查看对应的官方文档来了解基本使用方法：<a href="http://storm.apache.org/releases/current/storm-hbase.html" target="_blank" rel="external">storm-hbase</a>。但如果你需要进行一些更复杂的处理，或者希望对自己的代码有更多的掌控，那么脱离storm-hbase，直接使用HBase的Java API来完成操作，将是一个不错的选择。本文将展示的，就是一个在Storm的topology中直接使用HBase Java API操作HBase的简单示例。</p>
<h2 id="零-示例简述"><a href="#零-示例简述" class="headerlink" title="零.示例简述"></a>零.示例简述</h2><p>本项目数据源部分直接借用Storm词频统计的官方示例，在WordSpout.java中从静态字符串数组中读取单词，在WordCounterBolt.java中统计单词出现的次数，最后在MyHBaseBolt.java中将单词及其出现的次数写入到HBase。</p>
<h2 id="一-环境信息"><a href="#一-环境信息" class="headerlink" title="一.环境信息"></a>一.环境信息</h2><p>示例的测试环境：</p>
<ul>
<li>Java 8</li>
<li>Storm 1.0.1</li>
<li>HBase 1.2.2</li>
<li>Hadoop 2.6.4</li>
<li>Maven 3.3.3</li>
</ul>
<h2 id="二-创建项目"><a href="#二-创建项目" class="headerlink" title="二.创建项目"></a>二.创建项目</h2><p>示例直接使用hbase client操作HBase，因此关键的依赖只有storm和hbase client，项目pom.xml:</p>
<pre><code class="xml">&lt;properties&gt;
  &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;
  &lt;storm.version&gt;1.0.1&lt;/storm.version&gt;
  &lt;!-- 开发调试时配置为compile，topology打包时配置为provided --&gt;
  &lt;storm.scope&gt;compile&lt;/storm.scope&gt;
&lt;/properties&gt;

&lt;dependencies&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.apache.storm&lt;/groupId&gt;
        &lt;artifactId&gt;storm-core&lt;/artifactId&gt;
        &lt;version&gt;${storm.version}&lt;/version&gt;
        &lt;scope&gt;${storm.scope}&lt;/scope&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.apache.hbase&lt;/groupId&gt;
        &lt;artifactId&gt;hbase-client&lt;/artifactId&gt;
        &lt;version&gt;1.2.2&lt;/version&gt;
    &lt;/dependency&gt;
&lt;/dependencies&gt;
</code></pre>
<p>项目结构：</p>
<pre><code>--src
   --main
       --java
          --bolt
              --MyHBaseBolt.java
              --WordCounterBolt.java
          --spout
              --WordSpout.java
          --HBaseTopology.java
       --resources
           --hbase-site.xml
</code></pre><p>其中hbase-site.xml直接使用HBase服务器上面的hbase-site.xml即可。本示例的HBase集群使用独立的zookeeper集群，zk的端口使用了默认端口，因此不需要在hbase-site.xml中显式配置，详细内容见附录。</p>
<h2 id="三-词频统计"><a href="#三-词频统计" class="headerlink" title="三.词频统计"></a>三.词频统计</h2><p>这部分直接借用一个Storm官方示例：WordSpout.java从静态数组中随机读取单词并向外发射，WordCounterBolt接收来自WordSpout的包含一个个单词的tuple，对每个单词出现的次数进行统计，然后将每个单词及其对应的计数向外发射。为快速进入主题，这部分代码放在附录中。</p>
<h2 id="四-HBase操作"><a href="#四-HBase操作" class="headerlink" title="四.HBase操作"></a>四.HBase操作</h2><p>在java中通过hbase client对hbase进行读写大体有如下步骤：</p>
<ul>
<li>创建HBaseConfiguration对象，该对象可以读取CLASSPATH下的hbase-site.xml文件的内容。<br><code>Configuration config = HBaseConfiguration.create();</code></li>
<li>用前面的config对象为入参创建Connection对象来连接至目标HBase集群。connection对象对资源消耗较大，应该避免创建过多的实例。使用完毕后，调用connection的close()方法关闭连接，建议使用try/finally来确保连接的关闭。<br><code>Connection connection = ConnectionFactory.createConnection(config);</code></li>
<li>以指定的table名称(应该是已存在的)为入参创建Table对象来连接指定的表。使用完毕后，需要调用table的close()方法进行关闭。与connection不同，table对象是轻量的，对table对象的创建，不需要像connection那样小心，当然，这并不是鼓励你创建得越多越好。<br><code>Table table = connection.getTable(TableName.valueOf(&quot;WordCount&quot;));</code></li>
<li>以指定的row key(可以是在HBase中还不存在的)为入参创建Put对象来持有要写入的数据。<br><code>Put p = new Put(Bytes.toBytes(&quot;key&quot;));</code></li>
<li>调用Put对象的addColumn方法，接受列族名称(column family)、列名(column qualifier)和要写入的值作为参数。可以多次调用该方法让put对象持有一定数量的数据后，再一次性提交。<br><code>put.addColumn(Bytes.toBytes(&quot;cf&quot;), Bytes.toBytes(&quot;words&quot;), Bytes.toBytes(&quot;word&quot;));</code></li>
<li>以Put对象为入参，调用table的put方法来提交要写入hbase的数据</li>
<li>关闭table</li>
<li>关闭connection</li>
</ul>
<p>在Storm的bolt中进行实际应用：</p>
<pre><code class="java">public class MyHBaseBolt extends BaseBasicBolt {
    private Connection connection;
    private Table table;

    @Override
    public void prepare(Map stormConf, TopologyContext context) {
        Configuration config = HBaseConfiguration.create();
        try {
            connection = ConnectionFactory.createConnection(config);
//示例都是对同一个table进行操作，因此直接将Table对象的创建放在了prepare，在bolt执行过程中可以直接重用。
            table = connection.getTable(TableName.valueOf(&quot;WordCount&quot;));
        } catch (IOException e) {
            //do something to handle exception
        }
    }
    @Override
    public void execute(Tuple tuple, BasicOutputCollector basicOutputCollector) {
        //从tuple中获取单词
        String word = tuple.getString(0);
        //从tuple中获取计数，这里转换为String只是为了示例运行后存入hbase的计数值能够直观显示。
        String count = tuple.getInteger(1).toString();
        try {
            //以各个单词作为row key
            Put put = new Put(Bytes.toBytes(word));
            //将被计数的单词写入cf:words列
            put.addColumn(Bytes.toBytes(&quot;cf&quot;), Bytes.toBytes(&quot;words&quot;), Bytes.toBytes(word));
            //将单词的计数写入cf:counts列
            put.addColumn(Bytes.toBytes(&quot;cf&quot;), Bytes.toBytes(&quot;counts&quot;), Bytes.toBytes(count));
            table.put(put);
        } catch (IOException e) {
            //do something to handle exception
        }
    }
    @Override
    public void cleanup() {
        //关闭table
        try {
            if(table != null) table.close();
        } catch (Exception e){
            //do something to handle exception
        } finally {
            //在finally中关闭connection
            try {
                connection.close();
            } catch (IOException e) {
                //do something to handle exception
            }
        }
    }
    @Override
    public void declareOutputFields(OutputFieldsDeclarer outputFieldsDeclarer) {
        //示例中本bolt不向外发射数据，所以没有再做声明
    }
}
</code></pre>
<p>虽然可能应用场景相对较少，但还是附带介绍一下从HBase读取数据：</p>
<ul>
<li>以指定的row key为入参创建Get对象<br><code>Get get = new Get(Bytes.toBytes(&quot;key&quot;));</code></li>
<li>以Get实例为入参调用table的get方法来获取结果集对象Result<br><code>Result r = table.get(get);</code></li>
<li>从结果集中获取制定列的值<br><code>byte[] value = r.getValue(Bytes.toBytes(&quot;cf&quot;), Bytes.toBytes(&quot;words&quot;));</code></li>
<li><p>也可以使用scan来批量读取，Scanner实现了Iterable，因此可以使用foreach来进行遍历:</p>
<pre><code class="java">Scan scan = new Scan();
//获取指定列族所有列的数据
scan.addFamily(Bytes.toBytes(&quot;cf&quot;));
ResultScanner scanner = table.getScanner(scan);
try {
  for (Result r : scanner) {...}
}finally{
  scanner.close();
  }
</code></pre>
<h2 id="五-Topology"><a href="#五-Topology" class="headerlink" title="五.Topology"></a>五.Topology</h2><p>topology中唯一需要注意的是，在Windows测试该示例时，需要配置hadoop.home.dir属性，并确保将winutils.exe客户端(<a href="http://pan.baidu.com/s/1qWlCseK" target="_blank" rel="external">示例中使用的版本(链接若失效请自助)</a>)放置在所配置的hadoop.home.dir目录下(资料解释:在hadoop 2.x版本的包中不再包含winutils.exe文件)。<br>HBaseTopology.java：</p>
<pre><code class="java">public class PersistentWordCount {
  private static final String WORD_SPOUT = &quot;WORD_SPOUT&quot;;
  private static final String COUNT_BOLT = &quot;COUNT_BOLT&quot;;
  private static final String HBASE_BOLT = &quot;HBASE_BOLT&quot;;

  public static void main(String[] args) throws Exception {
      System.setProperty(&quot;hadoop.home.dir&quot;,&quot;E:/BaiduYunDownload&quot;);

      Config config = new Config();

      WordSpout spout = new WordSpout();
      WordCounter bolt = new WordCounter();
      MyHBaseBolt hbase = new MyHBaseBolt();

      // wordSpout ==&gt; countBolt ==&gt; HBaseBolt
      TopologyBuilder builder = new TopologyBuilder();

      builder.setSpout(WORD_SPOUT, spout, 1);
      builder.setBolt(COUNT_BOLT, bolt, 1).shuffleGrouping(WORD_SPOUT);
      builder.setBolt(HBASE_BOLT, hbase, 10).fieldsGrouping(COUNT_BOLT, new Fields(&quot;word&quot;));

      if (args.length == 0) {
          LocalCluster cluster = new LocalCluster();
          cluster.submitTopology(&quot;word&quot;, config, builder.createTopology());
          Thread.sleep(10000);
          cluster.killTopology(&quot;word&quot;);
          cluster.shutdown();
          System.exit(0);
      } else {
          config.setNumWorkers(3);
          StormSubmitter.submitTopology(args[0], config, builder.createTopology());
      }
}
</code></pre>
<p>如果编译遇到类似：<code>java.io.IOException: No FileSystem for scheme: hdfs</code>这样关于hadoop的问题，可能需要添加hadoop相关依赖包，如：</p>
<pre><code class="xml">&lt;dependency&gt;
  &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;
  &lt;artifactId&gt;hadoop-common&lt;/artifactId&gt;
  &lt;version&gt;2.6.4&lt;/version&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
  &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;
  &lt;artifactId&gt;hadoop-hdfs&lt;/artifactId&gt;
  &lt;version&gt;2.6.4&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
</li>
</ul>
<h2 id="六-总结"><a href="#六-总结" class="headerlink" title="六.总结"></a>六.总结</h2><p>本文通过一个词频统计后通过HBase进行结果持久化的topology示例，展示了如何在Storm的中直接使用HBase的java api来实现基本的读写操作，希望能为想自己完成Storm的HBase集成而不得其法的朋友提供一个入门指引。</p>
<h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><ol>
<li><p>WordSpout.java:</p>
<pre><code class="java">public class WordSpout extends BaseRichSpout {
 private SpoutOutputCollector collector;
 private static final String[] MSGS = new String[]{
         &quot;Storm&quot;, &quot;HBase&quot;, &quot;Integration&quot;, &quot;example&quot;, &quot;by &quot;, &quot;aloo&quot;, &quot;in&quot;, &quot;Aug&quot;,
 };

 private static final Random random = new Random();

 @Override
 public void declareOutputFields(OutputFieldsDeclarer declarer) {
     declarer.declare(new Fields(&quot;word&quot;));
 }

 @Override
 public void open(Map conf, TopologyContext context, SpoutOutputCollector collector) {
     this.collector = collector;
 }

 @Override
 public void nextTuple() {
     String word = MSGS[random.nextInt(8)];
     collector.emit(new Values(word));
 }
}
</code></pre>
</li>
<li><p>WordCounterBolt.java:</p>
<pre><code class="java">public class WordCounter extends BaseBasicBolt {
 private Map&lt;String, Integer&gt; _counts = new HashMap&lt;String, Integer&gt;();

 @Override
 public void execute(Tuple tuple, BasicOutputCollector collector) {
     String word = tuple.getString(0);
     int count;
     if(_counts.containsKey(word)){
         count = _counts.get(word);
     } else {
         count = 0;
     }
     count ++;
     _counts.put(word, count);
     collector.emit(new Values(word, count));
 }
 @Override
 public void declareOutputFields(OutputFieldsDeclarer declarer) {
     declarer.declare(new Fields(&quot;word&quot;, &quot;count&quot;));
 }
}
</code></pre>
</li>
<li>hbase-site.xml<pre><code class="xml">&lt;?xml version=&quot;1.0&quot;?&gt;
&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;
&lt;configuration&gt;
 &lt;property&gt;
     &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;
     &lt;value&gt;true&lt;/value&gt;
 &lt;/property&gt;
 &lt;property&gt;
     &lt;name&gt;hbase.rootdir&lt;/name&gt;
     &lt;value&gt;hdfs://xxx.xx.xx.xx:9000/hbase&lt;/value&gt;
 &lt;/property&gt;
 &lt;property&gt;
     &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt;
     &lt;value&gt;/home/hadoop/hbase/storm/zookeeper&lt;/value&gt;
 &lt;/property&gt;
 &lt;property&gt;
     &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;
     &lt;value&gt;zknode1,zdnode2,zknode3&lt;/value&gt;
&lt;/configuration&gt;
</code></pre>
</li>
</ol>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[性能测试中服务器关键性能指标浅析]]></title>
      <url>http://www.aloo.me/2016/08/01/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E4%B8%AD%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%85%B3%E9%94%AE%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87%E6%B5%85%E6%9E%90/</url>
      <content type="html"><![CDATA[<p><img src="http://ww2.sinaimg.cn/large/9bd9d3e2gw1f6df9vs0ojj20f406w76x.jpg" alt=""></p>
<blockquote>
<p>在对互联网服务进行服务端性能测试时，主要关注两方面的性能指标：</p>
<ul>
<li><strong>业务指标</strong>：如吞吐量(QPS、TPS)、响应时间(RT)、并发数、业务成功率等</li>
<li><strong>资源指标</strong>：如CPU、内存、Disk I/O、Network I/O等资源的消耗情况<br>本文主要介绍一些广泛适用的、基本的<strong>资源指标</strong>以及这些指标在<strong>Linux</strong>服务器的获取方式。</li>
</ul>
</blockquote>
<a id="more"></a>
<h2 id="一-CPU"><a href="#一-CPU" class="headerlink" title="一. CPU"></a>一. CPU</h2><p>关于CPU资源，有三个重要概念是我们需要关注的：使用率、运行队列和上下文切换，这里借助一张描述进程状态的图来进行简要说明：<br><img src="http://ww3.sinaimg.cn/large/9bd9d3e2gw1f6df9v7gnij20b40b4dgo.jpg" alt="Process state -via wikipedia"></p>
<p><div align="center" style="color:#808080;font-size:12px"><em>图1 Process state -via wikipedia</em></div></p>
<ul>
<li><strong>Running</strong>：正在运行的进程</li>
<li><strong>Waiting</strong>：已准备就绪，等待运行的进程</li>
<li><strong>Blocked</strong>：因为等待某些事件完成而阻塞的进程，通常是在等待I/O，如Disk I/O，Network I/O等。</li>
</ul>
<p>这里的Running和Waiting共同构成Linux进程状态中的<em>可运行状态(task_running)</em>，而Blocked状态可以对应Linux进程状态中的<em>不可中断睡眠状态(task_uninterruptible)</em></p>
<p>在Linux可以使用<strong>vmstat</strong>来获取这些数据：</p>
<pre><code class="shell">[hbase@ecs-097 ~]$ vmstat 1
procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 6  0      0 4591436 176804 1185380    0    0     0     0 7915 10357 83  5 12  0  0
</code></pre>
<p><strong>CPU使用率(CPU Utilization Percentages)：</strong>有进程处于Running状态的时间/总时间。在vmstat主要通过<strong>us</strong>、<strong>sys</strong>和<strong>id</strong>三列数据来体现：</p>
<ul>
<li>us：用户占用CPU的百分比</li>
<li>sy：系统(内核和中断)占用CPU的百分比</li>
<li>id：CPU空闲的百分比</li>
</ul>
<p>性能测试指标中，CPU使用率通常用us + sy来计算，其可接受上限通常在70%~80%。另外需要注意的是，在测试过程中，如果sy的值长期大于25%，应该关注in(系统中断)和cs(上下文切换)的数值，并根据被测应用的实现逻辑来分析是否合理。</p>
<p><strong>运行队列进程数(Processes on run queue)：</strong>Running状态 + Waiting状态的进程数，展示了正在运行和等待CPU资源的任务数，可以看作CPU的工作清单，是判断CPU资源是否成为瓶颈的重要依据。vmstat通过<strong>r</strong>的值来体现：</p>
<ul>
<li>r： 可运行进程数，包括正在运行(Running)和已就绪等待运行(Waiting)的。</li>
</ul>
<p>如果r的值等于系统CPU总核数，则说明CPU已经满负荷。在负载测试中，其可接受上限通常不超过CPU核数的2倍。</p>
<p><strong>上下文切换(Context Switches)：</strong>简单来说，context指CPU寄存器和程序计数器在某时间点的内容，(进程)上下文切换即kernel挂起一个进程并将该进程此时的状态存储到内存，然后从内存中恢复下一个要执行的进程原来的状态到寄存器，从其上次暂停的执行代码开始继续执行至频繁的上下文切换将导致sy值增长。vmstat通过cs的值来体现：</p>
<ul>
<li>cs：每秒上下文切换次数。</li>
</ul>
<p>另外还有一个指标用来作为系统在一段时间内的负载情况的参考：<br><strong>平均负载Load Average：</strong>在UNIX系统中，Load是对系统工作量的度量。Load取值有两种情况，多数UNIX系统取运行队列的值(vmstat输出的r)，而<strong>Linux系统取运行队列的值 + 处于<em>task_uninterruptible</em>状态的进程数(vmstat输出的b)</strong>，所以会出现CPU使用率不高但Load值很高的情况。Load Average就是在一段时间内的平均负载，系统工具top、uptime等提供1分钟、5分钟和15分钟的平均负载值。</p>
<pre><code class="shell">[hbase@ecs-097 ~]$ top
top - 19:23:28 up 18:05,  3 users,  load average: 0.80, 0.60, 0.53
</code></pre>
<p>上面示例中的0.80即是1分钟内的Load average，以此类推。<br>当我们需要了解当前系统负载情况时，可以先查看Load average的值，如果系统持续处于高负载(如15分钟平均负载大于CPU总核数的两倍)，则查看vmstat的r值和b值来确认是CPU负荷重还是等待I/O的进程太多。</p>
<h2 id="二-Memory"><a href="#二-Memory" class="headerlink" title="二. Memory"></a>二. Memory</h2><p>Memory资源也有三方面需要重点关注：可用内存，swap占用，页面交换(Paging)，仍然借助一张图来说明：<br><img src="http://ww1.sinaimg.cn/large/9bd9d3e2gw1f6e3jciyp5j20kd0g9myp.jpg" alt="Virtual Memory"></p>
<p><div align="center" style="color:#808080;font-size:12px"><em>图2 Virtual Memory</em></div><br>这里讲到的内存，包括物理内存和虚拟内存，如上图所示，物理内存和硬盘上的一块空间(SWAP)组合起来作为虚拟内存(Virtual Memory)为进程的运行提供一个连续的内存空间，这样的好处是进程可用的内存变大了，但需要注意的是，SWAP的读写速度远低于物理内存，并且物理内存和swap之间的数据交换会增加系统负担。虚拟内存被分成页(x86系统默认页大小为4k)，内核读写虚拟内存以页为单位，当物理内存空间不足时，内存调度会将物理内存上不常使用的内存页数据存储到磁盘的SWAP空间，物理内存与swap空间之间的数据交换过程称为页面交换(Paging)。</p>
<p><strong>可用内存(free memory)：</strong>内存占用的直观数据，vmstat输出free的值，可用内存过小将影响整个系统的运行效率，对于稳定运行的系统，free可接受的范围通常应该大于物理内存的20%，即内存占用应该小于物理内存的80%。在压力测试时，系统内存资源的情况应该用可用内存结合页面交换情况来判断，如果可以内存很少，但页面交换也很少，此时可以认为内存资源还对系统性能构成严重影响。</p>
<p><strong>页面交换(Paging)：</strong>页面交换包括从SWAP交换到内存和从内存交换到SWAP，如果系统出现频繁的页面交换，需要引起注意。可以从vmstat的si和so获取：</p>
<ul>
<li>si：每秒从SWAP读取到内存的数据大小</li>
<li>so：每秒从内存写入到SWAP的数据大小</li>
</ul>
<p><strong>SWAP空间占用:</strong>可以从vmstat的swpd来获取当前SWAP空间的使用情况，应该和页面交换结合来分析，比如当swpd不为0，但si，so持续保持为0时，内存资源并没有成为系统的瓶颈。</p>
<h2 id="三-Disk"><a href="#三-Disk" class="headerlink" title="三. Disk"></a>三. Disk</h2><p>磁盘通常是系统中最慢的一环，一是其自身速度慢，即使是SSD，其读写速度与内存都还存在数量级的差距，二是其离CPU最远。另外需要说明的是磁盘IO分为<strong>随机IO</strong>和<strong>顺序IO</strong>两种类型，在性能测试中应该先了解被测系统是偏向哪种类型。</p>
<ul>
<li>随机IO：随机读写数据，读写请求多，每次读写的数据量较小，其IO速度更依赖于磁盘每秒能IO次数(IOPS)。</li>
<li>顺序IO：顺序请求大量数据，读写请求个数相对较少，每次读写的数据量较大，顺序IO更重视每次IO的数据吞吐量。</li>
</ul>
<p>对于磁盘，首要关注使用率，IOPS和数据吞吐量，在Linux服务区，可以使用iostat来获取这些数据。</p>
<pre><code class="shell">[hbase@ecs-097 ~]$ iostat -dxk 1
Linux 2.6.32-504.3.3.el6.x86_64 (ecs-097)     08/01/2016     _x86_64_    (4 CPU)
avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           0.52    0.00    0.13    0.06    0.00   99.28
Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await  svctm  %util
xvda              0.10     6.63    0.40    2.57     6.22    36.80    29.00     0.04   14.63   1.19   0.35
</code></pre>
<p><strong>(设备)使用率：</strong>统计过程中处理I/O请求的时间与统计时间的百分比，即iostat输出中的%util，如果该值大于60%，很可能降低系统的性能表现。</p>
<p><strong>IOPS：</strong>每秒处理读/写请求的数量，即iostat输出中的r/s和w/s，个人PC的机械硬盘IOPS一般在100左右，而各种公有云/私有云的普通服务器，也只在百这个数量级。预先获取到所用服务区的IOPS能力，然后在性能测试中监控试试的IOPS数据，来衡量当前的磁盘是否能满足系统的IO需求。</p>
<p><strong>数据吞吐量：</strong>每秒读/写的数据大小，即iostat输出中的rkB/s和wkB/s，通常磁盘的数据吞吐量与IO类型有直接关系，顺序IO的吞吐能力明显优与随机读写，可以预先测得磁盘在随机IO和顺序IO下的吞吐量，以便于测试时监控到的数据进行比较衡量。</p>
<h2 id="四-Network"><a href="#四-Network" class="headerlink" title="四. Network"></a>四. Network</h2><p>网络本身是系统中一个非常复杂的部分，但常规的服务端性能测试通常放在一个局域网进行，因为我们首先关注被测系统自身的性能表现，并且需要保证能在较少的成本下发起足够大的压力。因此对于多数系统的性能测试，我们主要关注网络<strong>吞吐量</strong>即可，对于稳定运行的系统，需要为被测场景外的业务流出足够的带宽；在压力测试过程中，需要注意瓶颈可能来自于带宽。<br>在Linuxf服务器，可以使用iptraf来查看本机网络吞吐量，如：</p>
<pre><code class="shell">[root@ecs-097 ~]# iptraf -d eth0
x Total rates:         67.8 kbits/sec        Broadcast packets:            0                                                                                                                x
x                      54.2 packets/sec      Broadcast bytes:              0                                                                                                                x
x                                                                                                                                                                                           x
x Incoming rates:      19.2 kbits/sec                                                                                                                                                       x
x                      25.4 packets/sec                                                                                                                                                     x
x                                            IP checksum errors:           0                                                                                                                x
x Outgoing rates:      48.7 kbits/sec                                                                                                                                                       x
x                      28.8 packets/sec
</code></pre>
<h2 id="五-总结"><a href="#五-总结" class="headerlink" title="五. 总结"></a>五. 总结</h2><p>性能测试中，数据收集很重要，但是更重要的是快速抓住关键数据，读懂数据的含义。<br>本文主要介绍服务端性能测试中，对于CPU、内存等各种系统资源，通常首要关注的数据，以及这些数据在Linux服务器上的获取方式。<br>在实际测试中，通常会持续收集这些数据，如使用nmon，JMeter的PerfMon插件，以及zabbix等专门的系统监控工具，这就不在本文展开了。</p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p><a href="https://en.wikipedia.org/wiki/Load_%28computing%29" target="_blank" rel="external">Load (computing)</a><br><a href="https://en.wikipedia.org/wiki/Process_state" target="_blank" rel="external">Process state</a><br><a href="http://techblog.netflix.com/2015/11/linux-performance-analysis-in-60s.html" target="_blank" rel="external">Linux Performance Analysis in 60,000 Milliseconds</a></p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[HBase入门精要--百闻不如一Run]]></title>
      <url>http://www.aloo.me/2016/07/24/HBase%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81-%E7%99%BE%E9%97%BB%E4%B8%8D%E5%A6%82%E4%B8%80Run/</url>
      <content type="html"><![CDATA[<p><img src="http://ww1.sinaimg.cn/mw690/9bd9d3e2gw1f64pay4toej20d203c74i.jpg" alt="HBase Logo"></p>
<h2 id="零-导读"><a href="#零-导读" class="headerlink" title="零.导读"></a>零.导读</h2><p>HBase，基于Google Bigtable实现的开源、分布式、可伸缩的列式存储数据库，诞生于Hadoop，也是Hadoop生态的重要一环，如今作为一个Apache顶级项目，早已经不能将其仅仅看作Hadoop的一部分，基于Storm，Spark等框架的数据处理方案中，都有它的身影，可以说它已经成为大数据工具箱中非常重要的一种数据存储工具，也因此必然会被很纳入很多人学习计划。<br>对于一个新技术的入门，我认为一种有效的学习方式是：</p>
<blockquote>
<p>对其有简要认知后，通过Quick Start式的使用，获得直观的感知，消除距离感，然后再带着使用过程中的疑问去了解其背后的真相，最后支撑我们将其应用到实际工程。</p>
</blockquote>
<p>我将消除距离感这一阶段，称之为<strong>百闻不如一Run</strong>。</p>
<p>本文分三部分带你完成对HBase的<em>百闻不如一Run</em>：数据模型概述、环境部署和基本操作。</p>
<p><em>版本：本文基于HBase 1.2.2 –Release date: 11/Jul/16 </em></p>
<a id="more"></a>
<h2 id="一-HBase数据模型"><a href="#一-HBase数据模型" class="headerlink" title="一. HBase数据模型"></a>一. HBase数据模型</h2><p>HBase是对Bigtable的开源实现，所以先来认识一下Bigtabl概念，引用<a href="http://research.google.com/archive/bigtable.html" target="_blank" rel="external">Google’s BigTable Paper</a>中的精简描述：</p>
<blockquote>
<p>A Bigtable is a sparse, distributed, persistent multidimensional sorted map.</p>
<p>The map is indexed by a row key, column key, and a timestamp; each value in the map is an uninterpreted array of bytes.</p>
</blockquote>
<p>HBase的数据模型与此非常相似，用一张参考自上述论文的图来辅助理解：</p>
<p><img src="http://ww2.sinaimg.cn/large/9bd9d3e2gw1f64paypqtyj20ri081gmx.jpg" alt="图1 HBase表中某一行所存储数据的一种可视化呈现"></p>
<p><div align="center" style="color:#808080;font-size:12px"><em>图1 HBase表中某一行所存储数据的一种可视化呈现</em></div><br>HBase的结构：</p>
<ul>
<li><em>命名空间(namespace):0.96版本开始支持，是对多个表的逻辑分组，类似于关系数据库的database，在本文暂不关心。</em></li>
<li><strong>表(table)：</strong>一张表中包含若干行。</li>
<li><strong>行(row)：</strong>一行包括一个行键(row key)和若干列族，一张表中的行<strong>按照行键排序</strong>，并用行键作为索引。图1中展示了一个行键为row1的行。</li>
<li><strong>列族(column family)：</strong>每个列族包含若干个列，<strong>列族需要在建表时预定义，运行期间可以动态加入新的列</strong>。图1中的”data”、”meta”就是row1行中的两个列族。 在物理层面，HBase的数据存储是在列族这一层级进行组织，每个列族单独存储。</li>
<li><strong>列(column)：</strong>每个列都归属于某个列族，以列族名作为前缀，通常使用<em>列族名：修饰符</em>的形式来标识一个列，可以将其中的修饰符部分看作列名。图1中的”meta:mimetype”和”meta:size”即是列族meta中的成员。</li>
<li><strong>单元格(cell)：</strong>存储的每一个值存放在一个单元格中，由<strong><em>[行，列，版本号]</em></strong>来唯一指向一个单元格。图1中彩色标识的矩形块即可看作是一个单元格</li>
<li><strong>版本(version)：</strong>版本号默认是时间戳形式，同一列中可能包含若干单元格，这些单元格由版本号唯一区分，<strong>根据版本号降序排列</strong>，HBase查询时，如果不指定版本号，默认返回最新的值。图1中的t3,t6等即代表版本号。<strong>版本是HBase多维特性的表现</strong>。</li>
</ul>
<p>Google论文中Bigtable描述为一个map，那么从Map的维度，用JSON格式，HBase的结构可以理解为：</p>
<pre><code class="Json">{
  &quot;row1&quot; : {
    &quot;family1&quot; : {
      &quot;column1&quot; : {
        timestamp2 : &quot;value1&quot;,
        timestamp3 : &quot;value2&quot;
        },
      &quot;column2&quot; : {timestamp6 : &quot;value3&quot;}
    },
    &quot;family2&quot; : { ... }
  },
  &quot;row2&quot; : {
    &quot;family3&quot; : { ... }
  },
}
</code></pre>
<p>而关于其<em>稀疏</em>这一特性，可以用下图来辅助理解：</p>
<p><img src="http://ww2.sinaimg.cn/mw690/9bd9d3e2gw1f64pb0bqxcj20rr0poadb.jpg" alt="图2 HBase的行和列所构成的更像标签，而不是表格"></p>
<p><div align="center" style="color:#808080;font-size:12px"><em>图2 HBase的行和列所构成的更像标签，而不是表格</em></div><br>对于我们熟悉的关系型数据库，如MySQL，一张表中每一行都有相同的列，即使部分行的某些列不存储数据，也有消耗，如图中的NULL。而HBase，各行是相对独立的，可以有完全不同的列。</p>
<h2 id="二-部署"><a href="#二-部署" class="headerlink" title="二.部署"></a>二.部署</h2><p>如果最初阶段你需要HBase环境的主要目的是想熟悉对HBase的CRDU操作，那么看完<em>独立部署</em>后，可以直接跳到<em>三.基本操作</em>进行数据库操作。<br>如果希望在部署环境过程中对HBase的架构也做一个简要了解，那么建议进行<em>伪分布式部署</em>；如果伪分布式部署你能够很快完成，那么相信完全的分布式部署对你来说也并不困难，并且本文的主要目的是快速入门，因此不提供完全分布式部署的过程指引，如有需要，请参考官方指南<a href="http://hbase.apache.org/book.html#quickstart_fully_distributed" target="_blank" rel="external">quickstart_fully_distributed</a>。</p>
<h3 id="0-基础条件"><a href="#0-基础条件" class="headerlink" title="0. 基础条件"></a><strong>0. 基础条件</strong></h3><ul>
<li>需要Java，支持JDK7和JDK8</li>
<li>需要ssh，伪分布式部署需要<em>ssh localhost</em>能正常连接，分布式部署需要配置各节点间的无密码登陆(<em>ssh passwordless login</em>)</li>
</ul>
<p><em>注：1.0.0版本开始，HBase内部组件(HMaster,HRegionServer)的默认端口从60xxx变更为16xxx</em></p>
<h3 id="1-独立部署"><a href="#1-独立部署" class="headerlink" title="1. 独立部署"></a><strong>1. 独立部署</strong></h3><blockquote>
<p>如果想要最快速的搭建供你练习HBase数据库操作的环境，那么这可能是你想要的。<br>独立部署模式下，HBase的所有进程都运行在一个JVM中，数据直接存储在本地磁盘。</p>
</blockquote>
<p>a. 下载安装包并解压</p>
<pre><code>wget https://mirrors.tuna.tsinghua.edu.cn/apache/hbase/1.2.2/hbase-1.2.2-bin.tar.gz
tar zxvf hbase-1.2.2-bin.tar.gz -C target-dir
</code></pre><p>b. 配置</p>
<ul>
<li>在<em>/etc/hosts</em>中配置localhost的地址：<em>127.0.0.1 localhost</em></li>
<li>JAVA_HOME：在<em>conf/hbase-env.sh</em>中配置,例如：<em>export JAVA_HOME=/usr/local/jdk</em></li>
<li>配置HBase和zookeeper保存数据的位置：<ul>
<li>如果不配置，默认写在/tmp目录下</li>
<li>在<em>conf/hbase-site.xml.</em>中配置,地址格式有两种，例如：<pre><code class="xml">&lt;configuration&gt;
  &lt;property&gt;
      &lt;name&gt;hbase.rootdir&lt;/name&gt;
      &lt;value&gt;file:///home/hbase/hbase1.2.2&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
      &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt;
      &lt;value&gt;/home/hbase/hbase1.2.2/zookeeper&lt;/value&gt;
  &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>
</li>
</ul>
</li>
</ul>
<p>c. 启动和停止<br>   可以直接在HBase安装目录运行<em>bin/start-hbase.sh</em>启动：</p>
<pre><code class="bash">[hbase@iZ25n0dx8rxZh base]$ ./bin/start-hbase.sh 
starting master, logging to /usr/local/hbase/bin/../logs/hbase-hbase-master-iZ25n0dx8rxZ.out
</code></pre>
<p>启动日志默认位于<em>./logs/hbase-[username]-master-[yourhostname].log</em>，启动成功后，用<em>jps</em>命令可以看到名为HMaster的进程。接下来，你就可以使用hbase的shell来进行操作练习了。<br>要停止hbase，使用<em>bin/stop-hbase.sh</em>。</p>
<p>d. UI访问<br>  Hbase内建了一个用Jetty提供服务的web UI页面来查看该HBase环境的各种信息，默认端口16010，尝试用<em><a href="http://hostip:16010/" target="_blank" rel="external">http://hostip:16010/</a></em>来访问。</p>
<h3 id="2-伪分布式部署"><a href="#2-伪分布式部署" class="headerlink" title="2. 伪分布式部署"></a><strong>2. 伪分布式部署</strong></h3><blockquote>
<p>伪分布式模式下，HBase的所有组件还是运行在同一台主机，不同的是，每个组件独立运行在不同的JVM。更重要的是，我们可以在该模式下启动多个Regionserver和master，构成一个虚拟的分布式架构以供学习，这是很多<em>快速入门</em>文章所略过的重点。<br>该模式下，可以对接HDFS，但那涉及hadoop的部署，为以更短的时间达到当前阶段的目的，本文仍存储在本地磁盘。</p>
</blockquote>
<p><strong>a. HBase架构概要</strong><br><img src="http://ww1.sinaimg.cn/large/9bd9d3e2gw1f64pazfmiaj20mc0ep76l.jpg" alt="图3 HBase架构概要图"></p>
<p><div align="center" style="color:#808080;font-size:12px"><em>图3 HBase架构概要图</em></div><br>作为入门阶段，先从粗粒度对HBase的架构进行简单了解：<br><strong>HMaster：</strong>主要负责监控集群、管理RegionServers的负责均衡等，可以用主-备形式部署多个Master。<br><strong>HRegionServers：</strong>负责响应用户的I/O操作请求，客户端对HBase读写数据是与RegionServer交互。<br><strong>Zookeeper：</strong>负责选举Master的主节点；服务注册；保存RegionServers的状态等。可以使用系统内建的zookeeper，也可以使用独立的zookeeper，只需要在配置文件中调整即可。<br><strong>HDFS：</strong>真正的数据持久层，并非必须是HDFS文件系统，但搭配HDFS是最佳选择，也是目前应用最广泛的选择。</p>
<p><strong>b. 开始部署</strong><br>伪分布式模式下，需要保证<em>ssh localhost</em>能够成功连接(将HBase所属用户的publickey追加到其自身的authorized_keys中)。如果你跟随本文启动了独立模式的HBase，先将其停止。</p>
<ul>
<li>开启分布式配置<br>最基本的伪分布式配置，只需要在独立模式的配置基础上，追加开启分布式模式的配置，即将<em>hbase.cluster.distributed</em>配置为true，例如：<pre><code class="xml">&lt;configuration&gt;
    &lt;property&gt;
      &lt;name&gt;hbase.rootdir&lt;/name&gt;
      &lt;value&gt;/home/hbase/hbase1.2.2&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
      &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt;
      &lt;value&gt;file:///home/hbase/hbase1.2.2/zookeeper&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
      &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;
      &lt;value&gt;true&lt;/value&gt;
    &lt;/property&gt;
 &lt;/configuration&gt;
</code></pre>
</li>
<li>在安装目录运行<em>bin/start-hbase.sh</em><pre><code class="bash">[hbase@iZ25n0dx8rxZ hbase]$ ./bin/start-hbase.sh
localhost: starting zookeeper, logging to /usr/local/hbase/bin/../logs/hbase-hbase-zookeeper-iZ25n0dx8rxZ.out
starting master, logging to /usr/local/hbase/bin/../logs/hbase-hbase-master-iZ25n0dx8rxZ.out
starting regionserver, logging to /usr/local/hbase/bin/../logs/hbase-hbase-1-regionserver-iZ25n0dx8rxZ.out
</code></pre>
可以看到依次启动了zookeeper、master和regionserver，启动日志为<em>./logs</em>路径下的<em>.log</em>文件。</li>
<li><p>查看启动的进程以及占用的端口：</p>
<pre><code class="bash">[hbase@iZ25n0dx8rxZ logs]$ jps
4610 HRegionServer
4456 HQuorumPeer
5338 Jps
4522 HMaster
[hbase@iZ25n0dx8rxZ logs]$ netstat -lnp|grep 4522
tcp        0      0 172.16.5.23:16000           0.0.0.0:*                   LISTEN      4522/java           
tcp        0      0 0.0.0.0:16010               0.0.0.0:*                   LISTEN      4522/java           
[hbase@iZ25n0dx8rxZ logs]$ netstat -lnp|grep 4610
tcp        0      0 172.16.5.23:16201           0.0.0.0:*                   LISTEN      4610/java           
tcp        0      0 0.0.0.0:16301               0.0.0.0:*                   LISTEN      4610/java           
[root@iZ25n0dx8rxZ logs]$ netstat -lnp|grep 4456
tcp        0      0 0.0.0.0:2188                0.0.0.0:*                   LISTEN      4456/java
</code></pre>
<ul>
<li>HMaster占用16000(工作进程)和16010(Master的web UI服务端口)</li>
<li>HRegionServer占用16201(工作进程)和16301(Regionserver的web UI服务)</li>
<li>HQuorumPeer是HBase内建zookeeper进程，默认端口2181<em>(即zookeeper的默认配置)</em>。如果是独立的zookeeper，进程名是<em>QuorumPeerxxx</em>，没有第一个字母H。</li>
</ul>
</li>
<li><p><strong>启动和停止备份Master节点<em>(backup HMaster)</em></strong>：</p>
<ul>
<li>运行<em>./bin/local-master-backup.sh start n</em>来启动一个备份节点，如：<pre><code class="bash">[hbase@iZ25n0dx8rxZ hbase]$ ./bin/local-master-backup.sh start 1
starting master, logging to /usr/local/hbase/bin/../logs/hbase-hbase-1-master-iZ25n0dx8rxZ.out
</code></pre>
启动成功后，<em>jps</em>命令可以看到总共有两个HMaster进程。</li>
<li><p>端口：<strong>n</strong>用来指定占用的端口号，规则为<strong>[默认端口号+n]</strong>,如例子中的<em>./bin/local-master-backup.sh start 1</em>所启动的HMaster占用16001(工作端口)和16011(web UI服务端口)，以此类推。</p>
</li>
<li><p>日志：启动日志在<em>./logs/hbase-[username]-n-master-[hostname].log</em>，在上例的日志中，可以看到这样一行日志说明该节点目前是作为备用节点：</p>
<pre><code class="bash">master.ActiveMasterManager: Another master is the active master, iz25n0dx8rxz,16000,1469262015657; waiting to become the next active master
</code></pre>
<p><strong><em>注意：</em></strong>如果使用1.2.2之前版本的安装包(如1.1.5)，运行启动脚本后backup Master可能会因为端口被占用而无法启动，这是因为脚本里面，没有按照规则更改backup Master的工作端口，启动时仍然使用默认的16000，而该端口已经被前面启动的主节点占用。<strong>可以通过如下方法解决该问题：</strong><br>手动在<em>./bin/local-master-backup.sh</em>脚本中为<em>HBASE_MASTER_ARGS</em>赋值的这句话内添加<em>-D hbase.master.port=`expr 16000 + $DN` \ </em>来设置backup Master的工作端口，添加后这句话的完整内容如下：</p>
<pre><code class="bash">HBASE_MASTER_ARGS=&quot;\
-D hbase.master.port=`expr 16000 + $DN` \
-D hbase.master.info.port=`expr 16010 + $DN` \
-D hbase.regionserver.port=`expr 16020 + $DN` \
-D hbase.regionserver.info.port=`expr 16030 + $DN` \
--backup&quot;
</code></pre>
</li>
<li>web UI访问地址：<em><a href="http://ip:1601n" target="_blank" rel="external">http://ip:1601n</a></em></li>
<li>主节点切换：要观察HBase的Master组件主节点切换，可以使用<em>kill -9 PID</em>停止当前主节点<em>(即最初启动的HMaster)</em>，此时刚启动的备份节点将切换为主节点，可以在备份节点的日志<em>(./logs/hbase-[username]-1-master-[hostname].log)</em>中看到如下内容：<pre><code class="bash">INFO  [iZ25n0dx8rxZ:16001.activeMasterManager] master.ActiveMasterManager: Deleting ZNode for /hbase/backup-masters/iz25n0dx8rxz,16001,1469267021567 from backup master directory
INFO  [iZ25n0dx8rxZ:16001.activeMasterManager] master.ActiveMasterManager: Registered Active Master=iz25n0dx8rxz,16001,1469267021567
</code></pre>
</li>
<li>停止：使用<em>./bin/local-master-backup.sh stop n</em>来停止你的备份节点。</li>
<li>多备：可以一次启动多个backup HMaster，命令类似于<em>./bin/local-master-backup.sh start x y z</em>。</li>
</ul>
</li>
<li><strong>启动和停止额外的RegionServer</strong><ul>
<li>运行额外RegionServer的方式与backup HMaster类似，启动：<em>./bin/local-regionservers.sh start n</em>，停止：<em>./bin/local-regionservers.sh stop n</em></li>
<li>web UI访问地址：<em><a href="http://ip:1630n" target="_blank" rel="external">http://ip:1630n</a></em></li>
</ul>
</li>
</ul>
<h2 id="三-基本操作"><a href="#三-基本操作" class="headerlink" title="三. 基本操作"></a>三. 基本操作</h2><blockquote>
<p>本节介绍使用HBase shell在直接在服务器上对HBase进行基本操作，HBase shell是在(J)Ruby的IRB的基础上增加了HBase特有的命令，遵循IRB的操作。</p>
</blockquote>
<ol>
<li>连接：<em>./bin/hbase shell</em><pre><code class="bash">[hbase@iZ25n0dx8rxZ hbase]$ ./bin/hbase shell
HBase Shell; enter &#39;help&lt;RETURN&gt;&#39; for list of supported commands.
Type &quot;exit&lt;RETURN&gt;&quot; to leave the HBase Shell
Version 1.2.2, r3f671c1ead70d249ea4598f1bbcc5151322b3a13, Fri Jul  1 08:28:55 CDT 2016
hbase(main):001:0&gt;
</code></pre>
</li>
<li><p>建表：<em>create ‘test’, ‘cf1’, ‘cf2’</em>，即[create ‘表名’, ‘列族名’,..]，列族名可以有多个，<em>list</em>用于查看有哪些表</p>
<pre><code class="bash">hbase(main):008:0&gt; create &#39;test&#39;,&#39;cf1&#39;,&#39;cf2&#39;
0 row(s) in 1.2280 seconds
=&gt; Hbase::Table - test
hbase(main):009:0&gt;
</code></pre>
</li>
<li><p>写数据：<em>put ‘test’, ‘row1’, ‘cf1:c1’, ‘value1’</em>，即[put ‘表名’,’行键’,’列族名:列名’,’数据’]</p>
<pre><code class="bash">hbase(main):001:0&gt; put &#39;test&#39;,&#39;row1&#39;,&#39;cf1:c1&#39;,&#39;value1&#39;
0 row(s) in 0.3160 seconds
hbase(main):002:0&gt; put &#39;test&#39;,&#39;row1&#39;,&#39;cf1:c1&#39;,&#39;value2&#39;
0 row(s) in 0.3020 seconds
</code></pre>
</li>
<li>查看数据：<ul>
<li>全表数据：<em>scan ‘test’</em>，即[scan ‘表名’]<pre><code class="bash">hbase(main):001:0&gt; scan &#39;test&#39;
ROW                                            COLUMN+CELL                                                                                                                             
row1                                          column=cf1:c1, timestamp=1469277197280, value=value2                                                                                    
1 row(s) in 0.2710 seconds
hbase(main):002:0&gt;
</code></pre>
可以看到在put时指定的属性之外，有一个<strong>timestamp</strong>属性来作为版本标识，我们查看全表数据时，row1的cf1:c1列中展示的值是我们后一次写入的value2，sacn和get在不指定版本时，得到的是最近版本的数据</li>
<li>指定行的数据：<em>get ‘test’, ‘row1’</em>，即[get ‘表名’,’行键’]</li>
<li>指定版本的数据：<pre><code class="bash">hbase(main):005:0&gt; get &#39;test&#39;,&#39;row1&#39;,{COLUMN=&gt;&#39;cf1:c1&#39;,TIMESTAMP=&gt;1469277197280}
COLUMN                                         CELL                                                                                                                                    
cf1:c1                                        timestamp=1469277197280, value=value1                                                                                                   
1 row(s) in 0.0270 seconds
hbase(main):006:0&gt;
</code></pre>
</li>
</ul>
</li>
<li><strong>版本数量</strong>：每个列族有一个单独的VERSIONS属性，默认为1，可以在建表时指定：<code>create &#39;test1&#39;,{NAME=&gt;&#39;cf1&#39;,VERSIONS=&gt;3}</code>，代表该列族的每个列最多保存最近3个版本的数据，也可以通过<em>alter</em>来更新：<code>alter &#39;test1&#39;,NAME=&gt;&#39;cf1&#39;,VERSIONS=&gt;3</code>。查询数据时，可以通过设置VERSIONS来指定显示最近几个版本的数据<em>(最大范围不超过该列族的VERSIONS属性值)</em>：<code>get &#39;test&#39;,&#39;row1&#39;,{COLUMN=&gt;&#39;cf1:c1&#39;,VERSIONS=&gt;2}</code></li>
<li>删除数据：<ul>
<li>删除指定单元格：<em>delete ‘test’,’row1’,’cf1:c1’,1469277197280</em>，<em>将删除指定版本以及比其更早的版本</em></li>
<li>删除指定行的指定列：<em>delete ‘test’,’row1’,’cf1:c1’</em></li>
<li>删除整行： <em>deleteall ‘test’,’row1’</em></li>
</ul>
</li>
<li>禁用表：<em>disable ‘test’</em>，即[disable ‘表名’]，在要删除表或者变更配置时，要先禁用该表。相应的，要重新启用该表，使用[enable ‘表名’]</li>
<li>删除表：<em>drop ‘test’</em>，即[drop ‘表名’]</li>
<li>退出HBase shell:<em>exit</em>或者<em>quit</em></li>
<li>完整的命令列表，参考<a href="https://learnhbase.wordpress.com/2013/03/02/hbase-shell-commands/" target="_blank" rel="external">hbase-shell-commands</a></li>
</ol>
<h2 id="四-尾声"><a href="#四-尾声" class="headerlink" title="四. 尾声"></a>四. 尾声</h2><p>本文简要介绍了HBase的数据模型、快速搭建基本操作环境的步骤以及基于HBase shell的HBase数据库基本操作，旨在协助想要学习HBase的朋友快速进入到对HBase的操作和使用阶段，消除陌生感和距离感。在这之后，我们可能想问，真正应用在工程上的操作HBase的方式有哪些，HBase存取数据的完整过程是怎样的，怎样去设计一个适合的表结构，等等，那么，请带着这些问题继续你的HBase之路。</p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p><a href="https://hbase.apache.org/book.html" target="_blank" rel="external">Apache HBase ™ Reference Guide</a><br><a href="http://research.google.com/archive/bigtable.html" target="_blank" rel="external">Google’s BigTable Paper</a><br><a href="http://jimbojw.com/wiki/index.php?title=Understanding_Hbase_and_BigTable" target="_blank" rel="external">Understanding HBase and BigTable</a></p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[JMeter性能测试3.0时代之-多维度的图形化HTML报告]]></title>
      <url>http://www.aloo.me/2016/07/17/JMeter%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%953-0%E6%97%B6%E4%BB%A3%E4%B9%8B-%E5%A4%9A%E7%BB%B4%E5%BA%A6%E7%9A%84%E5%9B%BE%E5%BD%A2%E5%8C%96HTML%E6%8A%A5%E5%91%8A/</url>
      <content type="html"><![CDATA[<p><img src="http://ww2.sinaimg.cn/large/9bd9d3e2gw1f5x232chyaj20b5096q3q.jpg" alt=""></p>
<blockquote>
<p>在上一篇博客<a href="http://www.aloo.me/2016/07/05/JMeter%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%953-0%E6%97%B6%E4%BB%A3%E4%B9%8B-%E5%85%A8%E6%96%B0JMeter%E6%8F%92%E4%BB%B6%E7%AE%A1%E7%90%86/">JMeter性能测试3.0时代之-全新JMeter插件管理</a>中我说会写真正的JMeter 3.0新特性，时隔两周，总算在这个周末，暂停其他安排，来继续这个未完成的系列。<br>本文主要介绍JMeter3.0引入的新特性：<a href="https://jmeter.apache.org/usermanual/generating-dashboard.html" target="_blank" rel="external">Dashboard Report</a>，图形化的HTML格式多维度测试报告。借助这个特性，可以很大程度上降低我们搭建基于JMeter的性能测试平台时，在结果展示上的难度，将更多的精力放在后端的平台功能而不是去临时学习前端图表库。</p>
</blockquote>
<a id="more"></a>
<h2 id="一-为什么谈这个新特性"><a href="#一-为什么谈这个新特性" class="headerlink" title="一.为什么谈这个新特性"></a>一.为什么谈这个新特性</h2><p>在JMeter3.0之前，官方只提供在工具的UI上对测试结果部分维度的图形化展示，这对我带来了两方面的困扰：</p>
<ol>
<li>在实际使用中，在平台中集成JMeter后需要页面展示TPS曲线，平均响应时间曲线等图表时，需要我们手动操刀摆弄如Hightcharts/Echarts等前端图表库。</li>
<li>要查看历史的测试结果，需要启动JMeter的图形化界面，导入保存的CSV结果，过程繁琐，并且当结果集较大时，JMeter需要耗费相当多的时间在界面上展示图形化报告。</li>
</ol>
<p>本文讨论的新特性为这两个问题带来了较好的解决办法：</p>
<ul>
<li>新特性良好的实现了结果数据可视化，生成的报告是HTML页面形式，并且包含大多数实际测试中关心的度量维度的，可以便捷地嵌入到平台，从浏览器来查看每次测试运行的。</li>
<li>只要保留生成的HTML页面，后期要查看该次测试的结果，只需要在浏览器打开即可，方便快捷。</li>
</ul>
<h2 id="二-新特性简介"><a href="#二-新特性简介" class="headerlink" title="二.新特性简介"></a>二.新特性简介</h2><p>JMeter3.0提供一个用于生成<strong>HTML页面格式图形化报告</strong>的扩展模块。该模块支持通过两种方式生成多维度图形化测试报告：</p>
<ol>
<li>在JMeter性能测试结束时，自动生成本次测试的HTML图形化报告</li>
<li>使用一个已有的结果文件(如CSV文件)来生成该次结果的HTML图形化报告</li>
</ol>
<p><strong>其默认提供的度量维度包括：</strong></p>
<ol>
<li>APDEX(Application Performance Index)指数</li>
<li>聚合报告<ul>
<li>类似于UI上的<em>Aggregate Report</em></li>
</ul>
</li>
<li>Errors报告<ul>
<li>展示不同错误类型的数量以及百分比</li>
</ul>
</li>
<li>响应时间变化曲线<ul>
<li>展示平均响应时间随时间变化情况</li>
<li>类似于JMeter Plugins在UI上的<em>jp@gc - Response Times Over Time</em></li>
</ul>
</li>
<li>数据吞吐量时间曲线<ul>
<li>展示每秒数据吞吐量随时间变化的情况</li>
<li>类似于JMeter Plugins在UI上的<em>jp@gc - Bytes Throughput Over Time</em></li>
</ul>
</li>
<li>Latency time变化曲线<ul>
<li>展示Latency time随时间变化的情况</li>
<li>类似于JMeter Plugins在UI上的<em>jp@gc - Response Latencies Over Time</em></li>
</ul>
</li>
<li>每秒点击数曲线<ul>
<li>类似于JMeter Plugins在UI上的<em>jp@gc - Hits per Second</em></li>
</ul>
</li>
<li>HTTP状态码时间分布曲线<ul>
<li>展示响应状态码随时间的分布情况</li>
<li>类似于JMeter Plugins在UI上的<em>jp@gc - Response Codes per Second</em></li>
</ul>
</li>
<li>事务吞吐量时间曲线(TPS)<ul>
<li>展示每秒处理的事务数随时间变化情况</li>
<li>类似于JMeter Plugins在UI上的<em>jp@gc - Transactions per Second</em></li>
</ul>
</li>
<li>平均响应时间与每秒请求数的关系图<ul>
<li>展示平均响应时间与每秒请求数(可以理解为QPS)的关系</li>
</ul>
</li>
<li>Latency time与每秒请求数的关系图<ul>
<li>展示Latency time与每秒请求数的关系</li>
</ul>
</li>
<li>响应时间百分位图<ul>
<li>响应时间的百分位分布图</li>
</ul>
</li>
<li>活动线程数变化曲线<ul>
<li>展示测试过程中活动线程数随时间变化情况</li>
</ul>
</li>
<li>平均响应时间与线程数的关系图<ul>
<li>展示平均响应时间与线程数的关系</li>
<li>类似于JMeter Plugins在UI上的<em>jp@gc - Response Times vs Threads</em></li>
</ul>
</li>
<li>柱状响应时间分布图<ul>
<li>展示落在各个平均响应时间区间的请求数情况</li>
</ul>
</li>
</ol>
<p><em>注1：Latency time没有翻译成中文，这里对其计算方式做注解：</em><br>    <em>Latency time = 接收到响应的第一个字节的时间点 - 请求开始发送的时间点</em></p>
<blockquote>
<p> <em>from just before sending the request to just after the first response has been received</em><br>– <a href="http://jmeter.apache.org/usermanual/glossary.html" target="_blank" rel="external">Apache JMeter Glossary</a></p>
</blockquote>
<p>  <em>响应时间(JMeter术语中的Elapsed time) = 接收完所有响应内容的时间点 - 请求开始发送的时间点</em></p>
<blockquote>
<p><em>from just before sending the request to just after the last response has been received</em><br>– <a href="http://jmeter.apache.org/usermanual/glossary.html" target="_blank" rel="external">Apache JMeter Glossary</a></p>
</blockquote>
<p><em>注2：Apdex 标准从用户的角度出发，将对应用响应时间的表现，转为用户对于应用性能的可量化为范围为 0-1 的满意度评价。。</em></p>
<blockquote>
<p><strong>Apdex (Application Performance Index)</strong> is an open standard developed by an alliance of companies. It defines a standard method for reporting and comparing the performance of software applications in computing.<br>– <a href="https://en.wikipedia.org/wiki/Apdex" target="_blank" rel="external">wikipedia</a></p>
</blockquote>
<h2 id="三-快速入门"><a href="#三-快速入门" class="headerlink" title="三.快速入门"></a>三.快速入门</h2><h3 id="1-确认基本配置"><a href="#1-确认基本配置" class="headerlink" title="1.确认基本配置"></a>1.确认基本配置</h3><ul>
<li>在jmeter.properties或者user.properties确认如下配置项：<pre><code class="xml">jmeter.save.saveservice.bytes = true
jmeter.save.saveservice.label = true
jmeter.save.saveservice.latency = true
jmeter.save.saveservice.response_code = true
jmeter.save.saveservice.response_message = true
jmeter.save.saveservice.successful = true
jmeter.save.saveservice.thread_counts = true
jmeter.save.saveservice.thread_name = true
jmeter.save.saveservice.time = true
# the timestamp format must include the time and should include the date.
# For example the default, which is milliseconds since the epoch: 
jmeter.save.saveservice.timestamp_format = ms
# Or the following would also be suitable
jmeter.save.saveservice.timestamp_format = yyyy/MM/dd HH:mm:ss
</code></pre>
</li>
<li>如果希望在Errors报告中展示更详细数据，需要确保如下配置<ul>
<li><code>jmeter.save.saveservice.assertion_results_failure_message = true</code></li>
<li>如果使用了事务控制器(Transaction Controller)，确认<em>Generate parent sample</em>为未勾选状态</li>
</ul>
</li>
</ul>
<h3 id="2-生成报告"><a href="#2-生成报告" class="headerlink" title="2.生成报告"></a>2.生成报告</h3><p>a. 在压力测试结束时报告</p>
<ul>
<li>基本命令格式：<br><code>jmeter -n -t &lt;test JMX file&gt; -l &lt;test log file&gt; -e -o &lt;Path to output folder&gt;</code></li>
<li>样例：<br><code>jmeter -n -t F:\PerformanceTest\TestCase\script\getToken.jmx -l testLogFile -e -o ./output</code></li>
</ul>
<p>b. 使用已有的压力测试CSV日志文件生成报告</p>
<ul>
<li>基本命令格式：<br><code>jmeter -g &lt;log file&gt; -o &lt;Path to output folder&gt;</code></li>
<li>样例：<br><code>jmeter -g D:\apache-jmeter-3.0\bin\testLogFile -o ./output</code></li>
</ul>
<p>两个样例都会在\apache-jmeter-3.0\bin\output目录下产生如下文件(夹):<br><img src="http://ww3.sinaimg.cn/large/9bd9d3e2gw1f5x043a8xuj20if03vdgd.jpg" alt=""></p>
<p>用浏览器打开index.html文件，即可查看各种图形化报告:<br><img src="http://ww4.sinaimg.cn/large/9bd9d3e2gw1f5x04glvcqj20ki0cm3zr.jpg" alt=""><br><img src="http://ww3.sinaimg.cn/large/9bd9d3e2gw1f5x0ao5dkjj212u0fqjvr.jpg" alt=""></p>
<h2 id="四-自定义配置"><a href="#四-自定义配置" class="headerlink" title="四.自定义配置"></a>四.自定义配置</h2><p>JMeter3.0在bin目录新增了<code>reportgenerator.properties</code>文件保存了所有关于图形化HTML报告生成模块的默认配置，要变更配置，建议不要直接编辑该文件，而是推荐在<code>user.properties</code>中去配置和覆盖。</p>
<h3 id="1-总体配置"><a href="#1-总体配置" class="headerlink" title="1.总体配置"></a>1.总体配置</h3><p>总体配置都是以<code>jmeter.reportgenerator.</code>为前缀。如：jmeter.reportgenerator.overall_granularity=60000</p>
<ul>
<li><code>overall_granularity</code>：定义采样点粒度，默认为60000ms，通常在稳定性以外的测试中，我们可能需要定义更细的粒度，比如1000ms，我们可以在<code>user.properties</code>文件末尾添加如下配置：<pre><code class="xml"># Change this parameter if you want to change the granularity of over time graphs.
jmeter.reportgenerator.overall_granularity=6000
</code></pre>
</li>
<li><code>report_title</code>:定义报告的标题，我们可能需要将标题定义为实际测试项名称</li>
<li><code>apdex_satisfied_threshold</code>：定义Apdex评估中<strong>满意</strong>的阈值(单位ms)</li>
<li><code>apdex_tolerated_threshold</code>: 定义Apdex评估中<strong>可容忍</strong>的阈值<br><code>Apdext = (Satisfied Count + Tolerating Count / 2) / Total Samples</code></li>
</ul>
<p>另外，在<code>jmeter.properties</code>中，有关于集合报告中的三个百分位的默认值：</p>
<pre><code class="xml">aggregate_rpt_pct1 : Defaults to 90
aggregate_rpt_pct2 : Defaults to 95
aggregate_rpt_pct3 : Defaults to 99
</code></pre>
<p>可以在<code>user.properties</code>中对其进行覆盖，如：<code>aggregate_rpt_pct1 = 70</code>，效果如下：<br><img src="http://ww3.sinaimg.cn/large/9bd9d3e2gw1f5x04h6f3dj20bl06cq3b.jpg" alt=""></p>
<h3 id="2-图表配置"><a href="#2-图表配置" class="headerlink" title="2.图表配置"></a>2.图表配置</h3><p>每个图表配置都是以<code>jmeter.reportgenerator.graph.&lt;图表名称&gt;.</code>为前缀。</p>
<ul>
<li><code>classname</code> 图表的实现类，如果有自己定制的实现，将该配置的值写为自定义实现类的类名</li>
<li><code>title</code> 图标标题，比如要汉化的时候，在这里配置中文标题</li>
<li><code>property.set_granularity</code> 设置图标的采样点粒度，不配置时默认使用总体配置中的粒度设置</li>
</ul>
<h3 id="3-输出配置"><a href="#3-输出配置" class="headerlink" title="3.输出配置"></a>3.输出配置</h3><p>输出配置都以<code>jmeter.reportgenerator.exporter</code>为前缀。</p>
<ul>
<li><code>property.output_dir</code> 配置默认的报告输出路径。在命令行可以用-o选项来设置特定的路径覆盖该配置。</li>
<li><code>html.series_filter</code> 用于过滤展示内容。如在user.properties添加如下配置：<br><code>jmeter.reportgenerator.exporter.html.series_filter=(^Login)(-success|-failure)?</code><br>则最后的报告只展示名为Login这个取样器的数据。该配置包含两部分，<code>(-success|-failure)?</code>是<code>Transactions per second</code>图表所依赖的配置。前面部分接受一个正则表达式用来过滤。</li>
</ul>
<h2 id="五-总结"><a href="#五-总结" class="headerlink" title="五.总结"></a>五.总结</h2><p>本次介绍的<code>Dashboard Report</code>特性本质上是Apache JMeter对于测试结果数据可视化方式的顺应时代的更新，虽然算是姗姗来迟，虽然并不酷炫，但至少，对于要需要基于它来执行性能测试的人来说，仍然是一个福音。最后，感谢Apache JMeter项目的各位贡献者对它的持续更新。</p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol>
<li><a href="http://jmeter.apache.org/usermanual/generating-dashboard.html" target="_blank" rel="external">Apache JMeter Dashboard Report</a></li>
<li><a href="http://jmeter.apache.org/usermanual/glossary.html" target="_blank" rel="external">Apache JMeter Glossary</a></li>
</ol>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Dubbo高级特性实践-泛化调用]]></title>
      <url>http://www.aloo.me/2016/07/10/Dubbo%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7%E5%AE%9E%E8%B7%B5-%E6%B3%9B%E5%8C%96%E8%B0%83%E7%94%A8/</url>
      <content type="html"><![CDATA[<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>当后端Java服务用<a href="http://dubbo.io/" target="_blank" rel="external">Dubbo</a>协议作为RPC方案的基础，但部分消费方是前端Restful的PHP服务，不能直接调用，于是在中间架设了Router服务提供统一的基于HTTP的后端调用入口。<br>而Router调用后端Java服务就应用了Dubbo的高级特性–<strong>泛化调用</strong></p>
<ul>
<li>直接消费方(Router服务)不需要引入接口jar包</li>
<li>通过GenericService接口来处理所有服务请求</li>
<li>以PHP到Router的request body中的方法名和方法参数作为Router远程调用后端Java服务的入参，最后将远程调用的result返回给PHP端</li>
</ul>
<p>本文将用一个小Demo来演示上面所述的<strong>泛化调用</strong>应用场景</p>
<a id="more"></a>
<h2 id="零-Dubbo简介"><a href="#零-Dubbo简介" class="headerlink" title="零.Dubbo简介"></a>零.Dubbo简介</h2><blockquote>
<p><em>DUBBO是一个分布式服务框架，致力于提供高性能和透明化的RPC远程服务调用方案，是阿里巴巴SOA服务化治理方案的核心框架，每天为2,000+个服务提供3,000,000,000+次访问量支持，并被广泛应用于阿里巴巴集团的各成员站点。</em><br>– Dubbo官方描述</p>
<h3 id="Dubbo能做什么："><a href="#Dubbo能做什么：" class="headerlink" title="Dubbo能做什么："></a><em>Dubbo能做什么：</em></h3><ul>
<li>透明化的远程方法调用 <ul>
<li>就像调用本地方法一样调用远程方法</li>
<li>只需简单配置，没有任何API侵入。 </li>
</ul>
</li>
<li>软负载均衡及容错机制<ul>
<li>可在内网替代F5等硬件负载均衡器</li>
</ul>
</li>
<li>服务自动注册与发现<ul>
<li>不再需要写死服务提供方地址，注册中心基于接口名查询服务提 供者的IP地址，并且能够平滑添加或删除服务提供者 </li>
</ul>
</li>
</ul>
<p>– 《Dubbo功能介绍》(<em>官方资料</em>)</p>
</blockquote>
<p><em>注：Dubbo的基本使用介绍不在本文范畴，如有需要请自行参考<a href="http://dubbo.io/" target="_blank" rel="external">官方资料</a></em></p>
<blockquote>
<p><em>泛接口调用方式主要用于客户端没有API接口及模型类元的情况，参数及返回值中的所有POJO均用Map表示，通常用于框架集成，比如：实现一个通用的服务测试框架，可通过GenericService调用所有服务实现。</em><br>– Dubbo用户指南</p>
</blockquote>
<h2 id="一-后端API"><a href="#一-后端API" class="headerlink" title="一.后端API"></a>一.后端API</h2><pre><code class="java">public interface UserInfoService {
    public Map&lt;String, String&gt; getUser(String id);
    public Map&lt;String, String&gt;[] getUsers();
}
</code></pre>
<h2 id="二-Router端dubbo配置"><a href="#二-Router端dubbo配置" class="headerlink" title="二.Router端dubbo配置"></a>二.Router端dubbo配置</h2><p><code>dubboconf.properties:</code></p>
<pre><code>application.name=router
registry.address=zookeeper://address1?buckup=address2,address3
</code></pre><h2 id="三-前端服务post到Router的Request-Body示例："><a href="#三-前端服务post到Router的Request-Body示例：" class="headerlink" title="三.前端服务post到Router的Request Body示例："></a>三.前端服务post到Router的Request Body示例：</h2><pre><code class="json">{
    &quot;interfaceName&quot;: &quot;foo&quot;, 
    &quot;methodName&quot;: &quot;bar&quot;, 
    &quot;methodParams&quot;: [
        {
            &quot;id&quot;: &quot;xxx&quot;
        }
    ]
}
</code></pre>
<h2 id="四-处理前端参数用的Dto"><a href="#四-处理前端参数用的Dto" class="headerlink" title="四.处理前端参数用的Dto"></a>四.处理前端参数用的Dto</h2><p><code>RequestDto.java:</code></p>
<pre><code class="java">import java.util.Map;
/**
 * Created by Luo
 */
public class RequestDto {
    private String interfaceName;
    private String methodName
    private Map[] methodParams;

    public String getInterfaceName() {
        return interfaceName;
    }
    public void setInterfaceName(String interfaceName) {
        this.interfaceName =  interfaceName;
    }
    public String getMethodName() {
        return methodName;
    }
    public void setMethodName(String methodName) {
        this.methodName = methodName;
    }
    public Map[] getMethodParams() {
        return methodParams;
    }
    public void setMethodParam(Map[] methodParams) {
        this.methodParams = methodParams;
    }
}
</code></pre>
<h2 id="五-Router服务入口"><a href="#五-Router服务入口" class="headerlink" title="五.Router服务入口"></a>五.Router服务入口</h2><p><code>RouterController.java:</code></p>
<pre><code class="java">import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.web.bind.annotation.*;

import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;

/**
 * Created by Luo
 */
@RestController
public class App {
        @RequestMapping(value = &quot;/router/&quot;, method = RequestMethod.POST)
        public Object getUser(@ModelAttribute RequestDto dto) {
            Map map = new HashMap&lt;&gt;();
            map.put(&quot;ParamType&quot;, &quot;java.lang.String&quot;);  //后端接口参数类型
            map.put(&quot;Object&quot;, dto.getMethodParams()[0].get(&quot;id&quot;));  //用以调用后端接口的实参

            List&lt;Map&lt;String, Object&gt;&gt; paramInfos= new ArrayList&lt;&gt;();
            paramInfos.add(map);

            DubboServiceFactory dubbo = DubboServiceFactory.getInstance();

            return dubbo.genericInvoke(dto.getInterfaceName(), dto.getMethodName(), paramInfos);
        }
}
</code></pre>
<p><em>注：本文旨在演示泛化调用的一种应用方式，为简明起见，代码中直接从dto中获取了指定参数，而并没有完整实现其路由功能，望见谅。</em></p>
<h2 id="六-通过GenericService进行泛化调用"><a href="#六-通过GenericService进行泛化调用" class="headerlink" title="六.通过GenericService进行泛化调用"></a>六.通过GenericService进行泛化调用</h2><p><code>DubboServiceFactory.java</code></p>
<pre><code class="java">package local.demo.genericservice;

import com.alibaba.dubbo.config.ApplicationConfig;
import com.alibaba.dubbo.config.ReferenceConfig;
import com.alibaba.dubbo.config.RegistryConfig;
import com.alibaba.dubbo.config.utils.ReferenceConfigCache;
import com.alibaba.dubbo.rpc.service.GenericService;


import java.io.IOException;
import java.util.List;
import java.util.Map;
import java.util.Properties;

/**
 * Created by Luo
 */
public class DubboServiceFactory {

    private ApplicationConfig application;
    private RegistryConfig registry;

    private static class SingletonHolder {
        private static DubboServiceFactory INSTANCE = new DubboServiceFactory();
    }

    private DubboServiceFactory(){
        Properties prop = new Properties();
        ClassLoader loader = DubboServiceFactory.class.getClassLoader();

        try {
            prop.load(loader.getResourceAsStream(&quot;dubboconf.properties&quot;));
        } catch (IOException e) {
            e.printStackTrace();
        }

        ApplicationConfig applicationConfig = new ApplicationConfig();
        applicationConfig.setName(prop.getProperty(&quot;application.name&quot;)); 
        //这里配置了dubbo的application信息*(demo只配置了name)*，因此demo没有额外的dubbo.xml配置文件
        RegistryConfig registryConfig = new RegistryConfig();
        registryConfig.setAddress(prop.getProperty(&quot;registry.address&quot;)); 
        //这里配置dubbo的注册中心信息，因此demo没有额外的dubbo.xml配置文件

        this.application = applicationConfig;
        this.registry = registryConfig;

    }

    public static DubboServiceFactory getInstance() {
        return SingletonHolder.INSTANCE;
    }

    public Object genericInvoke(String interfaceClass, String methodName, List&lt;Map&lt;String, Object&gt;&gt; parameters){

        ReferenceConfig&lt;GenericService&gt; reference = new ReferenceConfig&lt;GenericService&gt;();
        reference.setApplication(application); 
        reference.setRegistry(registry); 
        reference.setInterface(interfaceClass); // 接口名 
        reference.setGeneric(true); // 声明为泛化接口 

        //ReferenceConfig实例很重，封装了与注册中心的连接以及与提供者的连接，
        //需要缓存，否则重复生成ReferenceConfig可能造成性能问题并且会有内存和连接泄漏。
        //API方式编程时，容易忽略此问题。
        //这里使用dubbo内置的简单缓存工具类进行缓存

        ReferenceConfigCache cache = ReferenceConfigCache.getCache();
        GenericService genericService = cache.get(reference); 
        // 用com.alibaba.dubbo.rpc.service.GenericService可以替代所有接口引用 

        int len = parameters.size();
        String[] invokeParamTyeps = new String[len];
        Object[] invokeParams = new Object[len];
        for(int i = 0; i &lt; len; i++){
            invokeParamTyeps[i] = parameters.get(i).get(&quot;ParamType&quot;) + &quot;&quot;;
            invokeParams[i] = parameters.get(i).get(&quot;Object&quot;);
        }
        return genericService.$invoke(methodName, invokeParamTyeps, invokeParams);
    }

}
</code></pre>
<h2 id="七-部署"><a href="#七-部署" class="headerlink" title="七.部署"></a>七.部署</h2><p>将Router部署到Jetty/Tomcat等容器，或者直接使用<a href="http://projects.spring.io/spring-boot/" target="_blank" rel="external">SpringBoot</a>开发，发布为内嵌Jetty/Tomcat的独立jar包，即可向前端服务提供服务。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[JMeter性能测试3.0时代之-全新JMeter插件管理]]></title>
      <url>http://www.aloo.me/2016/07/05/JMeter%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%953-0%E6%97%B6%E4%BB%A3%E4%B9%8B-%E5%85%A8%E6%96%B0JMeter%E6%8F%92%E4%BB%B6%E7%AE%A1%E7%90%86/</url>
      <content type="html"><![CDATA[<blockquote>
<p>今年五月，老牌开源性能测试工具<a href="http://jmeter.apache.org/" target="_blank" rel="external">Apache JMeter</a>迎来了自2011年11月成为Apache顶级项目以来的首次大版本更新–从2.13更新到3.0。<br>这对于广大JMeter用户来说无疑是一个好消息，它让我们看到了这个项目的活力。也是因此，打算写一些自己感受到的JMeter近来的变化。</p>
</blockquote>
<a id="more"></a>
<h2 id="JMeter"><a href="#JMeter" class="headerlink" title="JMeter"></a>JMeter</h2><p><a href="http://jmeter.apache.org/" target="_blank" rel="external">JMeter</a>，老牌，开源，轻量，Apache基金会的顶级项目，光是这些关键字就足以让大量用户将其纳入自己的性能测试工具箱。而从实际看来，其在国内的用户数量，足以和著名的LoadRunner分庭抗礼，甚至在如今的互联网浪潮下，其覆盖范围可能已经超越了LR，甚至在其他领域，如接口测试，也能看到JMeter的身影。对于这样的发展趋势，我也非常乐意看到，因为我最初做性能测试时，选择了使用JMeter作为主力工具。</p>
<p>然而最近两年，JMeter并没有太多值得关注的更新。虽然现在的我已经不再是性能测试的萌新，不会被一个工具所制约，但是作为帮助我入门的工具，还是希望能够看到一个更活跃的JMeter，更活跃的JMeter生态。</p>
<p>今年夏天，首先得到的好消息是JMeter迎来了它的3.0版本，其中一个重要的更新就是HTML页面形式的性能测试报告，这一方面它终于是赶上了<a href="http://gatling.io/#/" target="_blank" rel="external">Gatling</a>(<em>关注Gatling主要因为两方面：一是其甩JMeter几条街的性能，二就是其出色的report</em>)。</p>
<p>然而今天这篇文章并不是讲JMeter 3.0的新特性(<em>废话半天竟然又不讲这，我自己都醉了。主要是由于时间不够，3.0的新特性，计划放到下一篇文章</em>)，今天要提的是第二个消息，不是来自于JMeter自身，而是<strong>JMeter Plugins</strong>。</p>
<h2 id="JMeter-Plugins"><a href="#JMeter-Plugins" class="headerlink" title="JMeter Plugins"></a>JMeter Plugins</h2><p>一直以来，<a href="http://www.jmeter-plugins.org/" target="_blank" rel="external">JMeter Plugins</a>为我们提供了很多高价值的JMeter插件，比如:</p>
<ul>
<li>用于服务器性能监视的<a href="http://jmeter-plugins.org/wiki/PerfMon" target="_blank" rel="external">PerfMon Metrics Collector</a></li>
<li>用于建立压力变化模型的<a href="http://jmeter-plugins.org/wiki/SteppingThreadGroup" target="_blank" rel="external">Stepping Thread Group</a></li>
<li>用于Json解析的<a href="http://jmeter-plugins.org/wiki/JSONPathExtractor" target="_blank" rel="external">JSON Path Extractor</a></li>
<li>用于展示响应时间曲线的<a href="http://jmeter-plugins.org/wiki/ResponseTimesOverTime" target="_blank" rel="external">Response Times Over Time</a></li>
<li>用于展示TPS曲线的<a href="http://jmeter-plugins.org/wiki/TransactionsPerSecond" target="_blank" rel="external">Transactions per Second</a><br>非常感谢这些插件的贡献者很大程度上丰富了JMeter的生态，并直接造福了广大的JMeter使用者。</li>
</ul>
<p>在以前，这些插件的安装还是一个纯手工的方式：所有插件分为四个集合包，首先需要找到包含目标功能的集合包-下载该依赖包-拷贝的合适的路径-重启JMeter。这样的过程对于刚接触JMeter的新人来说，可能稍显繁琐。</p>
<h2 id="Plugins-Manager"><a href="#Plugins-Manager" class="headerlink" title="Plugins Manager"></a>Plugins Manager</h2><p>值得高兴的是，最近，<strong>jmeter-plugins.org</strong>推出了全新的<a href="http://www.jmeter-plugins.org/wiki/PluginsManager/" target="_blank" rel="external">Plugins Manager</a>，对于其提供的插件进行了集中的管理，我们只需要安装这个管理插件，即可以在JMeter的界面上搜索并安装指定的插件。简要步骤如下：</p>
<ol>
<li>下载管理插件的<a href="http://jmeter-plugins.org/get/" target="_blank" rel="external">JAR文件</a></li>
<li>将下载的文件拷贝的你的JMeter根目录下的<code>lib/ext</code>目录</li>
<li>启动JMeter，点击<code>菜单栏</code>-<code>Options</code>-<code>Plugins Manager</code>,如<code>图1</code>：</li>
</ol>
<p><img src="http://ww1.sinaimg.cn/large/9bd9d3e2gw1f5otxp1yk8j20c908675n.jpg" alt="图1"></p>
<ol>
<li>在如<code>图2</code>的管理页面进行插件管理，共有三个标签页:</li>
</ol>
<p><img src="http://ww2.sinaimg.cn/large/9bd9d3e2gw1f5otxpd97mj20hr07qjtn.jpg" alt="图2"></p>
<ul>
<li>Installed Plugins：顾名思义，是用于查看已安装的插件，并可通过<code>取消勾选</code>-<code>应用操作</code>来卸载插件</li>
<li>Available Plugins:用于查看和安装可用的插件</li>
<li>Upgrades:用于升级插件</li>
</ul>
<p>另外，Plugins Manager还提供了命令行安装的支持，具体参见<a href="http://jmeter-plugins.org/wiki/PluginsManager/" target="_blank" rel="external">官方wiki</a>，以便让在Linux上或者以NO-GUI方式在windows运行的使用者也能快捷的进行JMeter插件管理。</p>
<p>最后，快快去体验一下吧 : )</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[正确、安全地停止SpringBoot应用]]></title>
      <url>http://www.aloo.me/2016/06/27/%E6%AD%A3%E7%A1%AE%E3%80%81%E5%AE%89%E5%85%A8%E5%9C%B0SpringBoot%E5%BA%94%E7%94%A8/</url>
      <content type="html"><![CDATA[<p><img src="http://ww4.sinaimg.cn/large/9bd9d3e2gw1f5bxlcc3o9j20nz0b7t8t.jpg" alt=""></p>
<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p><a href="http://projects.spring.io/spring-boot/" target="_blank" rel="external">Spring Boot</a>，作为Spring框架对“约定优先于配置(Convention Over Configuration)”理念的最佳实践的产物，它能帮助我们很快捷的创建出独立运行、产品级别的基于Spring框架的应用，大部分Spring Boot应用只需要非常少的配置就可以快速运行起来，是一个与微服务(MicroServices)相当契合的微框架。<br>网络上关于Spring Boot的QuickStart式中文内容已经相当丰富，但是对于部署后怎样便捷、安全地停止服务(shutdown)，还比较缺乏，最近发现Spring Boot的官方指南更新了相关内容，因此结合该部分更新，对如何<strong>基于官方提供的特性</strong>正确地停止Spring Boot应用进行简单说明。</p>
<p>主要有两种方式：通过<code>HTTP</code>发送<code>shutdown</code>信号，或者通过<code>service stop</code>的方式<br><a id="more"></a></p>
<h2 id="方式一：通过HTTP发送shutdown信号"><a href="#方式一：通过HTTP发送shutdown信号" class="headerlink" title="方式一：通过HTTP发送shutdown信号"></a>方式一：通过<code>HTTP</code>发送<code>shutdown</code>信号</h2><p>该方式主要依赖<code>Spring Boot Actuator</code>的<code>endpoint</code>特性，具体步骤如下：</p>
<h3 id="1-在pom-xml中引入actuator依赖"><a href="#1-在pom-xml中引入actuator依赖" class="headerlink" title="1. 在pom.xml中引入actuator依赖"></a>1. 在<code>pom.xml</code>中引入<code>actuator</code>依赖</h3><pre><code>&lt;dependency&gt;
  &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
  &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre><h3 id="2-开启shutdown-endpoint"><a href="#2-开启shutdown-endpoint" class="headerlink" title="2. 开启shutdown endpoint"></a>2. 开启<code>shutdown endpoint</code></h3><p>  <code>Spring Boot Actuator</code>的<code>shutdown endpoin</code>t默认是关闭的，因此在<code>application.properties</code>中开启<code>shutdown endpoint</code>：</p>
<pre><code>#启用shutdown
endpoints.shutdown.enabled=true
#禁用密码验证
endpoints.shutdown.sensitive=false
</code></pre><h3 id="3-发送shutdown信号"><a href="#3-发送shutdown信号" class="headerlink" title="3. 发送shutdown信号"></a>3. 发送<code>shutdown</code>信号</h3><p>  <code>shutdown</code>的默认<code>url</code>为<code>host:port/shutdown</code>，当需要停止服务时，向服务器<code>post</code>该请求即可，如：<br><code>curl -X POST host:port/shutdown</code><br>将得到形如<code>{&quot;message&quot;:&quot;Shutting down, bye...&quot;}</code>的响应</p>
<h3 id="4-安全设置"><a href="#4-安全设置" class="headerlink" title="4. 安全设置"></a>4. 安全设置</h3><p>可以看出，使用该方法可以非常方便的进行远程操作，但是需要注意的是，正式使用时，必须对该请求进行必要的安全设置，比如借助<code>spring-boot-starter-security</code>进行身份认证：</p>
<ol>
<li>pom.xml添加security依赖<pre><code>&lt;dependency&gt;
 &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
 &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre></li>
<li>开启安全验证<br>在<code>application.properties</code>中变更配置,并<pre><code>#开启shutdown的安全验证
endpoints.shutdown.sensitive=true
#验证用户名
security.user.name=admin
#验证密码
security.user.password=secret
#角色
management.security.role=SUPERUSER
</code></pre></li>
<li>指定路径、IP、端口<pre><code>#指定shutdown endpoint的路径
endpoints.shutdown.path=/custompath
#也可以统一指定所有endpoints的路径`management.context-path=/manage`
#指定管理端口和IP
management.port=8081
management.address=127.0.0.1
</code></pre></li>
</ol>
<h2 id="方式二：部署为Unix-Linux-Service"><a href="#方式二：部署为Unix-Linux-Service" class="headerlink" title="方式二：部署为Unix/Linux Service"></a>方式二：部署为Unix/Linux Service</h2><p>该方式主要借助官方的<code>spring-boot-maven-plugin</code>创建”Fully executable” jar ，这中jar包内置一个shell脚本，可以方便的将该应用设置为Unix/Linux的系统服务(init.d service),官方对该功能在CentOS和Ubuntu进行了测试，对于OS X和FreeBSD,可能需要自定义。具体步骤如下:</p>
<h3 id="1-在pom-xml中引入插件："><a href="#1-在pom-xml中引入插件：" class="headerlink" title="1. 在pom.xml中引入插件："></a>1. 在<code>pom.xml</code>中引入插件：</h3><pre><code>&lt;plugin&gt;
  &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
  &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;
  &lt;configuration&gt;
    &lt;executable&gt;true&lt;/executable&gt;
  &lt;/configuration&gt;
&lt;/plugin&gt;
</code></pre><h3 id="2-设置为系统服务"><a href="#2-设置为系统服务" class="headerlink" title="2. 设置为系统服务"></a>2. 设置为系统服务</h3><p>  将你的应用打成jar包，部署到服务器，假设部署路径为/var/app，包名为app.jar，通过如下方式将应该设置为一个系统服务：<br><code>sudo ln -s /var/app/app.jar /etc/init.d/app</code></p>
<h3 id="3-赋予可执行权限："><a href="#3-赋予可执行权限：" class="headerlink" title="3. 赋予可执行权限："></a>3. 赋予可执行权限：</h3><p><code>chmod u+x app.jar</code></p>
<h3 id="4-以系统服务的方式管理"><a href="#4-以系统服务的方式管理" class="headerlink" title="4. 以系统服务的方式管理"></a>4. 以系统服务的方式管理</h3><p>  接下来，就可以使用我们熟悉的service foo start|stop|restart来对应用进行启停等管理了<br><code>sudo service app start|stop</code><br>命令将得到形如<code>Started|Stopped [PID]</code>的结果反馈</p>
<p>默认PID文件路径：/var/run/appname/appname.pid<br>默认日志文件路径：/var/log/appname.log</p>
<p>这可能是我们更熟悉也更常用的管理方式。</p>
<h3 id="自定义参数"><a href="#自定义参数" class="headerlink" title="自定义参数"></a>自定义参数</h3><p>在这种方式下，我们还可以使用自定义的.conf文件来变更默认配置，方法如下：</p>
<ol>
<li>在jar包相同路径下创建一个.conf文件，名称应该与.jar的名称相同，如appname.conf</li>
<li>在其中配置相关变量，如：<pre><code>JAVA_HOME=/usr/local/jdk
JAVA_OPTS=-Xmx1024M
LOG_FOLDER=/custom/log
</code></pre></li>
</ol>
<h3 id="安全设置"><a href="#安全设置" class="headerlink" title="安全设置"></a>安全设置</h3><p>作为应用服务，安全性是一个不能忽略的问题，如下一些操作可以作为部分基础设置参考：</p>
<ul>
<li>为服务创建一个独立的用户，同时最好将该用户的shell绑定为/usr/sbin/nologin</li>
<li>赋予最小范围权限：<code>chmod 500 app.jar</code></li>
<li>阻止修改：<code>sudo chattr +i app.jar</code></li>
<li>对.conf文件做类似的工作：<code>chmod 400 app.conf</code>,<code>sudo chown root:root app.conf</code></li>
</ul>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol>
<li><a href="http://docs.spring.io/spring-boot/docs/current/reference/html/deployment-install.html" target="_blank" rel="external">Installing Spring Boot applications</a></li>
<li><a href="http://docs.spring.io/spring-boot/docs/current/reference/html/production-ready-enabling.html" target="_blank" rel="external">Endpoints</a></li>
<li><a href="http://docs.spring.io/spring-boot/docs/current/reference/html/production-ready-monitoring.html#production-ready-sensitive-endpoints" target="_blank" rel="external">Securing sensitive endpoints</a></li>
</ol>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Welcome]]></title>
      <url>http://www.aloo.me/2016/06/21/FirstPost/</url>
      <content type="html"><![CDATA[<p>  Welcome to my blog, it is under construction.</p>
]]></content>
    </entry>
    
  
  
</search>
