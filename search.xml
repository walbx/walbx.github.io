<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
    
    <entry>
      <title><![CDATA[JMeter性能测试-服务器资源监控插件详解]]></title>
      <url>http://www.aloo.me/2017/07/30/JMeter%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95-%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%B5%84%E6%BA%90%E7%9B%91%E6%8E%A7%E6%8F%92%E4%BB%B6%E8%AF%A6%E8%A7%A3/</url>
      <content type="html"><![CDATA[<div align="center"><img src="http://wx4.sinaimg.cn/bmiddle/9bd9d3e2gy1fi1t7yuyo4j20e90cl754.jpg" alt=""></div>

<h2 id="零-引言"><a href="#零-引言" class="headerlink" title="零.引言"></a>零.引言</h2><p>  我们对被测应用进行性能测试时，除了关注吞吐量、响应时间等应用自身的表现外，对应用运行所涉及的服务器资源的使用情况，也是非常重要的方面，通过实时监控，可以准确的把握不同测试场景下服务器资源消耗情况的变化，对于应用性能分析有着重要的作用，同时也是调整测试场景设计的重要依据。对于使用JMeter执行性能测试的朋友，可能大都知道<a href="https://jmeter-plugins.org/" target="_blank" rel="external">jmeter-plugins</a>中就有用于服务器资源监控的插件<a href="https://jmeter-plugins.org/wiki/PerfMon/" target="_blank" rel="external">PerfMon Metrics Collector</a>，同时也有不少同学会选择类似<a href="http://nmon.sourceforge.net/pmwiki.php" target="_blank" rel="external">nmon</a>的独立监控方案。</p>
<p>之所以决定写这篇文章，一是因为在使用JMeter作为性能测试工具的情况下，使用专为其设计的插件会更方便，二是对于普通互联网公司的性能测试方案，这款插件所提供的功能已经可以满足其资源监控方面的大多数需求，而最重要的一点，是在技术群里发现虽然很多同学知道或者在用这款插件，但是对于一些概念和细节，并不了解，导致不能很好的满足自己的需求，而现在网络上介绍这款插件的博客文章，大都是Quick Start式的入门文章，并不能解答这些同学的疑问。<br>注：本文使用的JMeter版本为当前最新release版本3.2。</p>
<h2 id="壹-基础"><a href="#壹-基础" class="headerlink" title="壹.基础"></a>壹.基础</h2><p>本来PerfMon插件的安装部署不是本文的重点，但为了保持文章的完整性，这里还是进行简单的介绍。有基础的同学可以跳过。</p>
<p>使用PerfMon进行服务器资源监控的方案由两部分来实现</p>
<ol>
<li><a href="https://jmeter-plugins.org/wiki/PerfMonAgent/" target="_blank" rel="external">ServerAgent</a>，部署在被测服务器，负责资源耗用数据的采集，其功能实现主要基于hyperic的<a href="https://github.com/hyperic/sigar" target="_blank" rel="external">SIGAR</a>。</li>
<li><a href="https://jmeter-plugins.org/wiki/PerfMon/" target="_blank" rel="external">PerfMon Listener</a>，以插件形式集成到JMeter，作为其中一个Listener。</li>
</ol>
<h3 id="1-1-ServerAgent部署"><a href="#1-1-ServerAgent部署" class="headerlink" title="1.1 ServerAgent部署"></a>1.1 ServerAgent部署</h3><ul>
<li><strong>前提</strong>：ServerAgent运行需要jre1.4以上版本支持。</li>
<li><strong>下载</strong>：从<a href="https://jmeter-plugins.org/wiki/PerfMonAgent/" target="_blank" rel="external">官方下载</a></li>
<li><strong>部署</strong>：将下载的<code>.zip</code>放置到被测服务器，解压后，直接运行<code>startAgent.sh</code>(Linux)/<code>startAgent.bat</code>(Windows)即可，与JMeter进行数据传输时使用简单的文本协议，默认使用TCP协议，默认端口4444。当然，在Linux，我们通常将其放在后台运行，比如用nohup。<ul>
<li><strong>验证</strong>：为了保证测试过程的顺畅，我们可以先行确认JMeter压力机与被测服务器上部署的ServerAgent的通信是否正常。一个简便的方法是在JMeter压力机使用telnet像ServerAgent发送”test”，如<code>telnet 192.168.18.10 4444</code>，连通后，输入<code>test</code>，正常情况下ServerAgent会输出类似<code>INFO    2017-07-29 23:10:52.430 [kg.apc.p] (): Yep, we received the &#39;test&#39; command</code>的日志。</li>
</ul>
</li>
</ul>
<p>可以在运行脚本时添加<code>--tcp-port xxx</code>来指定端口，如<code>$ ./startAgent.sh --tcp-port 3450</code>，需要注意的是此时JMeterPerfMon插件使用时也需要对绑定端口进行对应修改。更多信息可以参考下载页的官方文档。</p>
<h3 id="1-2-PerfMon插件使用"><a href="#1-2-PerfMon插件使用" class="headerlink" title="1.2 PerfMon插件使用"></a>1.2 PerfMon插件使用</h3><ul>
<li><strong>安装</strong>：JMeter3.0之后，有两种方式安装<a href="https://jmeter-plugins.org/" target="_blank" rel="external">jmeter-plugins</a>所包含的插件。<ul>
<li>第一种方式：到<a href="https://jmeter-plugins.org" target="_blank" rel="external">jmeter-plugins官网</a>搜索<code>PerfMon</code>并下载，将得到的jar包放置于JMeter安装目录的<code>lib/ext/</code>路径下，重启JMeter，从Listener中选择使用插件。<div align="center"><img src="http://wx2.sinaimg.cn/bmiddle/9bd9d3e2gy1fi13xskkpyj20wx0f3gq3.jpg" alt="图1 插件下载"></div><br><div align="center" style="color:#808080;font-size:12px"><em>图1 插件下载</em></div></li>
<li>第二种方式：使用Plugins Manager，不过由于国内众所周知的原因，很多同学可能遇到网络不通不能展示插件的问题，这里就不展开了，可参考我之前的文章：<a href="http://www.jianshu.com/p/31776d20c22c" target="_blank" rel="external">JMeter性能测试3.0时代之-全新JMeter插件管理</a></li>
</ul>
</li>
<li><strong>使用</strong>：如图2所示，在Listener中选择PerfMon插件，添加到测试计划中，然后参考图3进行配置，包括配置部署了ServerAgent的被测服务器的IP、ServerAgent使用的端口、要获取和展示的资源项等。测试启动后</li>
</ul>
<div align="center"><img src="http://wx1.sinaimg.cn/bmiddle/9bd9d3e2gy1fi14tudbu4j20jr0ddq5z.jpg" alt="图2 使用PerfMon插件"></div><br><div align="center" style="color:#808080;font-size:12px"><em>图2 使用PerfMon插件</em></div><br><div align="center"><img src="http://wx1.sinaimg.cn/large/9bd9d3e2gy1fi150q73lwj20id07tjsy.jpg" alt="图3 配置"></div><br><div align="center" style="color:#808080;font-size:12px"><em>图3 配置</em></div>

<ul>
<li><strong>数据观察和保存</strong>：在使用GUI模式进行调试时，测试启动后，可以直接在对应窗口观察到根据采集数据描绘的图形。而要在使用NO GUI模式正式执行测试后，查看监控数据，可以在设计测试计划时在图3的<code>Filename</code>位置配置数据要保存的地址，它和保存JMeter测试主数据的方式一样，需要注意的是不要和JMeter测试主数据保存到同一个文件。在测试执行完成后，再在插件界面载入这个文件，即可显示监控数据的图形展示。</li>
</ul>
<h2 id="贰-进阶"><a href="#贰-进阶" class="headerlink" title="贰.进阶"></a>贰.进阶</h2><p>从同事、技术群友们那里，我了解到有不少同学对于PerfMon插件展示的各个指标数据的含义，特别是单位并不是特别明确，所以先讲一下这部分。另外对于数据曲线图的展示，也有一些点值得说明。</p>
<h3 id="2-1-指标"><a href="#2-1-指标" class="headerlink" title="2.1 指标"></a>2.1 指标</h3><p>关于监控指标数据的疑惑，大多可以从PerfMon插件的<code>Metric parameter</code>设置界面找到答案。我们知道对于服务器如CPU、内存等每一个监控指标类型，都有多种数据从不同维度来体现资源使用情况，比如对于CPU，在Linux系统用<code>top</code>命令，就可以看<code>idle</code>、<code>user</code>、<code>system</code>等数据。</p>
<p>对于PerfMon插件，可以通过<code>Metric parameter</code>来设置某种资源具体要收集和展示的数据，只是它的入口并不是很醒目，如下图4右上的红色箭头所指，需要双击输入框后，点击最后边的按钮打开，打开的界面如图4中级红色箭头所指，虽然每种指标的具体配置项不同，但结构相同，都分为<code>Primary Metrics</code>、<code>Additional Metrics</code>等等，Primary是官方认为常用的，通常也是实际工作中更关心，更具有参考意义的指标项，Additional则是在一些特殊场景可能需要了解的指标项。</p>
<div align="center"><img src="http://wx2.sinaimg.cn/bmiddle/9bd9d3e2gy1fi1acu0psvj20wk0e3n1m.jpg" alt="图4 监控指标参数设置"></div><br><div align="center" style="color:#808080;font-size:12px"><em>图4 监控指标参数设置</em></div>

<p>这里先简单说一下几种主要的资源类型的指标项，对应的图就不贴了，太占篇幅，影响阅读：</p>
<ol>
<li><strong>CPU</strong>：<ul>
<li>对于各指标项，数值都是<strong>代表百分比</strong>，比如默认配置(<code>combined</code>)下在曲线图中看到某个时间的数值是30，即代表此时总的cpu使用时间占比为30%。</li>
<li>有两点比较有用的地方值得说明：一是在Scope区域，可以通过Per Process选项来<strong>获取指定进程的CPU使用情况</strong>，二是在CPU Cores区域，我们可以选择监控指定的单个Core。</li>
</ul>
</li>
<li><strong>Memory</strong>：<ul>
<li>各指标项中，<code>usedperc</code>(默认)和<code>freeperc</code>两项的数值<strong>代表与总内存的百分比</strong>，其余指标项的数值都是<strong>指内存大小</strong>，选中对应想，可以看到<code>Metric Unit</code>区域单位配置将变为可用，通常Mb会比较适合观察。</li>
<li>同样，也可以选择监控指定进程的数据</li>
</ul>
</li>
<li><strong>Disk I/O</strong>:<ul>
<li>各指标项中，<code>queue</code>(默认)的数值代表等待I/O队列长度，<code>reads</code>、<code>writes</code>分别代表每秒处理的读/写次数，<code>readbytes</code>、<code>writebytes</code>顾名思义，代表每秒读/写的数据量，单位同样在<code>Metric Unit</code>区域配置，通常Mb会比较适合观察。<ul>
<li>如果有<strong>挂载多个存储设备</strong>，可以在<code>Filesystem Filter</code>区域指定要监控的设备。</li>
</ul>
</li>
</ul>
</li>
</ol>
<p>剩下的，就不一一说明了，参考前面几项，我觉得理解其他资源类型的配置应该没有问题了，至于具体指标项的含义，首先用不到的可以暂时不去了解，如果想要了解，请善用搜索。</p>
<h3 id="2-2-曲线图"><a href="#2-2-曲线图" class="headerlink" title="2.2  曲线图"></a>2.2  曲线图</h3><ol>
<li><p><strong>使用策略</strong>：</p>
<ul>
<li>如果测试场景的测试执行时间较长，采集的监控数据量比较大，为了在GUI模式查看曲线图时更方便、快捷，建议将各个监控指标项单独使用一个PerfMon监听器，从而配置不同的指标项数据存储到不同的文件中，测试执行完毕后，载入数据和数据查看都会更快。<ul>
<li>如果预计数据量不会太大，可以以服务器为单位来划分PerfMon监听器。这样可以方便的观察到整个测试过程中，某台服务器各项资源使用情况的变化趋势</li>
<li>对于分布式服务、为了方便观察各个节点的负载分布、负载变化趋势，可以考虑将同类型的节点放置到同一个PerfMon监听器，以便对比观察</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>数值</strong>：</p>
<ul>
<li>当一个PerfMon监听器中展示多种指标项的数据时，为了曲线图的可观察性，插件会自动进行优化，如图5所示，我们看到在CPU项和内存项都有个x10，<strong>代表曲线图中展示的数值是在采集到的真实数值上放大了10倍</strong>，目的是为了保证不同数据项在同一坐标系中展示时，各项都变化趋势都能够被观察到。</li>
</ul>
</li>
</ol>
<div align="center"><img src="http://wx2.sinaimg.cn/bmiddle/9bd9d3e2gy1fi1pdlehjyj20rk0f2wjj.jpg" alt="图5 曲线图"></div><br><div align="center" style="color:#808080;font-size:12px"><em>图5 曲线图</em></div>

<ol>
<li><strong>曲线图配置</strong>：<ul>
<li>插件界面的<code>Rows</code>标签页可以调整要在曲线图中展示的指标项</li>
<li><code>Setting</code>标签页中常用的有<ul>
<li><code>use relative times</code>用于配置曲线图x轴表示相对时间(测试开始时为0)还是实际系统时间。</li>
<li><code>Auto-zoom rows for best fit</code>默认勾选，则会有上一节讲数值时提到的展示数据自动放大的功能，取消勾选则全部展示采集的实际数值。</li>
<li><code>Limit number of points in row to xx points</code>：勾选后可以设定曲线图展示的采样点数量，我们的测试报告会有不同的角色查看，其中一些角色可能不具备也不需要对监控数据的细节理解能力，此时我们提供的监控曲线图应该是易读的，如果按照实际的所有采样点来渲染出曲线图，可能会有很多偏离趋势的噪点数据，这对于不了解的人来说可能会有很多疑惑，所以当我们有了分析结论，最后报告呈现的时候，可以考虑通过调整采样点，来让曲线图更好的展示资源使用趋势，消除其他不必要的信息。<div align="center"><img src="http://wx4.sinaimg.cn/large/9bd9d3e2gy1fi1qu1tvjwj20ex07oq3v.jpg" alt="图6 曲线图配置"></div><br><div align="center" style="color:#808080;font-size:12px"><em>图6 曲线图配置</em></div></li>
<li><code>Force maximum Y axis value to xx</code>，实际上我更多会选择不勾选，不勾选的情况下，插件在描绘曲线图的时候，会根据数值大小自动调整Y轴最大值，以达到更佳可读性，如图7和图8，分别是不勾选，和勾选后设置最大值为100时的曲线图效果，显然图7可以更容易的观察到变化的细节。不过与上一项类似，可能在对外出具报告时，为了更少的解释说明，可能需要某个指定的数值。</li>
</ul>
</li>
</ul>
</li>
</ol>
<div align="center"><img src="http://wx4.sinaimg.cn/bmiddle/9bd9d3e2gy1fi1qzhv3mfj20rd0aemzl.jpg" alt="图7 不自定义Y轴"></div><br><div align="center" style="color:#808080;font-size:12px"><em>图7 不自定义Y轴</em></div><br><div align="center"><img src="http://wx1.sinaimg.cn/bmiddle/9bd9d3e2gy1fi1qzjj606j20r6094tak.jpg" alt="图8 自定义Y轴"></div><br><div align="center" style="color:#808080;font-size:12px"><em>图8 自定义Y轴</em></div>

<h3 id="2-3-自定义指标"><a href="#2-3-自定义指标" class="headerlink" title="2.3 自定义指标"></a>2.3 自定义指标</h3><ol>
<li><strong>EXEC</strong><ul>
<li>在插件界面选择指标类型时，可以看到一个<code>EXEC</code>选型，该选项允许我们在后面的Metric parameter中配置一个命令语句(该语句最终应该输出单个数值)，测试执行时，ServerAgent将执行该命令，同时插件将接收ServerAgent捕获的输出数值。</li>
<li>语法规则：EXEC所配置的语句需要按照一定的规则来填写，先是给出命令的执行程序的位置，然后将具体的命令以及命令的参数作为，命令和命令参数都需要用冒号”:”来隔开。比如<code>/bin/sh:-c:free |grep Mem |awk &#39;{pring $7}&#39;</code><ul>
<li><code>/bin/sh</code>，代表命令的执行程序</li>
<li><code>-c</code>，即<code>/bin/sh</code>的<code>-c</code>选型，有-c选型的情况下，将从后面的字符串按一定规则解析为命令和命令参数</li>
<li>可以看到有用冒号分隔了执行程序/选型参数/命令语句</li>
<li>对于windows，也类似，如<code>C\:\Windows\System32\cmd.exe:/c:echo %RANDOM%</code></li>
</ul>
</li>
</ul>
</li>
<li><strong>TAIL</strong><ul>
<li>如同Linux的<code>tail</code>命令，读取文件的最后一行，用在这里，需要文件每一行只包含一个单独的数值。借助tail，我们可以通过自定义脚本监控任意指标，只需要脚本的输出满足要求即可。</li>
<li>显而易见，TAIL后面的参数就是配置要读取的文件的地址，测试执行时，ServerAgent将根据配置读取所在服务器的指定文件。</li>
</ul>
</li>
</ol>
<h2 id="叁-总结"><a href="#叁-总结" class="headerlink" title="叁.总结"></a>叁.总结</h2><p>  本文先简单的讲解了JMeter性能测试资源监控插件的部署，然后从现有指标、曲线图和自定义指标三个方面讲解了插件使用过程中比较使用的细节问题，希望通过本文，让大家能灵活运用这款插件来快速实现自己的测试需求。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Web自动化测试平台设计与落地-概览]]></title>
      <url>http://www.aloo.me/2017/06/25/Web%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95%E5%B9%B3%E5%8F%B0%E8%AE%BE%E8%AE%A1%E4%B8%8E%E8%90%BD%E5%9C%B0-%E6%A6%82%E8%A7%88/</url>
      <content type="html"><![CDATA[<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><div align="center"><img src="http://wx2.sinaimg.cn/bmiddle/9bd9d3e2gy1fgxclqm6pfj20jo0bt0tz.jpg" alt="自动化金字塔-灵魂手绘版"></div>

<div align="center" style="color:#808080;font-size:12px"><em>自动化金字塔-灵魂手绘版</em></div>

<p>关于Web自动化测试，投入产出比是一个绕不开的话题，对于走到2017年的测试人，这时候可能已经有很多人会想到著名的<a href="http://martinfowler.com/bliki/TestPyramid.html" target="_blank" rel="external">自动化测试金字塔</a>。它形象地展示了Mike Cohn对自动化分层中各层所应该投入比重的看法，可以作为我们Web自动化实施策略的重要参考。</p>
<p>  我最初开始接触Web自动化测试的时候，没有直接的领路人，测试行业知识也远不及如今这么丰富和易获取，当时我对于自动化测试的分层几乎没有什么了解，更不知道什么金字塔，就如很多同行一样，我一开始先入的是UI自动化的坑，那时候我还没有养成搜索英文资料的习惯，关于Selenuim2、WebDriver的中文信息还相当有限，国内主流还在Selenuim1, 先熟悉API，熟悉元素定位方式，进行一些简单的封装，到后来的PageObject，干劲十足。</p>
<p>  不过在UI自动化这个阶段的后期，我已经对自动化测试有了更多的认识，加上工作变动，开始跳接口自动化的坑，通过工作经历、朋友和网络，对现状有了一定的了解，大约2015年的时候，心里隐约有一些想法，我们的测试对象的架构从最简单的三层架构，到分布式架构，再到SOA，到微服务，一路向前，而再看我们测试人对Web系统接口自动化的实现方式，直接使用如 Postman这样成熟工具的先不谈，就自研框架而言，有用Java的，如Junit/TestNG + Ant（ + Jenkins + JMeter + xxx),有用Python的，比如基于广为人知的RobotFramework，有用Ruby的，可能基于BDD界耳熟能详的Cucumber，等等，技术栈可能各有不同，本质上，大多是孤立的工程 + 文件形式管理的数据和用例。</p>
<p>  可能四五年前，我看到的，大多是这样的方案，到今天，测试从业者的数量大幅度增长，有良好代码能力的并且能将其用到测试工作中的也越来越多，然而我看到的，这些的方案仍然占大多数，除开国内几家顶尖的互联网企业，就我所了解的以及网络上能搜索到的，尝试将方案走到简单Web系统的形式，用数据库存储数据，在线管理自动化实施的，很少。就这些方案本身，我觉得只要能达到自己团队的目的，都是很好的，没有优劣之分，我在意的是，我看到的变化低于预期很多，新的尝试低于预期很多，我觉得很多新的尝试，对于现在的测试人来说，难度并不会比以前的方案高多少，所需要的时间成本，也并不会高出多少，我希望我们测试人在做自动化实施的时候，能够像做业务测试一样，能够不局限于某一个方向。</p>
<p>  既然看到的尝试很少，那我就想自己去做一做，慢慢形成一些思路，到2016年，公司原有的自动化方案不能支撑一些新产品的需求，开始投入精力去设计和实现一个Web类型的测试平台，当时感觉就像当年刚开始自主实施UI自动化一样，有一股劲。设计选型、编码、首版服务端上线、第一个团队开始使用、首版UI上线、1.6、2.0、…在功能方面来说，算是做出了勉强接近自己预期的系统<del>(如果不考虑那拙劣UI的话)</del>。 平台明面上是我单独完成的，但实际上，同行大牛对思路的肯定、工作安排上的支持、业务线伙伴的需求，都是不可或缺的。本来今年年就计划写关于这部分的文章，但由于今年工作、生活上都很忙，这半年几乎没有一个周末有自己独立的时间，<del>加上拖延症作祟，</del>所以直到今天才总算开始码了。</p>
<p>  虽然并不确定这次计划输出的内容对读者能有多少帮助，但还是计划分几篇来写<del>，当然具体能输出几篇现在我也没底，拖延症是个强敌，所以决定第一篇先做一个总览</del></p>
<p>  <del>这期的引言太长了点，抱歉。</del>希望本文能为有耐心读到这里的人带来些许价值</p>
<h2 id="一、目标和定位"><a href="#一、目标和定位" class="headerlink" title="一、目标和定位"></a>一、目标和定位</h2><p>  首选需要说明的是，由于近年的工作重心主要在Web服务端，同时根据团队当前的工作情况，定的自动化策略是优先实施接口层而非UI层，所以平台当前的主要功能是围绕HTTP层的自动化测试展开的。</p>
<p>  平台的定位是作为公司各业务线服务端的自动化公共平台，目标是通过快速落地自动化测试来支撑公司各产品组提高测试效率。</p>
<h2 id="二、平台特点"><a href="#二、平台特点" class="headerlink" title="二、平台特点"></a>二、平台特点</h2><p>  最基本的特点，平台是一个前后端分离的Web服务、由数据库管理基本信息和测试用例、在线查看测试报告。详细一点的话，我认为通过对比的方式来呈现可能比较明了。这里以引言中提到的实施方案与本文所述的测试平台进行对比。</p>
<table>
<thead>
<tr>
<th style="text-align:center">对比项</th>
<th style="text-align:center">业界常见项目</th>
<th style="text-align:center">本文平台</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">定位</td>
<td style="text-align:center">支撑某一产品线的接口自动化需求</td>
<td style="text-align:center">支撑各产品线的多种自动化需求</td>
</tr>
<tr>
<td style="text-align:center">适用性</td>
<td style="text-align:center">适用于特定Web系统接口的自动化</td>
<td style="text-align:center">适用于不同产品、不同设计理念接口的自动化</td>
</tr>
<tr>
<td style="text-align:center">基础架构</td>
<td style="text-align:center">独立的工程，基于文件管理数据</td>
<td style="text-align:center">前后端分离的Web服务，基于数据库管理数据</td>
</tr>
<tr>
<td style="text-align:center">落地方式</td>
<td style="text-align:center">本地搭建运行环境，获取工程并运行以调试新用例</td>
<td style="text-align:center">在线UI操作，开放接口便于CI集成</td>
</tr>
<tr>
<td style="text-align:center">数据管理</td>
<td style="text-align:center">通过更新/上传文件的形式管理用例</td>
<td style="text-align:center">在线创建/更新用例，使用MySQL管理数据</td>
</tr>
<tr>
<td style="text-align:center">运行方式</td>
<td style="text-align:center">通过编辑Jenkins job/Crontab等实现运行计划管理</td>
<td style="text-align:center">在线自定义运行时间计划和运行内容</td>
</tr>
<tr>
<td style="text-align:center">结果校验</td>
<td style="text-align:center">校验粒度较粗，数据库校验可能在代码中</td>
<td style="text-align:center">基于Json解析的细粒度校验，在线管理数据库校验</td>
</tr>
<tr>
<td style="text-align:center">历史数据</td>
<td style="text-align:center">历史数据缺乏有效管理</td>
<td style="text-align:center">在线查看历史运行记录和测试报告</td>
</tr>
</tbody>
</table>
<h2 id="三、系统架构"><a href="#三、系统架构" class="headerlink" title="三、系统架构"></a>三、系统架构</h2><p>  整个平台的大体系统架构如下图，其中产品数据库交互主要是数据预置/清理/校验<br><img src="http://wx1.sinaimg.cn/large/9bd9d3e2gy1fgwfdy11isj20wf0j9n1o.jpg" alt="平台系统架构"></p>
<div align="center" style="color:#808080;font-size:12px"><em>平台系统架构</em></div>

<h2 id="四、相关技术栈"><a href="#四、相关技术栈" class="headerlink" title="四、相关技术栈"></a>四、相关技术栈</h2><table>
<thead>
<tr>
<th style="text-align:center">应用</th>
<th style="text-align:center">技术/工具</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Web服务基础框架</td>
<td style="text-align:center">Spring Boot</td>
</tr>
<tr>
<td style="text-align:center">Web容器</td>
<td style="text-align:center">Jetty</td>
</tr>
<tr>
<td style="text-align:center">持久层框架</td>
<td style="text-align:center">MyBatis</td>
</tr>
<tr>
<td style="text-align:center">HTTP调用和校验基础框架</td>
<td style="text-align:center"><a href="https://github.com/rest-assured/rest-assured" target="_blank" rel="external">REST-assured</a></td>
</tr>
<tr>
<td style="text-align:center">用例调度执行</td>
<td style="text-align:center">TestNG</td>
</tr>
<tr>
<td style="text-align:center">HTML报告</td>
<td style="text-align:center"><a href="https://github.com/allure-framework/allure1" target="_blank" rel="external">Allure</a></td>
</tr>
<tr>
<td style="text-align:center">基础UI组件</td>
<td style="text-align:center">Bootstrap</td>
</tr>
<tr>
<td style="text-align:center">前后端交互</td>
<td style="text-align:center">AJAX(Jquery)</td>
</tr>
<tr>
<td style="text-align:center">在线代码编辑</td>
<td style="text-align:center"><a href="https://github.com/ajaxorg/ace" target="_blank" rel="external">Ace</a></td>
</tr>
</tbody>
</table>
<p>关于在线代码编辑，主要提供给有基础代码能力的同学应用在复杂场景的自动化实施，普通的接口自动化需求不需要。后续文章会做更多的说明。</p>
<h2 id="五、UI概览"><a href="#五、UI概览" class="headerlink" title="五、UI概览"></a>五、UI概览</h2><p><img src="http://wx4.sinaimg.cn/large/9bd9d3e2gy1fgxa7j5javj20ni0g3mz2.jpg" alt="基础信息管理"></p>
<div align="center" style="color:#808080;font-size:12px"><em>基础信息管理</em></div><br><img src="http://wx2.sinaimg.cn/large/9bd9d3e2gy1fgxa7jwlzpj20os0i3gnt.jpg" alt="用例管理"><br><div align="center" style="color:#808080;font-size:12px"><em>用例管理</em></div><br><img src="http://wx2.sinaimg.cn/large/9bd9d3e2gy1fgxa7khv9vj20pt0eu75s.jpg" alt="在线场景编辑"><br><div align="center" style="color:#808080;font-size:12px"><em>在线场景编辑</em></div><br><img src="http://wx2.sinaimg.cn/large/9bd9d3e2gy1fgxa7krk21j20ni0bfjsz.jpg" alt="定时计划管理"><br><div align="center" style="color:#808080;font-size:12px"><em>定时计划管理</em></div><br><img src="http://wx3.sinaimg.cn/large/9bd9d3e2gy1fgxa7lmvtoj20sv0bdq4b.jpg" alt="用例调试"><br><div align="center" style="color:#808080;font-size:12px"><em>用例调试</em></div><br><img src="http://wx1.sinaimg.cn/large/9bd9d3e2gy1fgxa7lx4djj20zq0a2wgz.jpg" alt="在线报告"><br><div align="center" style="color:#808080;font-size:12px"><em>在线报告</em></div><br><img src="http://wx3.sinaimg.cn/mw690/9bd9d3e2gy1fgxa7mo39fj20m50i7glz.jpg" alt="邮件样例"><br><div align="center" style="color:#808080;font-size:12px"><em>邮件样例</em></div>

<h2 id="六、待完善部分"><a href="#六、待完善部分" class="headerlink" title="六、待完善部分"></a>六、待完善部分</h2><p>平台目前有两个较大的功能欠缺：</p>
<ul>
<li>账户体系和权限控制</li>
<li>代码动态编译运行的安全控制(沙箱)</li>
</ul>
<p>账户体系和权限控制目前没有实现，主要是时间成本的问题，考虑目前平台都是公司内部各测试组使用，暂时没有特别强的需求。至于动态编译运行的安全问题，主要是难度和时间成本两方面的原因，对于这个安全问题，目前我自己还没有一个周全的解决方案，欢迎提出宝贵意见，另一方面，作为内网运行的平台，安全需求相对较低。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Locust性能测试实施细节]]></title>
      <url>http://www.aloo.me/2017/04/09/Locust%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E5%AE%9E%E6%96%BD%E7%BB%86%E8%8A%82/</url>
      <content type="html"><![CDATA[<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>当我们做Web系统性能测试方案时，压力模拟工具的选择通常是一个绕不开的环节。对于大部分互联网公司的业务规模和测试资源投入，JMeter这个老牌开源性能测试工具能够满足大部分测试需求，它也可能是世面上书籍、博客教程丰富程度仅次于LoadRunner的性能测试工具。然而当我们的场景需要模拟的并发用户数以千为单位时，使用JMeter的成本越来越大，甚至超出我们掌握的资源。此时，我们开始寻找更低成本的方案，而<a href="http://locust.io/" target="_blank" rel="external">Locust</a>，为这样的方案带来了一种可能。</p>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Locust是开源、使用Python开发、基于事件、支持分布式并且提供Web UI进行测试执行和结果展示的性能测试工具。而它之所以能够在资源占用方面明显优于JMeter，一个关键点在于两者模拟虚拟用户的方式不同，JMeter通过线程来作为虚拟用户，而Locust借助gevent库对协程的支持，以greenlet来实现对用户的模拟，相同配置下Locust能支持的并发用户数相比JMeter可以达到一个数量级的提升。<br>        Locust使用Python代码定义测试场景，目前支持Python 2.7, 3.3, 3.4, 3.5, 和3.6。它自带一个Web UI,用于定义用户模型，发起测试，实时测试数据，错误统计等，在最新未正式发布的v0.8a2(当前最新发布版本v0.8a1)，还提供QPS、评价响应时间等几个简单的图表。</p>
<p><img src="http://wx4.sinaimg.cn/large/9bd9d3e2gy1fegq140omij20ox07iq46.jpg" alt="Summary Report"></p>
<p><div align="center" style="color:#808080;font-size:12px"><em>图1 Summary report</em></div><br><img src="http://wx4.sinaimg.cn/large/9bd9d3e2gy1fegq1klu2ej20oq0jatae.jpg" alt="Charts"></p>
<p><div align="center" style="color:#808080;font-size:12px"><em>图2 Charts</em></div><br>本文不会介绍Locust最基础的部署、运行等Quick start式内容，这部分内容请直接参照<a href="http://docs.locust.io/en/latest/quickstart.html" target="_blank" rel="external">官网Quick start</a>或者搜索Locust入门的博客，本文主要介绍一些目前网络上还比较缺少的，真正要用Locust来做Web系统性能测试时通常需要用到的内容或者可能遇到的问题</p>
<h2 id="v0-8a2"><a href="#v0-8a2" class="headerlink" title="v0.8a2"></a>v0.8a2<a id="a2"></a></h2><p>如前文所说，当前官方最新发布的版本为v0.8a1，还不包含图表特性，而在官方Github上已经在v0.8a2完成了图表特性的合并，想要提前体验可以直接从Github获取master分支的代码，覆盖<code>[PythonHome]\Lib\site-packages</code>中的locust目录即可。</p>
<h2 id="指定Web-host"><a href="#指定Web-host" class="headerlink" title="指定Web host"></a>指定Web host</h2><p>在Linux系统多网卡情况下，Locust自动选择网卡时可能会遇到<code>error: [Errno 97] Address family not supported by protocol</code>错误,此时可以通过直接指定web host来解决问题，使用选项<code>--web-host</code>来指定可用的地址，例：</p>
<pre><code>locust -f xxx.py --web-host=127.0.0.1
locust -f xxx.py --web-host=192.168.1.2
locust -f xxx.py --web-host=localhost
</code></pre><h2 id="断言"><a href="#断言" class="headerlink" title="断言"></a>断言</h2><p>当我们没有自定义断言时，测试请求结果的状态(success/fail)取决于Http请求是否有异常出现，而在对我们的Web系统实施性能测试时，当我们需要更准确的业务成功率数据时，就需要通过对响应状态码、Response body等数据进行校验来给出结果，此时，可以通过ResponseContextManager来实现。首先在场景代码的发起请求参数中通过<code>catch_response=True</code>来捕获响应数据，然后对响应数据进行校验，最后使用success()/failure()两个方法来标识请求结果的状态。例：</p>
<pre><code>from locust import HttpLocust, TaskSet,task
class UserBehavior(TaskSet):
    @task(2)
    def foo(self):
        with self.client.get(&quot;/&quot;, catch_response=True) as response:
            if response.status_code == 200:
                response.success()
        @task(1)
         def bar(self):
                reqBody = &#39;{&quot;username&quot;:&quot;ellen_key&quot;, &quot;password&quot;:&quot;education&quot;}&#39;
                with self.client.post(&quot;/login&quot;, reqBody, catch_response=True) as response: 
                        if response.content == &quot;&quot;:
                                response.failure(&quot;No data&quot;)
class WebsiteUser(HttpLocust):
    task_set = UserBehavior
    host = &quot;http://foo.bar.com&quot;
    min_wait = 0
    max_wait = 0
</code></pre><h2 id="Json解析"><a href="#Json解析" class="headerlink" title="Json解析"></a>Json解析</h2><p>Json作为一种轻量级的数据交换格式，以及被如今的互联网系统广泛采用。上一节的示例中，我们使用content获取完整的响应内容，实际测试实施中，对于动态的响应结果，可能更多的采用校验关键字段的方式对于Json格式的响应数据，要获取特定字段的值，可以直接使用内置的Json解析实现，例：<br>对于如下的响应结果：</p>
<pre><code>{
  &#39;code&#39;:0,
  &#39;data&#39;:[
        {
          &#39;id&#39;:123
        }
  ]
}
</code></pre><p>可以通过如下方式获取其中的关键数据：</p>
<pre><code>with self.client.post(&quot;/login&quot;, reqBody, catch_response=True) as response: 
    json_resp = response.json()
    code = json_resp[&quot;code&quot;]
    data_len = len(json_resp[&quot;data&quot;])
    id = json_resp[&quot;data&quot;][0][&quot;id&quot;]
</code></pre><h2 id="自定义标签"><a href="#自定义标签" class="headerlink" title="自定义标签"></a>自定义标签</h2><p>从简介的Summary report图中可以看到，Locust的结果展示中，请求的默认名称是url的path部分，而为了报告更直观，或者当同一个业务有动态的path(如/user/[userid])，需要聚合时，可以通过<code>name</code>参数来自定义标签实现,例：</p>
<pre><code>with  self.client.get(&quot;/account/{accountID}&quot;, catch_response=True, name = &quot;getAccount&quot;) as resp:
</code></pre><h2 id="分布式运行"><a href="#分布式运行" class="headerlink" title="分布式运行"></a>分布式运行</h2><p>Locust的分布式运行，master和slave节点都需要有场景脚本，分别以如下命令启动：</p>
<ul>
<li>master:<code>locust -f locustfile.py --master --web-host=x.x.x.x</code></li>
<li>slave:<code>locust -f locustfile.py --slave --master-host=x.x.x.x</code><br>master节点将运行Locust的Web UI服务，不会承担任何施压任务(不会模拟虚拟用户)。<br>如前面的简介，Locust模拟并发用户是使用协程，也因此对于多核CPU的服务器，为良好的利用多核能力，<strong>建议一台slave服务器运行与CPU核数相当的slave</strong>。</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Locust作为一个年轻的、轻量级的性能测试工具，网络上相关的应用文献特别是中文文献相对较少，而且多数是Quick start式的指引，对于一些实施的细节信息还比较欠缺，本文根据作者的实际应用经验，列举了部分使用细节，希望能为需要的朋友提供一点有用的信息。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[JMeter3.0图形化HTML报告中文乱码问题处理]]></title>
      <url>http://www.aloo.me/2016/08/19/JMeter3-0%E5%9B%BE%E5%BD%A2%E5%8C%96HTML%E6%8A%A5%E5%91%8A%E4%B8%AD%E6%96%87%E4%B9%B1%E7%A0%81%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86/</url>
      <content type="html"><![CDATA[<div align="center"><img src="http://ww2.sinaimg.cn/bmiddle/9bd9d3e2gw1f6z4u2pk8ij20gy0c379r.jpg" alt="Image: discovermagazine.com/"></div>

<blockquote>
<p>之前在博客中介绍了JMeter 3.0版本新特性：<a href="http://www.aloo.me/2016/07/17/JMeter%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%953-0%E6%97%B6%E4%BB%A3%E4%B9%8B-%E5%A4%9A%E7%BB%B4%E5%BA%A6%E7%9A%84%E5%9B%BE%E5%BD%A2%E5%8C%96HTML%E6%8A%A5%E5%91%8A/">Dashboard Report</a>，用于为JMeter测试结果生成多维度的图形化HTML报告，包括聚合报告、吞吐量趋势图、平均响应时间趋势图等十多种图表，为我们性能测试的结果分析和报告输出提供了很多便利。<br>本文主要介绍如何解决JMeter脚本中取样器(Sampler)名称定义为中文时，生成的HTML报告中中文展示为乱码的问题。</p>
</blockquote>
<h2 id="一-问题概述"><a href="#一-问题概述" class="headerlink" title="一. 问题概述"></a>一. 问题概述</h2><p>由于个人在JMeter 3.0的实际应用中，脚本中的Test Plan/Sampler等元件命名都没有使用中文，所以在之前介绍Dashboard Report特性的博客(原文戳<a href="(http://www.aloo.me/2016/07/17/JMeter%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%953-0%E6%97%B6%E4%BB%A3%E4%B9%8B-%E5%A4%9A%E7%BB%B4%E5%BA%A6%E7%9A%84%E5%9B%BE%E5%BD%A2%E5%8C%96HTML%E6%8A%A5%E5%91%8A/">这里</a>))成文时，没有提到关于中文的问题。之后有朋友反馈，Sampler名称为中文时，生成的报告中展示为乱码，自己测试，确实如此。<br>如图，脚本包含两个命名为中文的Sampler：<br><img src="http://ww2.sinaimg.cn/large/9bd9d3e2gw1f6yz2cx85gj20c104vaav.jpg" alt=""><br>执行测试后，生成的Dashboard Report图表中文乱码：<br><img src="http://ww3.sinaimg.cn/large/9bd9d3e2gw1f6yyuwwisfj20jk083gnb.jpg" alt=""><br><img src="http://ww3.sinaimg.cn/large/9bd9d3e2gw1f6yyuwy12uj20ib06xt9g.jpg" alt=""><br>于是通过查看官方文档和源码，找到原因并进行了解决，原打算直接追加到之前那篇文章，但考虑到篇幅过长，于是决定新成一文，然后在之前的文章中补充链接。</p>
<h2 id="二-解决方案"><a href="#二-解决方案" class="headerlink" title="二. 解决方案"></a>二. 解决方案</h2><p>先上解决方案：修改JMeter report模块读取数据源码中的字符集设置为UTF-8，编译后替换到<code>JMETER_HOME\lib\ext\ApacheJMeter_core.jar</code>内，这里会分享一个我处理好的一个jar包，但建议自己亲自动手：</p>
<h3 id="基础方案"><a href="#基础方案" class="headerlink" title="基础方案"></a>基础方案</h3><ol>
<li>在官网<a href="http://jmeter.apache.org/download_jmeter.cgi" target="_blank" rel="external">下载页面</a>下载<code>apache-jmeter-3.0_src.zip</code></li>
<li>相关源码位置：<br><code>apache-jmeter-3.0/src/core/org/apache/jmeter/report/core/CsvSampleReader.java</code></li>
<li>将<code>CsvSampleReader</code>的<code>CHARST</code>赋值为<code>UTF-8</code><pre><code class="java">private static final String CHARSET = StandardCharsets.UTF_8.displayName();
</code></pre>
</li>
<li>编译该文件，用得到的<code>.class</code>文件替换<code>JMETER_HOME\lib\ext\ApacheJMeter_core.jar</code>内的原文件。当然也可以直接对源码重新编译打包，但会比较费时。</li>
</ol>
<p>效果如图：<br><img src="http://ww3.sinaimg.cn/large/9bd9d3e2gw1f6yyuxt0g0j20ie06f0te.jpg" alt=""></p>
<h3 id="推荐方案"><a href="#推荐方案" class="headerlink" title="推荐方案"></a>推荐方案</h3><p>关于设置字符编码，一个更推荐的方案是设置默认字符编码为UTF-8，同时支持.properties配置项。JMeter读写结果文件(xml/csv)的字符编码配置项是<code>./bin/saveservice.properties</code>文件内的<code>_file_encoding</code>，由<code>org.apache.jmeter.save.SaveService.getFileEncoding(String dflt)</code>读取，当没有在配置相中指定时，将使用方法的入参作为默认编码，这里我们传入UFT-8作为默认格式，因此将基础方案中的步骤3做如下变更：</p>
<pre><code class="java">private static final String CHARSET = SaveService.getFileEncoding(StandardCharsets.UTF_8.displayName());
</code></pre>
<p>编译后替换即可。saveservice.properties文件的_file_encoding默认已配置为UTF-8，多数情况下，我们不需要修改。</p>
<h3 id="文件分享"><a href="#文件分享" class="headerlink" title="文件分享"></a>文件分享</h3><p>分享的文件和jar包是使用推荐方案进行处理。可以取用class文件自己替换进本地的ApacheJMeter_core.jar，也可以直接下载分享的jar包替换本地对应jar包。</p>
<ul>
<li>单独的CsvSampleReader.class文件：<code>https://pan.baidu.com/s/1bo10QnX</code>，提取码<code>ee68</code></li>
<li>处理完毕的ApacheJMeter_core.jar： <code>https://pan.baidu.com/s/1mhKLwgw</code>，提取码<code>id7h</code></li>
</ul>
<p><em>注：github上可以看到jmeter的trunk分支已经将dashboard report的默认字符编码更改为UFT-8，本文的推荐方案即是官方更新中的实现方式。只是目前官方还没有发布更新，所以自己动手。</em></p>
<h2 id="三-成因分析"><a href="#三-成因分析" class="headerlink" title="三. 成因分析"></a>三. 成因分析</h2><p>Dashboard Report特性生成HTML图表，使用JMeter记录测试结果数据的文件<em>(命令行执行时<code>-l</code>指定的文件，也可在图形界面的监听器中指定，作为基础知识不在这里展开)</em>作为数据源，Apache FreeMarker作为模板引擎，默认的模板位于JMETER_HOME\bin\report-template。</p>
<ul>
<li>查看官方说明，确认没有关于HTML报告字符编码的配置项。</li>
<li>查看数据源文件，确定文件格式为UTF-8，文件中的中文正常可读，排除数据源存在问题的可能。</li>
<li>查看生成的结果文件，主要数据在<code>指定路径/content/js/graph.js</code>，任选一个图表数据，查看其标签的值(“label”:”<em>*</em>“)，显示为乱码，排除js解析成乱码的可能。</li>
<li>此时首先想到Java文件读取过程问题，从官方发布的源码包查看源码<code>src/core/org/apache/jmeter/report/core/CsvSampleReader</code>，发现代码中字符编码指定为ISO8859-1:<pre><code class="java">package org.apache.jmeter.report.core;
//次要内容略...
public class CsvSampleReader implements Closeable{
  //次要内容略...
  private static final String CHARSET = &quot;ISO8859-1&quot;;
  //次要内容略...
  private CsvSampleReader(File inputFile, SampleMetadata metadata, char separator, boolean useSaveSampleCfg) {
    if (!(inputFile.isFile() &amp;&amp; inputFile.canRead())) {
      throw new IllegalArgumentException(inputFile.getAbsolutePath()
              + &quot; does not exist or is not readable&quot;);
    }
    this.file = inputFile;
    try {
      this.reader = new BufferedReader(new InputStreamReader(
              new FileInputStream(file), CHARSET), BUF_SIZE);
    } catch (FileNotFoundException | UnsupportedEncodingException ex) {
      throw new SampleException(&quot;Could not create file reader !&quot;, ex);
    }
  }
}
</code></pre>
至此，问题原因得以确定。</li>
</ul>
<h2 id="四-总结"><a href="#四-总结" class="headerlink" title="四. 总结"></a>四. 总结</h2><p>本文主要介绍使用JMeter 3.0新特性生成HTML图形化报告时，中文标签展示为乱码的现象，成因以及简单解决方案。另外，github上JMeter的trunk分支已经有相应更新，预计在下一次版本发布中，该问题应该可以得到修复。</p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol>
<li><a href="http://jmeter.apache.org/devguide-dashboard.html" target="_blank" rel="external">devguide-dashboard</a></li>
<li><a href="https://github.com/apache/jmeter" target="_blank" rel="external">github－apache/jmeter</a></li>
</ol>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Storm应用实例--集成HBase]]></title>
      <url>http://www.aloo.me/2016/08/14/%E5%9C%A8Storm%E4%B8%AD%E6%93%8D%E4%BD%9CHBase/</url>
      <content type="html"><![CDATA[<p><div align="center"><img src="http://ww1.sinaimg.cn/bmiddle/9bd9d3e2gw1f6tdpgrrp3j20fp08eq3s.jpg" alt=""></div></p>
<blockquote>
<p>本文展示一个Storm的topology，该topology对给定的词源进行词频统计，然后存入HBase，该实例不借助storm-hbase包，而是直接使用hbase client来完成对HBase的操作。</p>
</blockquote>
<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>由Twitter开源的、分布式实时计算系统<a href="http://storm.apache.org/" target="_blank" rel="external">Apache Storm</a>，如今已被多家知名企业应用于实时分析、流式计算、在线机器学习、分布式RPC调用、ETL等领域，甚至有看到“Storm之于实时计算，就像Hadoop之于数据批处理”这样的评价，是否言过其实，这里暂且不论，但至少已经看到业界对Storm在实时计算领域的肯定，加之其开源特性，必然会得到更广泛的应用。<br>在Storm的实际应用中，在topology中将经过处理的数据通过<a href="http://hbase.apache.org/" target="_blank" rel="external">HBase</a>进行持久化，是一个常见的需求。Storm官方提供了storm-hbase，包含一些比较通用的API及其简单实现，可以查看对应的官方文档来了解基本使用方法：<a href="http://storm.apache.org/releases/current/storm-hbase.html" target="_blank" rel="external">storm-hbase</a>。但如果你需要进行一些更复杂的处理，或者希望对自己的代码有更多的掌控，那么脱离storm-hbase，直接使用HBase的Java API来完成操作，将是一个不错的选择。本文将展示的，就是一个在Storm的topology中直接使用HBase Java API操作HBase的简单示例。</p>
<h2 id="零-示例简述"><a href="#零-示例简述" class="headerlink" title="零.示例简述"></a>零.示例简述</h2><p>本项目数据源部分直接借用Storm词频统计的官方示例，在WordSpout.java中从静态字符串数组中读取单词，在WordCounterBolt.java中统计单词出现的次数，最后在MyHBaseBolt.java中将单词及其出现的次数写入到HBase。</p>
<h2 id="一-环境信息"><a href="#一-环境信息" class="headerlink" title="一.环境信息"></a>一.环境信息</h2><p>示例的测试环境：</p>
<ul>
<li>Java 8</li>
<li>Storm 1.0.1</li>
<li>HBase 1.2.2</li>
<li>Hadoop 2.6.4</li>
<li>Maven 3.3.3</li>
</ul>
<h2 id="二-创建项目"><a href="#二-创建项目" class="headerlink" title="二.创建项目"></a>二.创建项目</h2><p>示例直接使用hbase client操作HBase，因此关键的依赖只有storm和hbase client，项目pom.xml:</p>
<pre><code class="xml">&lt;properties&gt;
  &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;
  &lt;storm.version&gt;1.0.1&lt;/storm.version&gt;
  &lt;!-- 开发调试时配置为compile，topology打包时配置为provided --&gt;
  &lt;storm.scope&gt;compile&lt;/storm.scope&gt;
&lt;/properties&gt;

&lt;dependencies&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.apache.storm&lt;/groupId&gt;
        &lt;artifactId&gt;storm-core&lt;/artifactId&gt;
        &lt;version&gt;${storm.version}&lt;/version&gt;
        &lt;scope&gt;${storm.scope}&lt;/scope&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.apache.hbase&lt;/groupId&gt;
        &lt;artifactId&gt;hbase-client&lt;/artifactId&gt;
        &lt;version&gt;1.2.2&lt;/version&gt;
    &lt;/dependency&gt;
&lt;/dependencies&gt;
</code></pre>
<p>项目结构：</p>
<pre><code>--src
   --main
       --java
          --bolt
              --MyHBaseBolt.java
              --WordCounterBolt.java
          --spout
              --WordSpout.java
          --HBaseTopology.java
       --resources
           --hbase-site.xml
</code></pre><p>其中hbase-site.xml直接使用HBase服务器上面的hbase-site.xml即可。本示例的HBase集群使用独立的zookeeper集群，zk的端口使用了默认端口，因此不需要在hbase-site.xml中显式配置，详细内容见附录。</p>
<h2 id="三-词频统计"><a href="#三-词频统计" class="headerlink" title="三.词频统计"></a>三.词频统计</h2><p>这部分直接借用一个Storm官方示例：WordSpout.java从静态数组中随机读取单词并向外发射，WordCounterBolt接收来自WordSpout的包含一个个单词的tuple，对每个单词出现的次数进行统计，然后将每个单词及其对应的计数向外发射。为快速进入主题，这部分代码放在附录中。</p>
<h2 id="四-HBase操作"><a href="#四-HBase操作" class="headerlink" title="四.HBase操作"></a>四.HBase操作</h2><p>在java中通过hbase client对hbase进行读写大体有如下步骤：</p>
<ul>
<li>创建HBaseConfiguration对象，该对象可以读取CLASSPATH下的hbase-site.xml文件的内容。<br><code>Configuration config = HBaseConfiguration.create();</code></li>
<li>用前面的config对象为入参创建Connection对象来连接至目标HBase集群。connection对象对资源消耗较大，应该避免创建过多的实例。使用完毕后，调用connection的close()方法关闭连接，建议使用try/finally来确保连接的关闭。<br><code>Connection connection = ConnectionFactory.createConnection(config);</code></li>
<li>以指定的table名称(应该是已存在的)为入参创建Table对象来连接指定的表。使用完毕后，需要调用table的close()方法进行关闭。与connection不同，table对象是轻量的，对table对象的创建，不需要像connection那样小心，当然，这并不是鼓励你创建得越多越好。<br><code>Table table = connection.getTable(TableName.valueOf(&quot;WordCount&quot;));</code></li>
<li>以指定的row key(可以是在HBase中还不存在的)为入参创建Put对象来持有要写入的数据。<br><code>Put p = new Put(Bytes.toBytes(&quot;key&quot;));</code></li>
<li>调用Put对象的addColumn方法，接受列族名称(column family)、列名(column qualifier)和要写入的值作为参数。可以多次调用该方法让put对象持有一定数量的数据后，再一次性提交。<br><code>put.addColumn(Bytes.toBytes(&quot;cf&quot;), Bytes.toBytes(&quot;words&quot;), Bytes.toBytes(&quot;word&quot;));</code></li>
<li>以Put对象为入参，调用table的put方法来提交要写入hbase的数据</li>
<li>关闭table</li>
<li>关闭connection</li>
</ul>
<p>在Storm的bolt中进行实际应用：</p>
<pre><code class="java">public class MyHBaseBolt extends BaseBasicBolt {
    private Connection connection;
    private Table table;

    @Override
    public void prepare(Map stormConf, TopologyContext context) {
        Configuration config = HBaseConfiguration.create();
        try {
            connection = ConnectionFactory.createConnection(config);
//示例都是对同一个table进行操作，因此直接将Table对象的创建放在了prepare，在bolt执行过程中可以直接重用。
            table = connection.getTable(TableName.valueOf(&quot;WordCount&quot;));
        } catch (IOException e) {
            //do something to handle exception
        }
    }
    @Override
    public void execute(Tuple tuple, BasicOutputCollector basicOutputCollector) {
        //从tuple中获取单词
        String word = tuple.getString(0);
        //从tuple中获取计数，这里转换为String只是为了示例运行后存入hbase的计数值能够直观显示。
        String count = tuple.getInteger(1).toString();
        try {
            //以各个单词作为row key
            Put put = new Put(Bytes.toBytes(word));
            //将被计数的单词写入cf:words列
            put.addColumn(Bytes.toBytes(&quot;cf&quot;), Bytes.toBytes(&quot;words&quot;), Bytes.toBytes(word));
            //将单词的计数写入cf:counts列
            put.addColumn(Bytes.toBytes(&quot;cf&quot;), Bytes.toBytes(&quot;counts&quot;), Bytes.toBytes(count));
            table.put(put);
        } catch (IOException e) {
            //do something to handle exception
        }
    }
    @Override
    public void cleanup() {
        //关闭table
        try {
            if(table != null) table.close();
        } catch (Exception e){
            //do something to handle exception
        } finally {
            //在finally中关闭connection
            try {
                connection.close();
            } catch (IOException e) {
                //do something to handle exception
            }
        }
    }
    @Override
    public void declareOutputFields(OutputFieldsDeclarer outputFieldsDeclarer) {
        //示例中本bolt不向外发射数据，所以没有再做声明
    }
}
</code></pre>
<p>虽然可能应用场景相对较少，但还是附带介绍一下从HBase读取数据：</p>
<ul>
<li>以指定的row key为入参创建Get对象<br><code>Get get = new Get(Bytes.toBytes(&quot;key&quot;));</code></li>
<li>以Get实例为入参调用table的get方法来获取结果集对象Result<br><code>Result r = table.get(get);</code></li>
<li>从结果集中获取制定列的值<br><code>byte[] value = r.getValue(Bytes.toBytes(&quot;cf&quot;), Bytes.toBytes(&quot;words&quot;));</code></li>
<li><p>也可以使用scan来批量读取，Scanner实现了Iterable，因此可以使用foreach来进行遍历:</p>
<pre><code class="java">Scan scan = new Scan();
//获取指定列族所有列的数据
scan.addFamily(Bytes.toBytes(&quot;cf&quot;));
ResultScanner scanner = table.getScanner(scan);
try {
  for (Result r : scanner) {...}
}finally{
  scanner.close();
  }
</code></pre>
<h2 id="五-Topology"><a href="#五-Topology" class="headerlink" title="五.Topology"></a>五.Topology</h2><p>topology中唯一需要注意的是，在Windows测试该示例时，需要配置hadoop.home.dir属性，并确保将winutils.exe客户端(<a href="http://pan.baidu.com/s/1qWlCseK" target="_blank" rel="external">示例中使用的版本(链接若失效请自助)</a>)放置在所配置的hadoop.home.dir目录下(资料解释:在hadoop 2.x版本的包中不再包含winutils.exe文件)。<br>HBaseTopology.java：</p>
<pre><code class="java">public class PersistentWordCount {
  private static final String WORD_SPOUT = &quot;WORD_SPOUT&quot;;
  private static final String COUNT_BOLT = &quot;COUNT_BOLT&quot;;
  private static final String HBASE_BOLT = &quot;HBASE_BOLT&quot;;

  public static void main(String[] args) throws Exception {
      System.setProperty(&quot;hadoop.home.dir&quot;,&quot;E:/BaiduYunDownload&quot;);

      Config config = new Config();

      WordSpout spout = new WordSpout();
      WordCounter bolt = new WordCounter();
      MyHBaseBolt hbase = new MyHBaseBolt();

      // wordSpout ==&gt; countBolt ==&gt; HBaseBolt
      TopologyBuilder builder = new TopologyBuilder();

      builder.setSpout(WORD_SPOUT, spout, 1);
      builder.setBolt(COUNT_BOLT, bolt, 1).shuffleGrouping(WORD_SPOUT);
      builder.setBolt(HBASE_BOLT, hbase, 10).fieldsGrouping(COUNT_BOLT, new Fields(&quot;word&quot;));

      if (args.length == 0) {
          LocalCluster cluster = new LocalCluster();
          cluster.submitTopology(&quot;word&quot;, config, builder.createTopology());
          Thread.sleep(10000);
          cluster.killTopology(&quot;word&quot;);
          cluster.shutdown();
          System.exit(0);
      } else {
          config.setNumWorkers(3);
          StormSubmitter.submitTopology(args[0], config, builder.createTopology());
      }
}
</code></pre>
<p>如果编译遇到类似：<code>java.io.IOException: No FileSystem for scheme: hdfs</code>这样关于hadoop的问题，可能需要添加hadoop相关依赖包，如：</p>
<pre><code class="xml">&lt;dependency&gt;
  &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;
  &lt;artifactId&gt;hadoop-common&lt;/artifactId&gt;
  &lt;version&gt;2.6.4&lt;/version&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
  &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;
  &lt;artifactId&gt;hadoop-hdfs&lt;/artifactId&gt;
  &lt;version&gt;2.6.4&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
</li>
</ul>
<h2 id="六-总结"><a href="#六-总结" class="headerlink" title="六.总结"></a>六.总结</h2><p>本文通过一个词频统计后通过HBase进行结果持久化的topology示例，展示了如何在Storm的中直接使用HBase的java api来实现基本的读写操作，希望能为想自己完成Storm的HBase集成而不得其法的朋友提供一个入门指引。</p>
<h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><ol>
<li><p>WordSpout.java:</p>
<pre><code class="java">public class WordSpout extends BaseRichSpout {
 private SpoutOutputCollector collector;
 private static final String[] MSGS = new String[]{
         &quot;Storm&quot;, &quot;HBase&quot;, &quot;Integration&quot;, &quot;example&quot;, &quot;by &quot;, &quot;aloo&quot;, &quot;in&quot;, &quot;Aug&quot;,
 };

 private static final Random random = new Random();

 @Override
 public void declareOutputFields(OutputFieldsDeclarer declarer) {
     declarer.declare(new Fields(&quot;word&quot;));
 }

 @Override
 public void open(Map conf, TopologyContext context, SpoutOutputCollector collector) {
     this.collector = collector;
 }

 @Override
 public void nextTuple() {
     String word = MSGS[random.nextInt(8)];
     collector.emit(new Values(word));
 }
}
</code></pre>
</li>
<li><p>WordCounterBolt.java:</p>
<pre><code class="java">public class WordCounter extends BaseBasicBolt {
 private Map&lt;String, Integer&gt; _counts = new HashMap&lt;String, Integer&gt;();

 @Override
 public void execute(Tuple tuple, BasicOutputCollector collector) {
     String word = tuple.getString(0);
     int count;
     if(_counts.containsKey(word)){
         count = _counts.get(word);
     } else {
         count = 0;
     }
     count ++;
     _counts.put(word, count);
     collector.emit(new Values(word, count));
 }
 @Override
 public void declareOutputFields(OutputFieldsDeclarer declarer) {
     declarer.declare(new Fields(&quot;word&quot;, &quot;count&quot;));
 }
}
</code></pre>
</li>
<li>hbase-site.xml<pre><code class="xml">&lt;?xml version=&quot;1.0&quot;?&gt;
&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;
&lt;configuration&gt;
 &lt;property&gt;
     &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;
     &lt;value&gt;true&lt;/value&gt;
 &lt;/property&gt;
 &lt;property&gt;
     &lt;name&gt;hbase.rootdir&lt;/name&gt;
     &lt;value&gt;hdfs://xxx.xx.xx.xx:9000/hbase&lt;/value&gt;
 &lt;/property&gt;
 &lt;property&gt;
     &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt;
     &lt;value&gt;/home/hadoop/hbase/storm/zookeeper&lt;/value&gt;
 &lt;/property&gt;
 &lt;property&gt;
     &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;
     &lt;value&gt;zknode1,zdnode2,zknode3&lt;/value&gt;
&lt;/configuration&gt;
</code></pre>
</li>
</ol>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[性能测试中服务器关键性能指标浅析]]></title>
      <url>http://www.aloo.me/2016/08/01/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E4%B8%AD%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%85%B3%E9%94%AE%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87%E6%B5%85%E6%9E%90/</url>
      <content type="html"><![CDATA[<p><img src="http://ww2.sinaimg.cn/large/9bd9d3e2gw1f6df9vs0ojj20f406w76x.jpg" alt=""></p>
<blockquote>
<p>在对互联网服务进行服务端性能测试时，主要关注两方面的性能指标：</p>
<ul>
<li><strong>业务指标</strong>：如吞吐量(QPS、TPS)、响应时间(RT)、并发数、业务成功率等</li>
<li><strong>资源指标</strong>：如CPU、内存、Disk I/O、Network I/O等资源的消耗情况<br>本文主要介绍一些广泛适用的、基本的<strong>资源指标</strong>以及这些指标在<strong>Linux</strong>服务器的获取方式。</li>
</ul>
</blockquote>
<a id="more"></a>
<h2 id="一-CPU"><a href="#一-CPU" class="headerlink" title="一. CPU"></a>一. CPU</h2><p>关于CPU资源，有三个重要概念是我们需要关注的：使用率、运行队列和上下文切换，这里借助一张描述进程状态的图来进行简要说明：<br><img src="http://ww3.sinaimg.cn/large/9bd9d3e2gw1f6df9v7gnij20b40b4dgo.jpg" alt="Process state -via wikipedia"></p>
<p><div align="center" style="color:#808080;font-size:12px"><em>图1 Process state -via wikipedia</em></div></p>
<ul>
<li><strong>Running</strong>：正在运行的进程</li>
<li><strong>Waiting</strong>：已准备就绪，等待运行的进程</li>
<li><strong>Blocked</strong>：因为等待某些事件完成而阻塞的进程，通常是在等待I/O，如Disk I/O，Network I/O等。</li>
</ul>
<p>这里的Running和Waiting共同构成Linux进程状态中的<em>可运行状态(task_running)</em>，而Blocked状态可以对应Linux进程状态中的<em>不可中断睡眠状态(task_uninterruptible)</em></p>
<p>在Linux可以使用<strong>vmstat</strong>来获取这些数据：</p>
<pre><code class="shell">[hbase@ecs-097 ~]$ vmstat 1
procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 6  0      0 4591436 176804 1185380    0    0     0     0 7915 10357 83  5 12  0  0
</code></pre>
<p><strong>CPU使用率(CPU Utilization Percentages)：</strong>有进程处于Running状态的时间/总时间。在vmstat主要通过<strong>us</strong>、<strong>sys</strong>和<strong>id</strong>三列数据来体现：</p>
<ul>
<li>us：用户占用CPU的百分比</li>
<li>sy：系统(内核和中断)占用CPU的百分比</li>
<li>id：CPU空闲的百分比</li>
</ul>
<p>性能测试指标中，CPU使用率通常用us + sy来计算，其可接受上限通常在70%~80%。另外需要注意的是，在测试过程中，如果sy的值长期大于25%，应该关注in(系统中断)和cs(上下文切换)的数值，并根据被测应用的实现逻辑来分析是否合理。</p>
<p><strong>运行队列进程数(Processes on run queue)：</strong>Running状态 + Waiting状态的进程数，展示了正在运行和等待CPU资源的任务数，可以看作CPU的工作清单，是判断CPU资源是否成为瓶颈的重要依据。vmstat通过<strong>r</strong>的值来体现：</p>
<ul>
<li>r： 可运行进程数，包括正在运行(Running)和已就绪等待运行(Waiting)的。</li>
</ul>
<p>如果r的值等于系统CPU总核数，则说明CPU已经满负荷。在负载测试中，其可接受上限通常不超过CPU核数的2倍。</p>
<p><strong>上下文切换(Context Switches)：</strong>简单来说，context指CPU寄存器和程序计数器在某时间点的内容，(进程)上下文切换即kernel挂起一个进程并将该进程此时的状态存储到内存，然后从内存中恢复下一个要执行的进程原来的状态到寄存器，从其上次暂停的执行代码开始继续执行至频繁的上下文切换将导致sy值增长。vmstat通过cs的值来体现：</p>
<ul>
<li>cs：每秒上下文切换次数。</li>
</ul>
<p>另外还有一个指标用来作为系统在一段时间内的负载情况的参考：<br><strong>平均负载Load Average：</strong>在UNIX系统中，Load是对系统工作量的度量。Load取值有两种情况，多数UNIX系统取运行队列的值(vmstat输出的r)，而<strong>Linux系统取运行队列的值 + 处于<em>task_uninterruptible</em>状态的进程数(vmstat输出的b)</strong>，所以会出现CPU使用率不高但Load值很高的情况。Load Average就是在一段时间内的平均负载，系统工具top、uptime等提供1分钟、5分钟和15分钟的平均负载值。</p>
<pre><code class="shell">[hbase@ecs-097 ~]$ top
top - 19:23:28 up 18:05,  3 users,  load average: 0.80, 0.60, 0.53
</code></pre>
<p>上面示例中的0.80即是1分钟内的Load average，以此类推。<br>当我们需要了解当前系统负载情况时，可以先查看Load average的值，如果系统持续处于高负载(如15分钟平均负载大于CPU总核数的两倍)，则查看vmstat的r值和b值来确认是CPU负荷重还是等待I/O的进程太多。</p>
<h2 id="二-Memory"><a href="#二-Memory" class="headerlink" title="二. Memory"></a>二. Memory</h2><p>Memory资源也有三方面需要重点关注：可用内存，swap占用，页面交换(Paging)，仍然借助一张图来说明：<br><img src="http://ww1.sinaimg.cn/large/9bd9d3e2gw1f6e3jciyp5j20kd0g9myp.jpg" alt="Virtual Memory"></p>
<p><div align="center" style="color:#808080;font-size:12px"><em>图2 Virtual Memory</em></div><br>这里讲到的内存，包括物理内存和虚拟内存，如上图所示，物理内存和硬盘上的一块空间(SWAP)组合起来作为虚拟内存(Virtual Memory)为进程的运行提供一个连续的内存空间，这样的好处是进程可用的内存变大了，但需要注意的是，SWAP的读写速度远低于物理内存，并且物理内存和swap之间的数据交换会增加系统负担。虚拟内存被分成页(x86系统默认页大小为4k)，内核读写虚拟内存以页为单位，当物理内存空间不足时，内存调度会将物理内存上不常使用的内存页数据存储到磁盘的SWAP空间，物理内存与swap空间之间的数据交换过程称为页面交换(Paging)。</p>
<p><strong>可用内存(free memory)：</strong>内存占用的直观数据，vmstat输出free的值，可用内存过小将影响整个系统的运行效率，对于稳定运行的系统，free可接受的范围通常应该大于物理内存的20%，即内存占用应该小于物理内存的80%。在压力测试时，系统内存资源的情况应该用可用内存结合页面交换情况来判断，如果可以内存很少，但页面交换也很少，此时可以认为内存资源还对系统性能构成严重影响。</p>
<p><strong>页面交换(Paging)：</strong>页面交换包括从SWAP交换到内存和从内存交换到SWAP，如果系统出现频繁的页面交换，需要引起注意。可以从vmstat的si和so获取：</p>
<ul>
<li>si：每秒从SWAP读取到内存的数据大小</li>
<li>so：每秒从内存写入到SWAP的数据大小</li>
</ul>
<p><strong>SWAP空间占用:</strong>可以从vmstat的swpd来获取当前SWAP空间的使用情况，应该和页面交换结合来分析，比如当swpd不为0，但si，so持续保持为0时，内存资源并没有成为系统的瓶颈。</p>
<h2 id="三-Disk"><a href="#三-Disk" class="headerlink" title="三. Disk"></a>三. Disk</h2><p>磁盘通常是系统中最慢的一环，一是其自身速度慢，即使是SSD，其读写速度与内存都还存在数量级的差距，二是其离CPU最远。另外需要说明的是磁盘IO分为<strong>随机IO</strong>和<strong>顺序IO</strong>两种类型，在性能测试中应该先了解被测系统是偏向哪种类型。</p>
<ul>
<li>随机IO：随机读写数据，读写请求多，每次读写的数据量较小，其IO速度更依赖于磁盘每秒能IO次数(IOPS)。</li>
<li>顺序IO：顺序请求大量数据，读写请求个数相对较少，每次读写的数据量较大，顺序IO更重视每次IO的数据吞吐量。</li>
</ul>
<p>对于磁盘，首要关注使用率，IOPS和数据吞吐量，在Linux服务区，可以使用iostat来获取这些数据。</p>
<pre><code class="shell">[hbase@ecs-097 ~]$ iostat -dxk 1
Linux 2.6.32-504.3.3.el6.x86_64 (ecs-097)     08/01/2016     _x86_64_    (4 CPU)
avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           0.52    0.00    0.13    0.06    0.00   99.28
Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await  svctm  %util
xvda              0.10     6.63    0.40    2.57     6.22    36.80    29.00     0.04   14.63   1.19   0.35
</code></pre>
<p><strong>(设备)使用率：</strong>统计过程中处理I/O请求的时间与统计时间的百分比，即iostat输出中的%util，如果该值大于60%，很可能降低系统的性能表现。</p>
<p><strong>IOPS：</strong>每秒处理读/写请求的数量，即iostat输出中的r/s和w/s，个人PC的机械硬盘IOPS一般在100左右，而各种公有云/私有云的普通服务器，也只在百这个数量级。预先获取到所用服务区的IOPS能力，然后在性能测试中监控试试的IOPS数据，来衡量当前的磁盘是否能满足系统的IO需求。</p>
<p><strong>数据吞吐量：</strong>每秒读/写的数据大小，即iostat输出中的rkB/s和wkB/s，通常磁盘的数据吞吐量与IO类型有直接关系，顺序IO的吞吐能力明显优与随机读写，可以预先测得磁盘在随机IO和顺序IO下的吞吐量，以便于测试时监控到的数据进行比较衡量。</p>
<h2 id="四-Network"><a href="#四-Network" class="headerlink" title="四. Network"></a>四. Network</h2><p>网络本身是系统中一个非常复杂的部分，但常规的服务端性能测试通常放在一个局域网进行，因为我们首先关注被测系统自身的性能表现，并且需要保证能在较少的成本下发起足够大的压力。因此对于多数系统的性能测试，我们主要关注网络<strong>吞吐量</strong>即可，对于稳定运行的系统，需要为被测场景外的业务流出足够的带宽；在压力测试过程中，需要注意瓶颈可能来自于带宽。<br>在Linuxf服务器，可以使用iptraf来查看本机网络吞吐量，如：</p>
<pre><code class="shell">[root@ecs-097 ~]# iptraf -d eth0
x Total rates:         67.8 kbits/sec        Broadcast packets:            0                                                                                                                x
x                      54.2 packets/sec      Broadcast bytes:              0                                                                                                                x
x                                                                                                                                                                                           x
x Incoming rates:      19.2 kbits/sec                                                                                                                                                       x
x                      25.4 packets/sec                                                                                                                                                     x
x                                            IP checksum errors:           0                                                                                                                x
x Outgoing rates:      48.7 kbits/sec                                                                                                                                                       x
x                      28.8 packets/sec
</code></pre>
<h2 id="五-总结"><a href="#五-总结" class="headerlink" title="五. 总结"></a>五. 总结</h2><p>性能测试中，数据收集很重要，但是更重要的是快速抓住关键数据，读懂数据的含义。<br>本文主要介绍服务端性能测试中，对于CPU、内存等各种系统资源，通常首要关注的数据，以及这些数据在Linux服务器上的获取方式。<br>在实际测试中，通常会持续收集这些数据，如使用nmon，JMeter的PerfMon插件，以及zabbix等专门的系统监控工具，这就不在本文展开了。</p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p><a href="https://en.wikipedia.org/wiki/Load_%28computing%29" target="_blank" rel="external">Load (computing)</a><br><a href="https://en.wikipedia.org/wiki/Process_state" target="_blank" rel="external">Process state</a><br><a href="http://techblog.netflix.com/2015/11/linux-performance-analysis-in-60s.html" target="_blank" rel="external">Linux Performance Analysis in 60,000 Milliseconds</a></p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[HBase入门精要--百闻不如一Run]]></title>
      <url>http://www.aloo.me/2016/07/24/HBase%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81-%E7%99%BE%E9%97%BB%E4%B8%8D%E5%A6%82%E4%B8%80Run/</url>
      <content type="html"><![CDATA[<p><img src="http://ww1.sinaimg.cn/mw690/9bd9d3e2gw1f64pay4toej20d203c74i.jpg" alt="HBase Logo"></p>
<h2 id="零-导读"><a href="#零-导读" class="headerlink" title="零.导读"></a>零.导读</h2><p>HBase，基于Google Bigtable实现的开源、分布式、可伸缩的列式存储数据库，诞生于Hadoop，也是Hadoop生态的重要一环，如今作为一个Apache顶级项目，早已经不能将其仅仅看作Hadoop的一部分，基于Storm，Spark等框架的数据处理方案中，都有它的身影，可以说它已经成为大数据工具箱中非常重要的一种数据存储工具，也因此必然会被很纳入很多人学习计划。<br>对于一个新技术的入门，我认为一种有效的学习方式是：</p>
<blockquote>
<p>对其有简要认知后，通过Quick Start式的使用，获得直观的感知，消除距离感，然后再带着使用过程中的疑问去了解其背后的真相，最后支撑我们将其应用到实际工程。</p>
</blockquote>
<p>我将消除距离感这一阶段，称之为<strong>百闻不如一Run</strong>。</p>
<p>本文分三部分带你完成对HBase的<em>百闻不如一Run</em>：数据模型概述、环境部署和基本操作。</p>
<p><em>版本：本文基于HBase 1.2.2 –Release date: 11/Jul/16 </em></p>
<a id="more"></a>
<h2 id="一-HBase数据模型"><a href="#一-HBase数据模型" class="headerlink" title="一. HBase数据模型"></a>一. HBase数据模型</h2><p>HBase是对Bigtable的开源实现，所以先来认识一下Bigtabl概念，引用<a href="http://research.google.com/archive/bigtable.html" target="_blank" rel="external">Google’s BigTable Paper</a>中的精简描述：</p>
<blockquote>
<p>A Bigtable is a sparse, distributed, persistent multidimensional sorted map.</p>
<p>The map is indexed by a row key, column key, and a timestamp; each value in the map is an uninterpreted array of bytes.</p>
</blockquote>
<p>HBase的数据模型与此非常相似，用一张参考自上述论文的图来辅助理解：</p>
<p><img src="http://ww2.sinaimg.cn/large/9bd9d3e2gw1f64paypqtyj20ri081gmx.jpg" alt="图1 HBase表中某一行所存储数据的一种可视化呈现"></p>
<p><div align="center" style="color:#808080;font-size:12px"><em>图1 HBase表中某一行所存储数据的一种可视化呈现</em></div><br>HBase的结构：</p>
<ul>
<li><em>命名空间(namespace):0.96版本开始支持，是对多个表的逻辑分组，类似于关系数据库的database，在本文暂不关心。</em></li>
<li><strong>表(table)：</strong>一张表中包含若干行。</li>
<li><strong>行(row)：</strong>一行包括一个行键(row key)和若干列族，一张表中的行<strong>按照行键排序</strong>，并用行键作为索引。图1中展示了一个行键为row1的行。</li>
<li><strong>列族(column family)：</strong>每个列族包含若干个列，<strong>列族需要在建表时预定义，运行期间可以动态加入新的列</strong>。图1中的”data”、”meta”就是row1行中的两个列族。 在物理层面，HBase的数据存储是在列族这一层级进行组织，每个列族单独存储。</li>
<li><strong>列(column)：</strong>每个列都归属于某个列族，以列族名作为前缀，通常使用<em>列族名：修饰符</em>的形式来标识一个列，可以将其中的修饰符部分看作列名。图1中的”meta:mimetype”和”meta:size”即是列族meta中的成员。</li>
<li><strong>单元格(cell)：</strong>存储的每一个值存放在一个单元格中，由<strong><em>[行，列，版本号]</em></strong>来唯一指向一个单元格。图1中彩色标识的矩形块即可看作是一个单元格</li>
<li><strong>版本(version)：</strong>版本号默认是时间戳形式，同一列中可能包含若干单元格，这些单元格由版本号唯一区分，<strong>根据版本号降序排列</strong>，HBase查询时，如果不指定版本号，默认返回最新的值。图1中的t3,t6等即代表版本号。<strong>版本是HBase多维特性的表现</strong>。</li>
</ul>
<p>Google论文中Bigtable描述为一个map，那么从Map的维度，用JSON格式，HBase的结构可以理解为：</p>
<pre><code class="Json">{
  &quot;row1&quot; : {
    &quot;family1&quot; : {
      &quot;column1&quot; : {
        timestamp2 : &quot;value1&quot;,
        timestamp3 : &quot;value2&quot;
        },
      &quot;column2&quot; : {timestamp6 : &quot;value3&quot;}
    },
    &quot;family2&quot; : { ... }
  },
  &quot;row2&quot; : {
    &quot;family3&quot; : { ... }
  },
}
</code></pre>
<p>而关于其<em>稀疏</em>这一特性，可以用下图来辅助理解：</p>
<p><img src="http://ww2.sinaimg.cn/mw690/9bd9d3e2gw1f64pb0bqxcj20rr0poadb.jpg" alt="图2 HBase的行和列所构成的更像标签，而不是表格"></p>
<p><div align="center" style="color:#808080;font-size:12px"><em>图2 HBase的行和列所构成的更像标签，而不是表格</em></div><br>对于我们熟悉的关系型数据库，如MySQL，一张表中每一行都有相同的列，即使部分行的某些列不存储数据，也有消耗，如图中的NULL。而HBase，各行是相对独立的，可以有完全不同的列。</p>
<h2 id="二-部署"><a href="#二-部署" class="headerlink" title="二.部署"></a>二.部署</h2><p>如果最初阶段你需要HBase环境的主要目的是想熟悉对HBase的CRDU操作，那么看完<em>独立部署</em>后，可以直接跳到<em>三.基本操作</em>进行数据库操作。<br>如果希望在部署环境过程中对HBase的架构也做一个简要了解，那么建议进行<em>伪分布式部署</em>；如果伪分布式部署你能够很快完成，那么相信完全的分布式部署对你来说也并不困难，并且本文的主要目的是快速入门，因此不提供完全分布式部署的过程指引，如有需要，请参考官方指南<a href="http://hbase.apache.org/book.html#quickstart_fully_distributed" target="_blank" rel="external">quickstart_fully_distributed</a>。</p>
<h3 id="0-基础条件"><a href="#0-基础条件" class="headerlink" title="0. 基础条件"></a><strong>0. 基础条件</strong></h3><ul>
<li>需要Java，支持JDK7和JDK8</li>
<li>需要ssh，伪分布式部署需要<em>ssh localhost</em>能正常连接，分布式部署需要配置各节点间的无密码登陆(<em>ssh passwordless login</em>)</li>
</ul>
<p><em>注：1.0.0版本开始，HBase内部组件(HMaster,HRegionServer)的默认端口从60xxx变更为16xxx</em></p>
<h3 id="1-独立部署"><a href="#1-独立部署" class="headerlink" title="1. 独立部署"></a><strong>1. 独立部署</strong></h3><blockquote>
<p>如果想要最快速的搭建供你练习HBase数据库操作的环境，那么这可能是你想要的。<br>独立部署模式下，HBase的所有进程都运行在一个JVM中，数据直接存储在本地磁盘。</p>
</blockquote>
<p>a. 下载安装包并解压</p>
<pre><code>wget https://mirrors.tuna.tsinghua.edu.cn/apache/hbase/1.2.2/hbase-1.2.2-bin.tar.gz
tar zxvf hbase-1.2.2-bin.tar.gz -C target-dir
</code></pre><p>b. 配置</p>
<ul>
<li>在<em>/etc/hosts</em>中配置localhost的地址：<em>127.0.0.1 localhost</em></li>
<li>JAVA_HOME：在<em>conf/hbase-env.sh</em>中配置,例如：<em>export JAVA_HOME=/usr/local/jdk</em></li>
<li>配置HBase和zookeeper保存数据的位置：<ul>
<li>如果不配置，默认写在/tmp目录下</li>
<li>在<em>conf/hbase-site.xml.</em>中配置,地址格式有两种，例如：<pre><code class="xml">&lt;configuration&gt;
  &lt;property&gt;
      &lt;name&gt;hbase.rootdir&lt;/name&gt;
      &lt;value&gt;file:///home/hbase/hbase1.2.2&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
      &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt;
      &lt;value&gt;/home/hbase/hbase1.2.2/zookeeper&lt;/value&gt;
  &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>
</li>
</ul>
</li>
</ul>
<p>c. 启动和停止<br>   可以直接在HBase安装目录运行<em>bin/start-hbase.sh</em>启动：</p>
<pre><code class="bash">[hbase@iZ25n0dx8rxZh base]$ ./bin/start-hbase.sh 
starting master, logging to /usr/local/hbase/bin/../logs/hbase-hbase-master-iZ25n0dx8rxZ.out
</code></pre>
<p>启动日志默认位于<em>./logs/hbase-[username]-master-[yourhostname].log</em>，启动成功后，用<em>jps</em>命令可以看到名为HMaster的进程。接下来，你就可以使用hbase的shell来进行操作练习了。<br>要停止hbase，使用<em>bin/stop-hbase.sh</em>。</p>
<p>d. UI访问<br>  Hbase内建了一个用Jetty提供服务的web UI页面来查看该HBase环境的各种信息，默认端口16010，尝试用<em><a href="http://hostip:16010/" target="_blank" rel="external">http://hostip:16010/</a></em>来访问。</p>
<h3 id="2-伪分布式部署"><a href="#2-伪分布式部署" class="headerlink" title="2. 伪分布式部署"></a><strong>2. 伪分布式部署</strong></h3><blockquote>
<p>伪分布式模式下，HBase的所有组件还是运行在同一台主机，不同的是，每个组件独立运行在不同的JVM。更重要的是，我们可以在该模式下启动多个Regionserver和master，构成一个虚拟的分布式架构以供学习，这是很多<em>快速入门</em>文章所略过的重点。<br>该模式下，可以对接HDFS，但那涉及hadoop的部署，为以更短的时间达到当前阶段的目的，本文仍存储在本地磁盘。</p>
</blockquote>
<p><strong>a. HBase架构概要</strong><br><img src="http://ww1.sinaimg.cn/large/9bd9d3e2gw1f64pazfmiaj20mc0ep76l.jpg" alt="图3 HBase架构概要图"></p>
<p><div align="center" style="color:#808080;font-size:12px"><em>图3 HBase架构概要图</em></div><br>作为入门阶段，先从粗粒度对HBase的架构进行简单了解：<br><strong>HMaster：</strong>主要负责监控集群、管理RegionServers的负责均衡等，可以用主-备形式部署多个Master。<br><strong>HRegionServers：</strong>负责响应用户的I/O操作请求，客户端对HBase读写数据是与RegionServer交互。<br><strong>Zookeeper：</strong>负责选举Master的主节点；服务注册；保存RegionServers的状态等。可以使用系统内建的zookeeper，也可以使用独立的zookeeper，只需要在配置文件中调整即可。<br><strong>HDFS：</strong>真正的数据持久层，并非必须是HDFS文件系统，但搭配HDFS是最佳选择，也是目前应用最广泛的选择。</p>
<p><strong>b. 开始部署</strong><br>伪分布式模式下，需要保证<em>ssh localhost</em>能够成功连接(将HBase所属用户的publickey追加到其自身的authorized_keys中)。如果你跟随本文启动了独立模式的HBase，先将其停止。</p>
<ul>
<li>开启分布式配置<br>最基本的伪分布式配置，只需要在独立模式的配置基础上，追加开启分布式模式的配置，即将<em>hbase.cluster.distributed</em>配置为true，例如：<pre><code class="xml">&lt;configuration&gt;
    &lt;property&gt;
      &lt;name&gt;hbase.rootdir&lt;/name&gt;
      &lt;value&gt;/home/hbase/hbase1.2.2&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
      &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt;
      &lt;value&gt;file:///home/hbase/hbase1.2.2/zookeeper&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
      &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;
      &lt;value&gt;true&lt;/value&gt;
    &lt;/property&gt;
 &lt;/configuration&gt;
</code></pre>
</li>
<li>在安装目录运行<em>bin/start-hbase.sh</em><pre><code class="bash">[hbase@iZ25n0dx8rxZ hbase]$ ./bin/start-hbase.sh
localhost: starting zookeeper, logging to /usr/local/hbase/bin/../logs/hbase-hbase-zookeeper-iZ25n0dx8rxZ.out
starting master, logging to /usr/local/hbase/bin/../logs/hbase-hbase-master-iZ25n0dx8rxZ.out
starting regionserver, logging to /usr/local/hbase/bin/../logs/hbase-hbase-1-regionserver-iZ25n0dx8rxZ.out
</code></pre>
可以看到依次启动了zookeeper、master和regionserver，启动日志为<em>./logs</em>路径下的<em>.log</em>文件。</li>
<li><p>查看启动的进程以及占用的端口：</p>
<pre><code class="bash">[hbase@iZ25n0dx8rxZ logs]$ jps
4610 HRegionServer
4456 HQuorumPeer
5338 Jps
4522 HMaster
[hbase@iZ25n0dx8rxZ logs]$ netstat -lnp|grep 4522
tcp        0      0 172.16.5.23:16000           0.0.0.0:*                   LISTEN      4522/java           
tcp        0      0 0.0.0.0:16010               0.0.0.0:*                   LISTEN      4522/java           
[hbase@iZ25n0dx8rxZ logs]$ netstat -lnp|grep 4610
tcp        0      0 172.16.5.23:16201           0.0.0.0:*                   LISTEN      4610/java           
tcp        0      0 0.0.0.0:16301               0.0.0.0:*                   LISTEN      4610/java           
[root@iZ25n0dx8rxZ logs]$ netstat -lnp|grep 4456
tcp        0      0 0.0.0.0:2188                0.0.0.0:*                   LISTEN      4456/java
</code></pre>
<ul>
<li>HMaster占用16000(工作进程)和16010(Master的web UI服务端口)</li>
<li>HRegionServer占用16201(工作进程)和16301(Regionserver的web UI服务)</li>
<li>HQuorumPeer是HBase内建zookeeper进程，默认端口2181<em>(即zookeeper的默认配置)</em>。如果是独立的zookeeper，进程名是<em>QuorumPeerxxx</em>，没有第一个字母H。</li>
</ul>
</li>
<li><p><strong>启动和停止备份Master节点<em>(backup HMaster)</em></strong>：</p>
<ul>
<li>运行<em>./bin/local-master-backup.sh start n</em>来启动一个备份节点，如：<pre><code class="bash">[hbase@iZ25n0dx8rxZ hbase]$ ./bin/local-master-backup.sh start 1
starting master, logging to /usr/local/hbase/bin/../logs/hbase-hbase-1-master-iZ25n0dx8rxZ.out
</code></pre>
启动成功后，<em>jps</em>命令可以看到总共有两个HMaster进程。</li>
<li><p>端口：<strong>n</strong>用来指定占用的端口号，规则为<strong>[默认端口号+n]</strong>,如例子中的<em>./bin/local-master-backup.sh start 1</em>所启动的HMaster占用16001(工作端口)和16011(web UI服务端口)，以此类推。</p>
</li>
<li><p>日志：启动日志在<em>./logs/hbase-[username]-n-master-[hostname].log</em>，在上例的日志中，可以看到这样一行日志说明该节点目前是作为备用节点：</p>
<pre><code class="bash">master.ActiveMasterManager: Another master is the active master, iz25n0dx8rxz,16000,1469262015657; waiting to become the next active master
</code></pre>
<p><strong><em>注意：</em></strong>如果使用1.2.2之前版本的安装包(如1.1.5)，运行启动脚本后backup Master可能会因为端口被占用而无法启动，这是因为脚本里面，没有按照规则更改backup Master的工作端口，启动时仍然使用默认的16000，而该端口已经被前面启动的主节点占用。<strong>可以通过如下方法解决该问题：</strong><br>手动在<em>./bin/local-master-backup.sh</em>脚本中为<em>HBASE_MASTER_ARGS</em>赋值的这句话内添加<em>-D hbase.master.port=`expr 16000 + $DN` \ </em>来设置backup Master的工作端口，添加后这句话的完整内容如下：</p>
<pre><code class="bash">HBASE_MASTER_ARGS=&quot;\
-D hbase.master.port=`expr 16000 + $DN` \
-D hbase.master.info.port=`expr 16010 + $DN` \
-D hbase.regionserver.port=`expr 16020 + $DN` \
-D hbase.regionserver.info.port=`expr 16030 + $DN` \
--backup&quot;
</code></pre>
</li>
<li>web UI访问地址：<em><a href="http://ip:1601n" target="_blank" rel="external">http://ip:1601n</a></em></li>
<li>主节点切换：要观察HBase的Master组件主节点切换，可以使用<em>kill -9 PID</em>停止当前主节点<em>(即最初启动的HMaster)</em>，此时刚启动的备份节点将切换为主节点，可以在备份节点的日志<em>(./logs/hbase-[username]-1-master-[hostname].log)</em>中看到如下内容：<pre><code class="bash">INFO  [iZ25n0dx8rxZ:16001.activeMasterManager] master.ActiveMasterManager: Deleting ZNode for /hbase/backup-masters/iz25n0dx8rxz,16001,1469267021567 from backup master directory
INFO  [iZ25n0dx8rxZ:16001.activeMasterManager] master.ActiveMasterManager: Registered Active Master=iz25n0dx8rxz,16001,1469267021567
</code></pre>
</li>
<li>停止：使用<em>./bin/local-master-backup.sh stop n</em>来停止你的备份节点。</li>
<li>多备：可以一次启动多个backup HMaster，命令类似于<em>./bin/local-master-backup.sh start x y z</em>。</li>
</ul>
</li>
<li><strong>启动和停止额外的RegionServer</strong><ul>
<li>运行额外RegionServer的方式与backup HMaster类似，启动：<em>./bin/local-regionservers.sh start n</em>，停止：<em>./bin/local-regionservers.sh stop n</em></li>
<li>web UI访问地址：<em><a href="http://ip:1630n" target="_blank" rel="external">http://ip:1630n</a></em></li>
</ul>
</li>
</ul>
<h2 id="三-基本操作"><a href="#三-基本操作" class="headerlink" title="三. 基本操作"></a>三. 基本操作</h2><blockquote>
<p>本节介绍使用HBase shell在直接在服务器上对HBase进行基本操作，HBase shell是在(J)Ruby的IRB的基础上增加了HBase特有的命令，遵循IRB的操作。</p>
</blockquote>
<ol>
<li>连接：<em>./bin/hbase shell</em><pre><code class="bash">[hbase@iZ25n0dx8rxZ hbase]$ ./bin/hbase shell
HBase Shell; enter &#39;help&lt;RETURN&gt;&#39; for list of supported commands.
Type &quot;exit&lt;RETURN&gt;&quot; to leave the HBase Shell
Version 1.2.2, r3f671c1ead70d249ea4598f1bbcc5151322b3a13, Fri Jul  1 08:28:55 CDT 2016
hbase(main):001:0&gt;
</code></pre>
</li>
<li><p>建表：<em>create ‘test’, ‘cf1’, ‘cf2’</em>，即[create ‘表名’, ‘列族名’,..]，列族名可以有多个，<em>list</em>用于查看有哪些表</p>
<pre><code class="bash">hbase(main):008:0&gt; create &#39;test&#39;,&#39;cf1&#39;,&#39;cf2&#39;
0 row(s) in 1.2280 seconds
=&gt; Hbase::Table - test
hbase(main):009:0&gt;
</code></pre>
</li>
<li><p>写数据：<em>put ‘test’, ‘row1’, ‘cf1:c1’, ‘value1’</em>，即[put ‘表名’,’行键’,’列族名:列名’,’数据’]</p>
<pre><code class="bash">hbase(main):001:0&gt; put &#39;test&#39;,&#39;row1&#39;,&#39;cf1:c1&#39;,&#39;value1&#39;
0 row(s) in 0.3160 seconds
hbase(main):002:0&gt; put &#39;test&#39;,&#39;row1&#39;,&#39;cf1:c1&#39;,&#39;value2&#39;
0 row(s) in 0.3020 seconds
</code></pre>
</li>
<li>查看数据：<ul>
<li>全表数据：<em>scan ‘test’</em>，即[scan ‘表名’]<pre><code class="bash">hbase(main):001:0&gt; scan &#39;test&#39;
ROW                                            COLUMN+CELL                                                                                                                             
row1                                          column=cf1:c1, timestamp=1469277197280, value=value2                                                                                    
1 row(s) in 0.2710 seconds
hbase(main):002:0&gt;
</code></pre>
可以看到在put时指定的属性之外，有一个<strong>timestamp</strong>属性来作为版本标识，我们查看全表数据时，row1的cf1:c1列中展示的值是我们后一次写入的value2，sacn和get在不指定版本时，得到的是最近版本的数据</li>
<li>指定行的数据：<em>get ‘test’, ‘row1’</em>，即[get ‘表名’,’行键’]</li>
<li>指定版本的数据：<pre><code class="bash">hbase(main):005:0&gt; get &#39;test&#39;,&#39;row1&#39;,{COLUMN=&gt;&#39;cf1:c1&#39;,TIMESTAMP=&gt;1469277197280}
COLUMN                                         CELL                                                                                                                                    
cf1:c1                                        timestamp=1469277197280, value=value1                                                                                                   
1 row(s) in 0.0270 seconds
hbase(main):006:0&gt;
</code></pre>
</li>
</ul>
</li>
<li><strong>版本数量</strong>：每个列族有一个单独的VERSIONS属性，默认为1，可以在建表时指定：<code>create &#39;test1&#39;,{NAME=&gt;&#39;cf1&#39;,VERSIONS=&gt;3}</code>，代表该列族的每个列最多保存最近3个版本的数据，也可以通过<em>alter</em>来更新：<code>alter &#39;test1&#39;,NAME=&gt;&#39;cf1&#39;,VERSIONS=&gt;3</code>。查询数据时，可以通过设置VERSIONS来指定显示最近几个版本的数据<em>(最大范围不超过该列族的VERSIONS属性值)</em>：<code>get &#39;test&#39;,&#39;row1&#39;,{COLUMN=&gt;&#39;cf1:c1&#39;,VERSIONS=&gt;2}</code></li>
<li>删除数据：<ul>
<li>删除指定单元格：<em>delete ‘test’,’row1’,’cf1:c1’,1469277197280</em>，<em>将删除指定版本以及比其更早的版本</em></li>
<li>删除指定行的指定列：<em>delete ‘test’,’row1’,’cf1:c1’</em></li>
<li>删除整行： <em>deleteall ‘test’,’row1’</em></li>
</ul>
</li>
<li>禁用表：<em>disable ‘test’</em>，即[disable ‘表名’]，在要删除表或者变更配置时，要先禁用该表。相应的，要重新启用该表，使用[enable ‘表名’]</li>
<li>删除表：<em>drop ‘test’</em>，即[drop ‘表名’]</li>
<li>退出HBase shell:<em>exit</em>或者<em>quit</em></li>
<li>完整的命令列表，参考<a href="https://learnhbase.wordpress.com/2013/03/02/hbase-shell-commands/" target="_blank" rel="external">hbase-shell-commands</a></li>
</ol>
<h2 id="四-尾声"><a href="#四-尾声" class="headerlink" title="四. 尾声"></a>四. 尾声</h2><p>本文简要介绍了HBase的数据模型、快速搭建基本操作环境的步骤以及基于HBase shell的HBase数据库基本操作，旨在协助想要学习HBase的朋友快速进入到对HBase的操作和使用阶段，消除陌生感和距离感。在这之后，我们可能想问，真正应用在工程上的操作HBase的方式有哪些，HBase存取数据的完整过程是怎样的，怎样去设计一个适合的表结构，等等，那么，请带着这些问题继续你的HBase之路。</p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p><a href="https://hbase.apache.org/book.html" target="_blank" rel="external">Apache HBase ™ Reference Guide</a><br><a href="http://research.google.com/archive/bigtable.html" target="_blank" rel="external">Google’s BigTable Paper</a><br><a href="http://jimbojw.com/wiki/index.php?title=Understanding_Hbase_and_BigTable" target="_blank" rel="external">Understanding HBase and BigTable</a></p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[JMeter性能测试3.0时代之-多维度的图形化HTML报告]]></title>
      <url>http://www.aloo.me/2016/07/17/JMeter%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%953-0%E6%97%B6%E4%BB%A3%E4%B9%8B-%E5%A4%9A%E7%BB%B4%E5%BA%A6%E7%9A%84%E5%9B%BE%E5%BD%A2%E5%8C%96HTML%E6%8A%A5%E5%91%8A/</url>
      <content type="html"><![CDATA[<p><img src="http://ww2.sinaimg.cn/large/9bd9d3e2gw1f5x232chyaj20b5096q3q.jpg" alt=""></p>
<blockquote>
<p>在上一篇博客<a href="http://www.aloo.me/2016/07/05/JMeter%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%953-0%E6%97%B6%E4%BB%A3%E4%B9%8B-%E5%85%A8%E6%96%B0JMeter%E6%8F%92%E4%BB%B6%E7%AE%A1%E7%90%86/">JMeter性能测试3.0时代之-全新JMeter插件管理</a>中我说会写真正的JMeter 3.0新特性，时隔两周，总算在这个周末，暂停其他安排，来继续这个未完成的系列。<br>本文主要介绍JMeter3.0引入的新特性：<a href="https://jmeter.apache.org/usermanual/generating-dashboard.html" target="_blank" rel="external">Dashboard Report</a>，图形化的HTML格式多维度测试报告。借助这个特性，可以很大程度上降低我们搭建基于JMeter的性能测试平台时，在结果展示上的难度，将更多的精力放在后端的平台功能而不是去临时学习前端图表库。</p>
</blockquote>
<a id="more"></a>
<h2 id="一-为什么谈这个新特性"><a href="#一-为什么谈这个新特性" class="headerlink" title="一.为什么谈这个新特性"></a>一.为什么谈这个新特性</h2><p>在JMeter3.0之前，官方只提供在工具的UI上对测试结果部分维度的图形化展示，这对我带来了两方面的困扰：</p>
<ol>
<li>在实际使用中，在平台中集成JMeter后需要页面展示TPS曲线，平均响应时间曲线等图表时，需要我们手动操刀摆弄如Hightcharts/Echarts等前端图表库。</li>
<li>要查看历史的测试结果，需要启动JMeter的图形化界面，导入保存的CSV结果，过程繁琐，并且当结果集较大时，JMeter需要耗费相当多的时间在界面上展示图形化报告。</li>
</ol>
<p>本文讨论的新特性为这两个问题带来了较好的解决办法：</p>
<ul>
<li>新特性良好的实现了结果数据可视化，生成的报告是HTML页面形式，并且包含大多数实际测试中关心的度量维度的，可以便捷地嵌入到平台，从浏览器来查看每次测试运行的。</li>
<li>只要保留生成的HTML页面，后期要查看该次测试的结果，只需要在浏览器打开即可，方便快捷。</li>
</ul>
<h2 id="二-新特性简介"><a href="#二-新特性简介" class="headerlink" title="二.新特性简介"></a>二.新特性简介</h2><p>JMeter3.0提供一个用于生成<strong>HTML页面格式图形化报告</strong>的扩展模块。该模块支持通过两种方式生成多维度图形化测试报告：</p>
<ol>
<li>在JMeter性能测试结束时，自动生成本次测试的HTML图形化报告</li>
<li>使用一个已有的结果文件(如CSV文件)来生成该次结果的HTML图形化报告</li>
</ol>
<p><strong>其默认提供的度量维度包括：</strong></p>
<ol>
<li>APDEX(Application Performance Index)指数</li>
<li>聚合报告<ul>
<li>类似于UI上的<em>Aggregate Report</em></li>
</ul>
</li>
<li>Errors报告<ul>
<li>展示不同错误类型的数量以及百分比</li>
</ul>
</li>
<li>响应时间变化曲线<ul>
<li>展示平均响应时间随时间变化情况</li>
<li>类似于JMeter Plugins在UI上的<em>jp@gc - Response Times Over Time</em></li>
</ul>
</li>
<li>数据吞吐量时间曲线<ul>
<li>展示每秒数据吞吐量随时间变化的情况</li>
<li>类似于JMeter Plugins在UI上的<em>jp@gc - Bytes Throughput Over Time</em></li>
</ul>
</li>
<li>Latency time变化曲线<ul>
<li>展示Latency time随时间变化的情况</li>
<li>类似于JMeter Plugins在UI上的<em>jp@gc - Response Latencies Over Time</em></li>
</ul>
</li>
<li>每秒点击数曲线<ul>
<li>类似于JMeter Plugins在UI上的<em>jp@gc - Hits per Second</em></li>
</ul>
</li>
<li>HTTP状态码时间分布曲线<ul>
<li>展示响应状态码随时间的分布情况</li>
<li>类似于JMeter Plugins在UI上的<em>jp@gc - Response Codes per Second</em></li>
</ul>
</li>
<li>事务吞吐量时间曲线(TPS)<ul>
<li>展示每秒处理的事务数随时间变化情况</li>
<li>类似于JMeter Plugins在UI上的<em>jp@gc - Transactions per Second</em></li>
</ul>
</li>
<li>平均响应时间与每秒请求数的关系图<ul>
<li>展示平均响应时间与每秒请求数(可以理解为QPS)的关系</li>
</ul>
</li>
<li>Latency time与每秒请求数的关系图<ul>
<li>展示Latency time与每秒请求数的关系</li>
</ul>
</li>
<li>响应时间百分位图<ul>
<li>响应时间的百分位分布图</li>
</ul>
</li>
<li>活动线程数变化曲线<ul>
<li>展示测试过程中活动线程数随时间变化情况</li>
</ul>
</li>
<li>平均响应时间与线程数的关系图<ul>
<li>展示平均响应时间与线程数的关系</li>
<li>类似于JMeter Plugins在UI上的<em>jp@gc - Response Times vs Threads</em></li>
</ul>
</li>
<li>柱状响应时间分布图<ul>
<li>展示落在各个平均响应时间区间的请求数情况</li>
</ul>
</li>
</ol>
<p><em>注1：Latency time没有翻译成中文，这里对其计算方式做注解：</em><br>    <em>Latency time = 接收到响应的第一个字节的时间点 - 请求开始发送的时间点</em></p>
<blockquote>
<p> <em>from just before sending the request to just after the first response has been received</em><br>– <a href="http://jmeter.apache.org/usermanual/glossary.html" target="_blank" rel="external">Apache JMeter Glossary</a></p>
</blockquote>
<p>  <em>响应时间(JMeter术语中的Elapsed time) = 接收完所有响应内容的时间点 - 请求开始发送的时间点</em></p>
<blockquote>
<p><em>from just before sending the request to just after the last response has been received</em><br>– <a href="http://jmeter.apache.org/usermanual/glossary.html" target="_blank" rel="external">Apache JMeter Glossary</a></p>
</blockquote>
<p><em>注2：Apdex 标准从用户的角度出发，将对应用响应时间的表现，转为用户对于应用性能的可量化为范围为 0-1 的满意度评价。。</em></p>
<blockquote>
<p><strong>Apdex (Application Performance Index)</strong> is an open standard developed by an alliance of companies. It defines a standard method for reporting and comparing the performance of software applications in computing.<br>– <a href="https://en.wikipedia.org/wiki/Apdex" target="_blank" rel="external">wikipedia</a></p>
</blockquote>
<h2 id="三-快速入门"><a href="#三-快速入门" class="headerlink" title="三.快速入门"></a>三.快速入门</h2><h3 id="1-确认基本配置"><a href="#1-确认基本配置" class="headerlink" title="1.确认基本配置"></a>1.确认基本配置</h3><ul>
<li>在jmeter.properties或者user.properties确认如下配置项：<pre><code class="xml">jmeter.save.saveservice.bytes = true
jmeter.save.saveservice.label = true
jmeter.save.saveservice.latency = true
jmeter.save.saveservice.response_code = true
jmeter.save.saveservice.response_message = true
jmeter.save.saveservice.successful = true
jmeter.save.saveservice.thread_counts = true
jmeter.save.saveservice.thread_name = true
jmeter.save.saveservice.time = true
# the timestamp format must include the time and should include the date.
# For example the default, which is milliseconds since the epoch: 
jmeter.save.saveservice.timestamp_format = ms
# Or the following would also be suitable
jmeter.save.saveservice.timestamp_format = yyyy/MM/dd HH:mm:ss
</code></pre>
</li>
<li>如果希望在Errors报告中展示更详细数据，需要确保如下配置<ul>
<li><code>jmeter.save.saveservice.assertion_results_failure_message = true</code></li>
<li>如果使用了事务控制器(Transaction Controller)，确认<em>Generate parent sample</em>为未勾选状态</li>
</ul>
</li>
</ul>
<h3 id="2-生成报告"><a href="#2-生成报告" class="headerlink" title="2.生成报告"></a>2.生成报告</h3><p>a. 在压力测试结束时报告</p>
<ul>
<li>基本命令格式：<br><code>jmeter -n -t &lt;test JMX file&gt; -l &lt;test log file&gt; -e -o &lt;Path to output folder&gt;</code></li>
<li>样例：<br><code>jmeter -n -t F:\PerformanceTest\TestCase\script\getToken.jmx -l testLogFile -e -o ./output</code></li>
</ul>
<p>b. 使用已有的压力测试CSV日志文件生成报告</p>
<ul>
<li>基本命令格式：<br><code>jmeter -g &lt;log file&gt; -o &lt;Path to output folder&gt;</code></li>
<li>样例：<br><code>jmeter -g D:\apache-jmeter-3.0\bin\testLogFile -o ./output</code></li>
</ul>
<p>两个样例都会在\apache-jmeter-3.0\bin\output目录下产生如下文件(夹):<br><img src="http://ww3.sinaimg.cn/large/9bd9d3e2gw1f5x043a8xuj20if03vdgd.jpg" alt=""></p>
<p>用浏览器打开index.html文件，即可查看各种图形化报告:<br><img src="http://ww4.sinaimg.cn/large/9bd9d3e2gw1f5x04glvcqj20ki0cm3zr.jpg" alt=""><br><img src="http://ww3.sinaimg.cn/large/9bd9d3e2gw1f5x0ao5dkjj212u0fqjvr.jpg" alt=""></p>
<p>注：在3.0版本，由于字符编码问题，可能会遇到生成的报告中，中文标签展示为乱码的问题，因篇幅限制，解决办法请<a href="http://www.aloo.me/2016/08/19/JMeter3-0%E5%9B%BE%E5%BD%A2%E5%8C%96HTML%E6%8A%A5%E5%91%8A%E4%B8%AD%E6%96%87%E4%B9%B1%E7%A0%81%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86/">戳这里</a>看我另一篇文章。</p>
<h2 id="四-自定义配置"><a href="#四-自定义配置" class="headerlink" title="四.自定义配置"></a>四.自定义配置</h2><p>JMeter3.0在bin目录新增了<code>reportgenerator.properties</code>文件保存了所有关于图形化HTML报告生成模块的默认配置，要变更配置，建议不要直接编辑该文件，而是推荐在<code>user.properties</code>中去配置和覆盖。</p>
<h3 id="1-总体配置"><a href="#1-总体配置" class="headerlink" title="1.总体配置"></a>1.总体配置</h3><p>总体配置都是以<code>jmeter.reportgenerator.</code>为前缀。如：jmeter.reportgenerator.overall_granularity=60000</p>
<ul>
<li><code>overall_granularity</code>：定义采样点粒度，默认为60000ms，通常在稳定性以外的测试中，我们可能需要定义更细的粒度，比如1000ms，我们可以在<code>user.properties</code>文件末尾添加如下配置：<pre><code class="xml"># Change this parameter if you want to change the granularity of over time graphs.
jmeter.reportgenerator.overall_granularity=6000
</code></pre>
</li>
<li><code>report_title</code>:定义报告的标题，我们可能需要将标题定义为实际测试项名称</li>
<li><code>apdex_satisfied_threshold</code>：定义Apdex评估中<strong>满意</strong>的阈值(单位ms)</li>
<li><code>apdex_tolerated_threshold</code>: 定义Apdex评估中<strong>可容忍</strong>的阈值<br><code>Apdext = (Satisfied Count + Tolerating Count / 2) / Total Samples</code></li>
</ul>
<p>另外，在<code>jmeter.properties</code>中，有关于集合报告中的三个百分位的默认值：</p>
<pre><code class="xml">aggregate_rpt_pct1 : Defaults to 90
aggregate_rpt_pct2 : Defaults to 95
aggregate_rpt_pct3 : Defaults to 99
</code></pre>
<p>可以在<code>user.properties</code>中对其进行覆盖，如：<code>aggregate_rpt_pct1 = 70</code>，效果如下：<br><img src="http://ww3.sinaimg.cn/large/9bd9d3e2gw1f5x04h6f3dj20bl06cq3b.jpg" alt=""></p>
<h3 id="2-图表配置"><a href="#2-图表配置" class="headerlink" title="2.图表配置"></a>2.图表配置</h3><p>每个图表配置都是以<code>jmeter.reportgenerator.graph.&lt;图表名称&gt;.</code>为前缀。</p>
<ul>
<li><code>classname</code> 图表的实现类，如果有自己定制的实现，将该配置的值写为自定义实现类的类名</li>
<li><code>title</code> 图标标题，比如要汉化的时候，在这里配置中文标题</li>
<li><code>property.set_granularity</code> 设置图标的采样点粒度，不配置时默认使用总体配置中的粒度设置</li>
</ul>
<h3 id="3-输出配置"><a href="#3-输出配置" class="headerlink" title="3.输出配置"></a>3.输出配置</h3><p>输出配置都以<code>jmeter.reportgenerator.exporter</code>为前缀。</p>
<ul>
<li><code>property.output_dir</code> 配置默认的报告输出路径。在命令行可以用-o选项来设置特定的路径覆盖该配置。</li>
<li><code>html.series_filter</code> 用于过滤展示内容。如在user.properties添加如下配置：<br><code>jmeter.reportgenerator.exporter.html.series_filter=(^Login)(-success|-failure)?</code><br>则最后的报告只展示名为Login这个取样器的数据。该配置包含两部分，<code>(-success|-failure)?</code>是<code>Transactions per second</code>图表所依赖的配置。前面部分接受一个正则表达式用来过滤。</li>
</ul>
<h2 id="五-总结"><a href="#五-总结" class="headerlink" title="五.总结"></a>五.总结</h2><p>本次介绍的<code>Dashboard Report</code>特性本质上是Apache JMeter对于测试结果数据可视化方式的顺应时代的更新，虽然算是姗姗来迟，虽然并不酷炫，但至少，对于要需要基于它来执行性能测试的人来说，仍然是一个福音。最后，感谢Apache JMeter项目的各位贡献者对它的持续更新。</p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol>
<li><a href="http://jmeter.apache.org/usermanual/generating-dashboard.html" target="_blank" rel="external">Apache JMeter Dashboard Report</a></li>
<li><a href="http://jmeter.apache.org/usermanual/glossary.html" target="_blank" rel="external">Apache JMeter Glossary</a></li>
</ol>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Dubbo高级特性实践-泛化调用]]></title>
      <url>http://www.aloo.me/2016/07/10/Dubbo%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7%E5%AE%9E%E8%B7%B5-%E6%B3%9B%E5%8C%96%E8%B0%83%E7%94%A8/</url>
      <content type="html"><![CDATA[<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>当后端Java服务用<a href="http://dubbo.io/" target="_blank" rel="external">Dubbo</a>协议作为RPC方案的基础，但部分消费方是前端Restful的PHP服务，不能直接调用，于是在中间架设了Router服务提供统一的基于HTTP的后端调用入口。<br>而Router调用后端Java服务就应用了Dubbo的高级特性–<strong>泛化调用</strong></p>
<ul>
<li>直接消费方(Router服务)不需要引入接口jar包</li>
<li>通过GenericService接口来处理所有服务请求</li>
<li>以PHP到Router的request body中的方法名和方法参数作为Router远程调用后端Java服务的入参，最后将远程调用的result返回给PHP端</li>
</ul>
<p>本文将用一个小Demo来演示上面所述的<strong>泛化调用</strong>应用场景</p>
<a id="more"></a>
<h2 id="零-Dubbo简介"><a href="#零-Dubbo简介" class="headerlink" title="零.Dubbo简介"></a>零.Dubbo简介</h2><blockquote>
<p><em>DUBBO是一个分布式服务框架，致力于提供高性能和透明化的RPC远程服务调用方案，是阿里巴巴SOA服务化治理方案的核心框架，每天为2,000+个服务提供3,000,000,000+次访问量支持，并被广泛应用于阿里巴巴集团的各成员站点。</em><br>– Dubbo官方描述</p>
<h3 id="Dubbo能做什么："><a href="#Dubbo能做什么：" class="headerlink" title="Dubbo能做什么："></a><em>Dubbo能做什么：</em></h3><ul>
<li>透明化的远程方法调用 <ul>
<li>就像调用本地方法一样调用远程方法</li>
<li>只需简单配置，没有任何API侵入。 </li>
</ul>
</li>
<li>软负载均衡及容错机制<ul>
<li>可在内网替代F5等硬件负载均衡器</li>
</ul>
</li>
<li>服务自动注册与发现<ul>
<li>不再需要写死服务提供方地址，注册中心基于接口名查询服务提 供者的IP地址，并且能够平滑添加或删除服务提供者 </li>
</ul>
</li>
</ul>
<p>– 《Dubbo功能介绍》(<em>官方资料</em>)</p>
</blockquote>
<p><em>注：Dubbo的基本使用介绍不在本文范畴，如有需要请自行参考<a href="http://dubbo.io/" target="_blank" rel="external">官方资料</a></em></p>
<blockquote>
<p><em>泛接口调用方式主要用于客户端没有API接口及模型类元的情况，参数及返回值中的所有POJO均用Map表示，通常用于框架集成，比如：实现一个通用的服务测试框架，可通过GenericService调用所有服务实现。</em><br>– Dubbo用户指南</p>
</blockquote>
<h2 id="一-后端API"><a href="#一-后端API" class="headerlink" title="一.后端API"></a>一.后端API</h2><pre><code class="java">public interface UserInfoService {
    public Map&lt;String, String&gt; getUser(String id);
    public Map&lt;String, String&gt;[] getUsers();
}
</code></pre>
<h2 id="二-Router端dubbo配置"><a href="#二-Router端dubbo配置" class="headerlink" title="二.Router端dubbo配置"></a>二.Router端dubbo配置</h2><p><code>dubboconf.properties:</code></p>
<pre><code>application.name=router
registry.address=zookeeper://address1?buckup=address2,address3
</code></pre><h2 id="三-前端服务post到Router的Request-Body示例："><a href="#三-前端服务post到Router的Request-Body示例：" class="headerlink" title="三.前端服务post到Router的Request Body示例："></a>三.前端服务post到Router的Request Body示例：</h2><pre><code class="json">{
    &quot;interfaceName&quot;: &quot;foo&quot;, 
    &quot;methodName&quot;: &quot;bar&quot;, 
    &quot;methodParams&quot;: [
        {
            &quot;id&quot;: &quot;xxx&quot;
        }
    ]
}
</code></pre>
<h2 id="四-处理前端参数用的Dto"><a href="#四-处理前端参数用的Dto" class="headerlink" title="四.处理前端参数用的Dto"></a>四.处理前端参数用的Dto</h2><p><code>RequestDto.java:</code></p>
<pre><code class="java">import java.util.Map;
/**
 * Created by Luo
 */
public class RequestDto {
    private String interfaceName;
    private String methodName
    private Map[] methodParams;

    public String getInterfaceName() {
        return interfaceName;
    }
    public void setInterfaceName(String interfaceName) {
        this.interfaceName =  interfaceName;
    }
    public String getMethodName() {
        return methodName;
    }
    public void setMethodName(String methodName) {
        this.methodName = methodName;
    }
    public Map[] getMethodParams() {
        return methodParams;
    }
    public void setMethodParam(Map[] methodParams) {
        this.methodParams = methodParams;
    }
}
</code></pre>
<h2 id="五-Router服务入口"><a href="#五-Router服务入口" class="headerlink" title="五.Router服务入口"></a>五.Router服务入口</h2><p><code>RouterController.java:</code></p>
<pre><code class="java">import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.web.bind.annotation.*;

import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;

/**
 * Created by Luo
 */
@RestController
public class App {
        @RequestMapping(value = &quot;/router/&quot;, method = RequestMethod.POST)
        public Object getUser(@ModelAttribute RequestDto dto) {
            Map map = new HashMap&lt;&gt;();
            map.put(&quot;ParamType&quot;, &quot;java.lang.String&quot;);  //后端接口参数类型
            map.put(&quot;Object&quot;, dto.getMethodParams()[0].get(&quot;id&quot;));  //用以调用后端接口的实参

            List&lt;Map&lt;String, Object&gt;&gt; paramInfos= new ArrayList&lt;&gt;();
            paramInfos.add(map);

            DubboServiceFactory dubbo = DubboServiceFactory.getInstance();

            return dubbo.genericInvoke(dto.getInterfaceName(), dto.getMethodName(), paramInfos);
        }
}
</code></pre>
<p><em>注：本文旨在演示泛化调用的一种应用方式，为简明起见，代码中直接从dto中获取了指定参数，而并没有完整实现其路由功能，望见谅。</em></p>
<h2 id="六-通过GenericService进行泛化调用"><a href="#六-通过GenericService进行泛化调用" class="headerlink" title="六.通过GenericService进行泛化调用"></a>六.通过GenericService进行泛化调用</h2><p><code>DubboServiceFactory.java</code></p>
<pre><code class="java">package local.demo.genericservice;

import com.alibaba.dubbo.config.ApplicationConfig;
import com.alibaba.dubbo.config.ReferenceConfig;
import com.alibaba.dubbo.config.RegistryConfig;
import com.alibaba.dubbo.config.utils.ReferenceConfigCache;
import com.alibaba.dubbo.rpc.service.GenericService;


import java.io.IOException;
import java.util.List;
import java.util.Map;
import java.util.Properties;

/**
 * Created by Luo
 */
public class DubboServiceFactory {

    private ApplicationConfig application;
    private RegistryConfig registry;

    private static class SingletonHolder {
        private static DubboServiceFactory INSTANCE = new DubboServiceFactory();
    }

    private DubboServiceFactory(){
        Properties prop = new Properties();
        ClassLoader loader = DubboServiceFactory.class.getClassLoader();

        try {
            prop.load(loader.getResourceAsStream(&quot;dubboconf.properties&quot;));
        } catch (IOException e) {
            e.printStackTrace();
        }

        ApplicationConfig applicationConfig = new ApplicationConfig();
        applicationConfig.setName(prop.getProperty(&quot;application.name&quot;)); 
        //这里配置了dubbo的application信息*(demo只配置了name)*，因此demo没有额外的dubbo.xml配置文件
        RegistryConfig registryConfig = new RegistryConfig();
        registryConfig.setAddress(prop.getProperty(&quot;registry.address&quot;)); 
        //这里配置dubbo的注册中心信息，因此demo没有额外的dubbo.xml配置文件

        this.application = applicationConfig;
        this.registry = registryConfig;

    }

    public static DubboServiceFactory getInstance() {
        return SingletonHolder.INSTANCE;
    }

    public Object genericInvoke(String interfaceClass, String methodName, List&lt;Map&lt;String, Object&gt;&gt; parameters){

        ReferenceConfig&lt;GenericService&gt; reference = new ReferenceConfig&lt;GenericService&gt;();
        reference.setApplication(application); 
        reference.setRegistry(registry); 
        reference.setInterface(interfaceClass); // 接口名 
        reference.setGeneric(true); // 声明为泛化接口 

        //ReferenceConfig实例很重，封装了与注册中心的连接以及与提供者的连接，
        //需要缓存，否则重复生成ReferenceConfig可能造成性能问题并且会有内存和连接泄漏。
        //API方式编程时，容易忽略此问题。
        //这里使用dubbo内置的简单缓存工具类进行缓存

        ReferenceConfigCache cache = ReferenceConfigCache.getCache();
        GenericService genericService = cache.get(reference); 
        // 用com.alibaba.dubbo.rpc.service.GenericService可以替代所有接口引用 

        int len = parameters.size();
        String[] invokeParamTyeps = new String[len];
        Object[] invokeParams = new Object[len];
        for(int i = 0; i &lt; len; i++){
            invokeParamTyeps[i] = parameters.get(i).get(&quot;ParamType&quot;) + &quot;&quot;;
            invokeParams[i] = parameters.get(i).get(&quot;Object&quot;);
        }
        return genericService.$invoke(methodName, invokeParamTyeps, invokeParams);
    }

}
</code></pre>
<h2 id="七-部署"><a href="#七-部署" class="headerlink" title="七.部署"></a>七.部署</h2><p>将Router部署到Jetty/Tomcat等容器，或者直接使用<a href="http://projects.spring.io/spring-boot/" target="_blank" rel="external">SpringBoot</a>开发，发布为内嵌Jetty/Tomcat的独立jar包，即可向前端服务提供服务。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[JMeter性能测试3.0时代之-全新JMeter插件管理]]></title>
      <url>http://www.aloo.me/2016/07/05/JMeter%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%953-0%E6%97%B6%E4%BB%A3%E4%B9%8B-%E5%85%A8%E6%96%B0JMeter%E6%8F%92%E4%BB%B6%E7%AE%A1%E7%90%86/</url>
      <content type="html"><![CDATA[<blockquote>
<p>今年五月，老牌开源性能测试工具<a href="http://jmeter.apache.org/" target="_blank" rel="external">Apache JMeter</a>迎来了自2011年11月成为Apache顶级项目以来的首次大版本更新–从2.13更新到3.0。<br>这对于广大JMeter用户来说无疑是一个好消息，它让我们看到了这个项目的活力。也是因此，打算写一些自己感受到的JMeter近来的变化。</p>
</blockquote>
<a id="more"></a>
<h2 id="JMeter"><a href="#JMeter" class="headerlink" title="JMeter"></a>JMeter</h2><p><a href="http://jmeter.apache.org/" target="_blank" rel="external">JMeter</a>，老牌，开源，轻量，Apache基金会的顶级项目，光是这些关键字就足以让大量用户将其纳入自己的性能测试工具箱。而从实际看来，其在国内的用户数量，足以和著名的LoadRunner分庭抗礼，甚至在如今的互联网浪潮下，其覆盖范围可能已经超越了LR，甚至在其他领域，如接口测试，也能看到JMeter的身影。对于这样的发展趋势，我也非常乐意看到，因为我最初做性能测试时，选择了使用JMeter作为主力工具。</p>
<p>然而最近两年，JMeter并没有太多值得关注的更新。虽然现在的我已经不再是性能测试的萌新，不会被一个工具所制约，但是作为帮助我入门的工具，还是希望能够看到一个更活跃的JMeter，更活跃的JMeter生态。</p>
<p>今年夏天，首先得到的好消息是JMeter迎来了它的3.0版本，其中一个重要的更新就是HTML页面形式的性能测试报告，这一方面它终于是赶上了<a href="http://gatling.io/#/" target="_blank" rel="external">Gatling</a>(<em>关注Gatling主要因为两方面：一是其甩JMeter几条街的性能，二就是其出色的report</em>)。</p>
<p>然而今天这篇文章并不是讲JMeter 3.0的新特性(<em>废话半天竟然又不讲这，我自己都醉了。主要是由于时间不够，3.0的新特性，计划放到下一篇文章</em>)，今天要提的是第二个消息，不是来自于JMeter自身，而是<strong>JMeter Plugins</strong>。</p>
<h2 id="JMeter-Plugins"><a href="#JMeter-Plugins" class="headerlink" title="JMeter Plugins"></a>JMeter Plugins</h2><p>一直以来，<a href="http://www.jmeter-plugins.org/" target="_blank" rel="external">JMeter Plugins</a>为我们提供了很多高价值的JMeter插件，比如:</p>
<ul>
<li>用于服务器性能监视的<a href="http://jmeter-plugins.org/wiki/PerfMon" target="_blank" rel="external">PerfMon Metrics Collector</a></li>
<li>用于建立压力变化模型的<a href="http://jmeter-plugins.org/wiki/SteppingThreadGroup" target="_blank" rel="external">Stepping Thread Group</a></li>
<li>用于Json解析的<a href="http://jmeter-plugins.org/wiki/JSONPathExtractor" target="_blank" rel="external">JSON Path Extractor</a></li>
<li>用于展示响应时间曲线的<a href="http://jmeter-plugins.org/wiki/ResponseTimesOverTime" target="_blank" rel="external">Response Times Over Time</a></li>
<li>用于展示TPS曲线的<a href="http://jmeter-plugins.org/wiki/TransactionsPerSecond" target="_blank" rel="external">Transactions per Second</a><br>非常感谢这些插件的贡献者很大程度上丰富了JMeter的生态，并直接造福了广大的JMeter使用者。</li>
</ul>
<p>在以前，这些插件的安装还是一个纯手工的方式：所有插件分为四个集合包，首先需要找到包含目标功能的集合包-下载该依赖包-拷贝的合适的路径-重启JMeter。这样的过程对于刚接触JMeter的新人来说，可能稍显繁琐。</p>
<h2 id="Plugins-Manager"><a href="#Plugins-Manager" class="headerlink" title="Plugins Manager"></a>Plugins Manager</h2><p>值得高兴的是，最近，<strong>jmeter-plugins.org</strong>推出了全新的<a href="http://www.jmeter-plugins.org/wiki/PluginsManager/" target="_blank" rel="external">Plugins Manager</a>，对于其提供的插件进行了集中的管理，我们只需要安装这个管理插件，即可以在JMeter的界面上搜索并安装指定的插件。简要步骤如下：</p>
<ol>
<li>下载管理插件的<a href="http://jmeter-plugins.org/get/" target="_blank" rel="external">JAR文件</a></li>
<li>将下载的文件拷贝的你的JMeter根目录下的<code>lib/ext</code>目录</li>
<li>启动JMeter，点击<code>菜单栏</code>-<code>Options</code>-<code>Plugins Manager</code>,如<code>图1</code>：</li>
</ol>
<p><img src="http://ww1.sinaimg.cn/large/9bd9d3e2gw1f5otxp1yk8j20c908675n.jpg" alt="图1"></p>
<ol>
<li>在如<code>图2</code>的管理页面进行插件管理，共有三个标签页:</li>
</ol>
<p><img src="http://ww2.sinaimg.cn/large/9bd9d3e2gw1f5otxpd97mj20hr07qjtn.jpg" alt="图2"></p>
<ul>
<li>Installed Plugins：顾名思义，是用于查看已安装的插件，并可通过<code>取消勾选</code>-<code>应用操作</code>来卸载插件</li>
<li>Available Plugins:用于查看和安装可用的插件</li>
<li>Upgrades:用于升级插件</li>
</ul>
<p>另外，Plugins Manager还提供了命令行安装的支持，具体参见<a href="http://jmeter-plugins.org/wiki/PluginsManager/" target="_blank" rel="external">官方wiki</a>，以便让在Linux上或者以NO-GUI方式在windows运行的使用者也能快捷的进行JMeter插件管理。</p>
<p>最后，快快去体验一下吧 : )</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[正确、安全地停止SpringBoot应用]]></title>
      <url>http://www.aloo.me/2016/06/27/%E6%AD%A3%E7%A1%AE%E3%80%81%E5%AE%89%E5%85%A8%E5%9C%B0SpringBoot%E5%BA%94%E7%94%A8/</url>
      <content type="html"><![CDATA[<p><img src="http://ww4.sinaimg.cn/large/9bd9d3e2gw1f5bxlcc3o9j20nz0b7t8t.jpg" alt=""></p>
<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p><a href="http://projects.spring.io/spring-boot/" target="_blank" rel="external">Spring Boot</a>，作为Spring框架对“约定优先于配置(Convention Over Configuration)”理念的最佳实践的产物，它能帮助我们很快捷的创建出独立运行、产品级别的基于Spring框架的应用，大部分Spring Boot应用只需要非常少的配置就可以快速运行起来，是一个与微服务(MicroServices)相当契合的微框架。<br>网络上关于Spring Boot的QuickStart式中文内容已经相当丰富，但是对于部署后怎样便捷、安全地停止服务(shutdown)，还比较缺乏，最近发现Spring Boot的官方指南更新了相关内容，因此结合该部分更新，对如何<strong>基于官方提供的特性</strong>正确地停止Spring Boot应用进行简单说明。</p>
<p>主要有两种方式：通过<code>HTTP</code>发送<code>shutdown</code>信号，或者通过<code>service stop</code>的方式<br><a id="more"></a></p>
<h2 id="方式一：通过HTTP发送shutdown信号"><a href="#方式一：通过HTTP发送shutdown信号" class="headerlink" title="方式一：通过HTTP发送shutdown信号"></a>方式一：通过<code>HTTP</code>发送<code>shutdown</code>信号</h2><p>该方式主要依赖<code>Spring Boot Actuator</code>的<code>endpoint</code>特性，具体步骤如下：</p>
<h3 id="1-在pom-xml中引入actuator依赖"><a href="#1-在pom-xml中引入actuator依赖" class="headerlink" title="1. 在pom.xml中引入actuator依赖"></a>1. 在<code>pom.xml</code>中引入<code>actuator</code>依赖</h3><pre><code>&lt;dependency&gt;
  &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
  &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre><h3 id="2-开启shutdown-endpoint"><a href="#2-开启shutdown-endpoint" class="headerlink" title="2. 开启shutdown endpoint"></a>2. 开启<code>shutdown endpoint</code></h3><p>  <code>Spring Boot Actuator</code>的<code>shutdown endpoin</code>t默认是关闭的，因此在<code>application.properties</code>中开启<code>shutdown endpoint</code>：</p>
<pre><code>#启用shutdown
endpoints.shutdown.enabled=true
#禁用密码验证
endpoints.shutdown.sensitive=false
</code></pre><h3 id="3-发送shutdown信号"><a href="#3-发送shutdown信号" class="headerlink" title="3. 发送shutdown信号"></a>3. 发送<code>shutdown</code>信号</h3><p>  <code>shutdown</code>的默认<code>url</code>为<code>host:port/shutdown</code>，当需要停止服务时，向服务器<code>post</code>该请求即可，如：<br><code>curl -X POST host:port/shutdown</code><br>将得到形如<code>{&quot;message&quot;:&quot;Shutting down, bye...&quot;}</code>的响应</p>
<h3 id="4-安全设置"><a href="#4-安全设置" class="headerlink" title="4. 安全设置"></a>4. 安全设置</h3><p>可以看出，使用该方法可以非常方便的进行远程操作，但是需要注意的是，正式使用时，必须对该请求进行必要的安全设置，比如借助<code>spring-boot-starter-security</code>进行身份认证：</p>
<ol>
<li>pom.xml添加security依赖<pre><code>&lt;dependency&gt;
 &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
 &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre></li>
<li>开启安全验证<br>在<code>application.properties</code>中变更配置,并<pre><code>#开启shutdown的安全验证
endpoints.shutdown.sensitive=true
#验证用户名
security.user.name=admin
#验证密码
security.user.password=secret
#角色
management.security.role=SUPERUSER
</code></pre></li>
<li>指定路径、IP、端口<pre><code>#指定shutdown endpoint的路径
endpoints.shutdown.path=/custompath
#也可以统一指定所有endpoints的路径`management.context-path=/manage`
#指定管理端口和IP
management.port=8081
management.address=127.0.0.1
</code></pre></li>
</ol>
<h2 id="方式二：部署为Unix-Linux-Service"><a href="#方式二：部署为Unix-Linux-Service" class="headerlink" title="方式二：部署为Unix/Linux Service"></a>方式二：部署为Unix/Linux Service</h2><p>该方式主要借助官方的<code>spring-boot-maven-plugin</code>创建”Fully executable” jar ，这中jar包内置一个shell脚本，可以方便的将该应用设置为Unix/Linux的系统服务(init.d service),官方对该功能在CentOS和Ubuntu进行了测试，对于OS X和FreeBSD,可能需要自定义。具体步骤如下:</p>
<h3 id="1-在pom-xml中引入插件："><a href="#1-在pom-xml中引入插件：" class="headerlink" title="1. 在pom.xml中引入插件："></a>1. 在<code>pom.xml</code>中引入插件：</h3><pre><code>&lt;plugin&gt;
  &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
  &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;
  &lt;configuration&gt;
    &lt;executable&gt;true&lt;/executable&gt;
  &lt;/configuration&gt;
&lt;/plugin&gt;
</code></pre><h3 id="2-设置为系统服务"><a href="#2-设置为系统服务" class="headerlink" title="2. 设置为系统服务"></a>2. 设置为系统服务</h3><p>  将你的应用打成jar包，部署到服务器，假设部署路径为/var/app，包名为app.jar，通过如下方式将应该设置为一个系统服务：<br><code>sudo ln -s /var/app/app.jar /etc/init.d/app</code></p>
<h3 id="3-赋予可执行权限："><a href="#3-赋予可执行权限：" class="headerlink" title="3. 赋予可执行权限："></a>3. 赋予可执行权限：</h3><p><code>chmod u+x app.jar</code></p>
<h3 id="4-以系统服务的方式管理"><a href="#4-以系统服务的方式管理" class="headerlink" title="4. 以系统服务的方式管理"></a>4. 以系统服务的方式管理</h3><p>  接下来，就可以使用我们熟悉的service foo start|stop|restart来对应用进行启停等管理了<br><code>sudo service app start|stop</code><br>命令将得到形如<code>Started|Stopped [PID]</code>的结果反馈</p>
<p>默认PID文件路径：/var/run/appname/appname.pid<br>默认日志文件路径：/var/log/appname.log</p>
<p>这可能是我们更熟悉也更常用的管理方式。</p>
<h3 id="自定义参数"><a href="#自定义参数" class="headerlink" title="自定义参数"></a>自定义参数</h3><p>在这种方式下，我们还可以使用自定义的.conf文件来变更默认配置，方法如下：</p>
<ol>
<li>在jar包相同路径下创建一个.conf文件，名称应该与.jar的名称相同，如appname.conf</li>
<li>在其中配置相关变量，如：<pre><code>JAVA_HOME=/usr/local/jdk
JAVA_OPTS=-Xmx1024M
LOG_FOLDER=/custom/log
</code></pre></li>
</ol>
<h3 id="安全设置"><a href="#安全设置" class="headerlink" title="安全设置"></a>安全设置</h3><p>作为应用服务，安全性是一个不能忽略的问题，如下一些操作可以作为部分基础设置参考：</p>
<ul>
<li>为服务创建一个独立的用户，同时最好将该用户的shell绑定为/usr/sbin/nologin</li>
<li>赋予最小范围权限：<code>chmod 500 app.jar</code></li>
<li>阻止修改：<code>sudo chattr +i app.jar</code></li>
<li>对.conf文件做类似的工作：<code>chmod 400 app.conf</code>,<code>sudo chown root:root app.conf</code></li>
</ul>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol>
<li><a href="http://docs.spring.io/spring-boot/docs/current/reference/html/deployment-install.html" target="_blank" rel="external">Installing Spring Boot applications</a></li>
<li><a href="http://docs.spring.io/spring-boot/docs/current/reference/html/production-ready-enabling.html" target="_blank" rel="external">Endpoints</a></li>
<li><a href="http://docs.spring.io/spring-boot/docs/current/reference/html/production-ready-monitoring.html#production-ready-sensitive-endpoints" target="_blank" rel="external">Securing sensitive endpoints</a></li>
</ol>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Welcome]]></title>
      <url>http://www.aloo.me/2016/06/21/FirstPost/</url>
      <content type="html"><![CDATA[<p>  Welcome to my blog, it is under construction.</p>
]]></content>
    </entry>
    
  
  
</search>
